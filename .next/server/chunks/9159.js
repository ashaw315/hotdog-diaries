"use strict";exports.id=9159,exports.ids=[9159],exports.modules={29159:(a,b,c)=>{c.a(a,async(a,d)=>{try{c.d(b,{Q:()=>n});var e=c(7462),f=c(35144),g=c(76865),h=c(40704),i=c(99986),j=c(73790),k=c(55511),l=c.n(k),m=a([e,g,h,i,j]);[e,g,h,i,j]=m.then?(await m)():m;class n{static{this.DEFAULT_CONFIG={autoApprovalThreshold:.8,autoRejectionThreshold:.3,requireManualReview:!1,enableDuplicateDetection:!0,enableSpamFilter:!0,enableInappropriateFilter:!0,enableUnrelatedFilter:!0,enableRequiredTermsCheck:!0}}static{this.MAX_PROCESSING_ATTEMPTS=3}static{this.BATCH_SIZE=50}async processContent(a,b){let c={...n.DEFAULT_CONFIG,...b},d=Date.now();try{let b;await i.RE.logInfo("ContentProcessor","Starting content processing",{contentId:a,config:c}),await j.z.recordCustomMetric("content_processing_started",1,"count",{contentId:a.toString()});let k=await this.getContentById(a);if(!k)throw Error(`Content with ID ${a} not found`);let l=await this.validateContent(k);if(!l.isValid)return{success:!1,contentId:a,action:"rejected",analysis:this.createEmptyAnalysis(),reason:`Validation failed: ${l.errors.join(", ")}`};if(c.enableDuplicateDetection){let c=await h.i.checkForDuplicates(k);if(c.isDuplicate&&c.originalContentId)return b=c.originalContentId,await this.saveContentAnalysis(a,{...this.createEmptyAnalysis(),duplicate_of:b}),await (0,e.rP)(f.$b.INFO,"Duplicate content detected","ContentProcessor",{contentId:a,duplicateOf:b}),{success:!0,contentId:a,action:"duplicate",analysis:this.createEmptyAnalysis(),reason:"Duplicate content detected",duplicateOf:b}}let m=await g.M.isValidHotdogContent(k);m.content_id=a,c.enableSpamFilter||(m.is_spam=!1),c.enableInappropriateFilter||(m.is_inappropriate=!1),c.enableUnrelatedFilter||(m.is_unrelated=!1),c.enableRequiredTermsCheck||(m.is_valid_hotdog=!0);let n=this.determineAction(m,c);await this.updateContentStatus(a,n,m),await this.saveContentAnalysis(a,m);let o=Date.now()-d;return await j.z.recordContentProcessingMetric("content_processing",o,!0,1,{action:n,confidence:m.confidence_score,isValidHotdog:m.is_valid_hotdog}),await i.RE.logInfo("ContentProcessor","Content processing completed",{contentId:a,action:n,confidence:m.confidence_score,isValidHotdog:m.is_valid_hotdog,duration:o}),{success:!0,contentId:a,action:n,analysis:m,reason:this.getActionReason(n,m)}}catch(c){let b=Date.now()-d;return await j.z.recordContentProcessingMetric("content_processing",b,!1,0,{error:c instanceof Error?c.message:"Unknown error"}),await i.RE.logError("ContentProcessor","Content processing failed",{contentId:a,duration:b,error:c instanceof Error?c.message:"Unknown error"},c),{success:!1,contentId:a,action:"rejected",analysis:this.createEmptyAnalysis(),reason:`Processing failed: ${c instanceof Error?c.message:"Unknown error"}`}}}async processBatch(a,b){let c=[],d=Math.min(a.length,n.BATCH_SIZE),g=Date.now();await i.RE.logInfo("ContentProcessor","Starting batch processing",{totalItems:a.length,batchSize:d}),await j.z.recordCustomMetric("batch_processing_started",a.length,"count");for(let g=0;g<a.length;g+=d){let h=a.slice(g,g+d),i=h.map(a=>this.processContent(a,b));try{for(let a of(await Promise.allSettled(i)))"fulfilled"===a.status?c.push(a.value):c.push({success:!1,contentId:0,action:"rejected",analysis:this.createEmptyAnalysis(),reason:`Batch processing failed: ${a.reason}`})}catch(a){await (0,e.rP)(f.$b.ERROR,"Batch processing failed","ContentProcessor",{batchStart:g,batchSize:h.length,error:a instanceof Error?a.message:"Unknown error"})}}let h=Date.now()-g,k=c.filter(a=>a.success).length,l=c.filter(a=>!a.success).length;return await j.z.recordContentProcessingMetric("batch_processing",h,0===l,c.length,{successful:k,failed:l,batchSize:d}),await i.RE.logInfo("ContentProcessor","Batch processing completed",{totalProcessed:c.length,successful:k,failed:l,duration:h}),c}async addToProcessingQueue(a,b="medium"){try{await e.db.query(`INSERT INTO processing_queue (content_queue_id, priority, status, attempts, created_at, updated_at)
         VALUES ($1, $2, 'pending', 0, NOW(), NOW())`,[a,b]),await (0,e.rP)(f.$b.INFO,"Content added to processing queue","ContentProcessor",{contentId:a,priority:b})}catch(c){throw await (0,e.rP)(f.$b.ERROR,"Failed to add content to processing queue","ContentProcessor",{contentId:a,priority:b,error:c instanceof Error?c.message:"Unknown error"}),c}}async processQueue(a=100){try{let b=await e.db.query(`SELECT * FROM processing_queue 
         WHERE status = 'pending' 
         AND attempts < $1
         ORDER BY 
           CASE priority 
             WHEN 'high' THEN 1 
             WHEN 'medium' THEN 2 
             WHEN 'low' THEN 3 
           END,
           created_at ASC
         LIMIT $2`,[n.MAX_PROCESSING_ATTEMPTS,a]);if(0===b.rows.length)return[];let c=[];for(let a of b.rows)try{await e.db.query(`UPDATE processing_queue 
             SET status = 'processing', attempts = attempts + 1, updated_at = NOW() 
             WHERE id = $1`,[a.id]);let b=await this.processContent(a.content_queue_id);c.push(b),await e.db.query(`UPDATE processing_queue 
             SET status = 'completed', updated_at = NOW() 
             WHERE id = $1`,[a.id])}catch(d){let b=d instanceof Error?d.message:"Unknown error",c=a.attempts+1>=n.MAX_PROCESSING_ATTEMPTS?"failed":"pending";await e.db.query(`UPDATE processing_queue 
             SET status = $1, last_error = $2, updated_at = NOW() 
             WHERE id = $3`,[c,b,a.id]),await (0,e.rP)(f.$b.ERROR,"Queue item processing failed","ContentProcessor",{queueId:a.id,contentId:a.content_queue_id,attempt:a.attempts+1,error:b})}return c}catch(a){return await (0,e.rP)(f.$b.ERROR,"Queue processing failed","ContentProcessor",{error:a instanceof Error?a.message:"Unknown error"}),[]}}async getProcessingStats(){try{let a=(await e.db.query(`
        SELECT 
          COUNT(*) as total,
          COUNT(*) FILTER (WHERE status = 'pending') as pending,
          COUNT(*) FILTER (WHERE status = 'processing') as processing,
          COUNT(*) FILTER (WHERE status = 'failed') as failed,
          AVG(EXTRACT(EPOCH FROM (updated_at - created_at))) as avg_processing_time
        FROM processing_queue
        WHERE created_at >= NOW() - INTERVAL '24 hours'
      `)).rows[0];return{queueSize:parseInt(a.total),pendingItems:parseInt(a.pending),processingItems:parseInt(a.processing),failedItems:parseInt(a.failed),averageProcessingTime:parseFloat(a.avg_processing_time)||0}}catch(a){return await (0,e.rP)(f.$b.ERROR,"Failed to get processing stats","ContentProcessor",{error:a instanceof Error?a.message:"Unknown error"}),{queueSize:0,pendingItems:0,processingItems:0,failedItems:0,averageProcessingTime:0}}}async validateContent(a){let b=[],c=[];return a.original_url||b.push("Original URL is required"),a.content_text||a.content_image_url||a.content_video_url||b.push("At least one content field (text, image, or video) is required"),a.source_platform||b.push("Source platform is required"),a.original_url&&!this.isValidUrl(a.original_url)&&b.push("Invalid original URL format"),a.content_image_url&&!this.isValidUrl(a.content_image_url)&&b.push("Invalid image URL format"),a.content_video_url&&!this.isValidUrl(a.content_video_url)&&b.push("Invalid video URL format"),a.content_text&&(a.content_text.length<10&&c.push("Content text is very short"),a.content_text.length>5e3&&c.push("Content text is very long")),a.source_platform&&!["reddit","instagram","facebook","tiktok"].includes(a.source_platform)&&b.push(`Invalid source platform: ${a.source_platform}`),a.original_author&&a.original_author.length>255&&c.push("Author name is very long"),{isValid:0===b.length,errors:b,warnings:c}}async getContentById(a){let b=await e.db.query("SELECT * FROM content_queue WHERE id = $1",[a]);return b.rows.length>0?b.rows[0]:null}determineAction(a,b){return a.is_spam||a.is_inappropriate?"rejected":a.is_unrelated?"flagged":a.confidence_score>=b.autoApprovalThreshold&&a.is_valid_hotdog?"approved":a.confidence_score<=b.autoRejectionThreshold?"rejected":(b.requireManualReview,"flagged")}async updateContentStatus(a,b,c){let d=!1,f=!1;switch(b){case"approved":d=!0;break;case"rejected":case"duplicate":d=!1;break;case"flagged":f=!0}await e.db.query(`UPDATE content_queue 
       SET is_approved = $1, updated_at = NOW() 
       WHERE id = $2`,[d,a]),f&&(c.is_flagged=!0,c.flagged_reason=this.getActionReason(b,c))}async saveContentAnalysis(a,b){await e.db.query(`INSERT INTO content_analysis (
        content_queue_id, is_spam, is_inappropriate, is_unrelated, is_valid_hotdog,
        confidence_score, flagged_patterns, processing_notes, similarity_hash,
        duplicate_of, filter_results, is_flagged, flagged_reason, created_at, updated_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, NOW(), NOW())
      ON CONFLICT (content_queue_id) 
      DO UPDATE SET
        is_spam = EXCLUDED.is_spam,
        is_inappropriate = EXCLUDED.is_inappropriate,
        is_unrelated = EXCLUDED.is_unrelated,
        is_valid_hotdog = EXCLUDED.is_valid_hotdog,
        confidence_score = EXCLUDED.confidence_score,
        flagged_patterns = EXCLUDED.flagged_patterns,
        processing_notes = EXCLUDED.processing_notes,
        similarity_hash = EXCLUDED.similarity_hash,
        duplicate_of = EXCLUDED.duplicate_of,
        filter_results = EXCLUDED.filter_results,
        is_flagged = EXCLUDED.is_flagged,
        flagged_reason = EXCLUDED.flagged_reason,
        updated_at = NOW()`,[a,b.is_spam,b.is_inappropriate,b.is_unrelated,b.is_valid_hotdog,b.confidence_score,b.flagged_patterns,b.processing_notes,b.similarity_hash,b.duplicate_of,JSON.stringify({is_spam:b.is_spam,is_inappropriate:b.is_inappropriate,is_unrelated:b.is_unrelated,is_valid_hotdog:b.is_valid_hotdog,confidence_score:b.confidence_score}),b.is_flagged||!1,b.flagged_reason||null])}getActionReason(a,b){switch(a){case"approved":return"Content passed all filters and meets quality standards";case"rejected":if(b.is_spam)return"Content detected as spam";if(b.is_inappropriate)return"Content contains inappropriate material";if(b.confidence_score<.3)return"Content has low confidence score";return"Content failed quality checks";case"flagged":if(b.is_unrelated)return"Content may be unrelated to hotdogs";if(b.confidence_score<.8)return"Content requires manual review due to low confidence";return"Content flagged for manual review";case"duplicate":return"Content identified as duplicate";default:return"Unknown action"}}createEmptyAnalysis(){return{is_spam:!1,is_inappropriate:!1,is_unrelated:!1,is_valid_hotdog:!1,confidence_score:0,flagged_patterns:[],processing_notes:[],similarity_hash:""}}isValidUrl(a){try{return new URL(a),!0}catch{return!1}}generateContentHash(a){let b=[a.content_text||"",a.content_image_url||"",a.content_video_url||"",a.original_url||""].join("|");return l().createHash("sha256").update(b).digest("hex")}}new n,d()}catch(a){d(a)}})},40704:(a,b,c)=>{c.a(a,async(a,d)=>{try{c.d(b,{Y:()=>j,i:()=>k});var e=c(7462),f=c(35144),g=c(55511),h=c.n(g),i=a([e]);e=(i.then?(await i)():i)[0];class j{static{this.EXACT_MATCH_THRESHOLD=1}static{this.FUZZY_MATCH_THRESHOLD=.85}static{this.URL_SIMILARITY_THRESHOLD=.9}static{this.IMAGE_SIMILARITY_THRESHOLD=.95}static{this.VIDEO_SIMILARITY_THRESHOLD=.95}async checkForDuplicates(a){try{await (0,e.rP)(f.$b.INFO,"Starting duplicate detection","DuplicateDetectionService",{contentId:a.id});let b=this.generateExactHash(a);this.generateFuzzyHash(a);let c=this.generateUrlHash(a),d=this.generateImageHash(a),g=this.generateVideoHash(a),h=await this.findExactMatch(b,a.id);if(h)return{isDuplicate:!0,originalContentId:h.id,similarityScore:1,matchType:"exact",confidence:1};let i=await this.findUrlMatch(c,a.id);if(i)return{isDuplicate:!0,originalContentId:i.id,similarityScore:j.URL_SIMILARITY_THRESHOLD,matchType:"url",confidence:.95};if(a.content_image_url){let b=await this.findImageMatch(d,a.id);if(b)return{isDuplicate:!0,originalContentId:b.id,similarityScore:j.IMAGE_SIMILARITY_THRESHOLD,matchType:"image",confidence:.9}}if(a.content_video_url){let b=await this.findVideoMatch(g,a.id);if(b)return{isDuplicate:!0,originalContentId:b.id,similarityScore:j.VIDEO_SIMILARITY_THRESHOLD,matchType:"video",confidence:.9}}let k=await this.findFuzzyMatches(a);if(k.length>0){let a=k[0];if(a.similarity>=j.FUZZY_MATCH_THRESHOLD)return{isDuplicate:!0,originalContentId:a.contentId,similarityScore:a.similarity,matchType:"fuzzy",confidence:a.similarity}}return await (0,e.rP)(f.$b.INFO,"No duplicates found","DuplicateDetectionService",{contentId:a.id}),{isDuplicate:!1,similarityScore:0,matchType:"none",confidence:0}}catch(b){return await (0,e.rP)(f.$b.ERROR,"Duplicate detection failed","DuplicateDetectionService",{contentId:a.id,error:b instanceof Error?b.message:"Unknown error"}),{isDuplicate:!1,similarityScore:0,matchType:"none",confidence:0}}}async findSimilarContent(a,b=10){try{let c=await this.getContentById(a);if(!c)return[];return(await this.findFuzzyMatches(c,b)).map(a=>({contentId:a.contentId,similarity:a.similarity,matchType:a.matchType,matchedField:a.matchType}))}catch(b){return await (0,e.rP)(f.$b.ERROR,"Failed to find similar content","DuplicateDetectionService",{contentId:a,error:b instanceof Error?b.message:"Unknown error"}),[]}}async getDuplicateClusters(a=50){try{return(await e.db.query(`
        SELECT 
          ca.duplicate_of as original_id,
          array_agg(ca.content_queue_id) as duplicate_ids,
          count(ca.content_queue_id) as cluster_size,
          avg(ca.confidence_score) as avg_similarity,
          min(ca.created_at) as created_at
        FROM content_analysis ca
        WHERE ca.duplicate_of IS NOT NULL
        GROUP BY ca.duplicate_of
        HAVING count(ca.content_queue_id) > 1
        ORDER BY count(ca.content_queue_id) DESC, min(ca.created_at) DESC
        LIMIT $1
      `,[a])).rows.map(a=>({originalId:a.original_id,duplicateIds:a.duplicate_ids,clusterSize:parseInt(a.cluster_size),similarity:parseFloat(a.avg_similarity),createdAt:new Date(a.created_at)}))}catch(a){return await (0,e.rP)(f.$b.ERROR,"Failed to get duplicate clusters","DuplicateDetectionService",{error:a instanceof Error?a.message:"Unknown error"}),[]}}async cleanupDuplicates(a=!0){try{let b=await this.getDuplicateClusters(1e3),c=[],d=0;for(let f of b)try{a||await e.db.query("DELETE FROM content_queue WHERE id = ANY($1)",[f.duplicateIds]),d+=f.duplicateIds.length}catch(a){c.push(`Failed to cleanup cluster ${f.originalId}: ${a instanceof Error?a.message:"Unknown error"}`)}return await (0,e.rP)(f.$b.INFO,`Duplicate cleanup ${a?"simulation":"execution"} completed`,"DuplicateDetectionService",{clustersFound:b.length,duplicatesRemoved:d,errors:c.length,dryRun:a}),{clustersFound:b.length,duplicatesRemoved:d,errors:c}}catch(a){return await (0,e.rP)(f.$b.ERROR,"Duplicate cleanup failed","DuplicateDetectionService",{error:a instanceof Error?a.message:"Unknown error"}),{clustersFound:0,duplicatesRemoved:0,errors:[a instanceof Error?a.message:"Unknown error"]}}}async findExactMatch(a,b){let c=await e.db.query(`SELECT cq.* FROM content_queue cq
       WHERE cq.content_hash = $1 
       AND ($2 IS NULL OR cq.id != $2)
       ORDER BY cq.created_at ASC
       LIMIT 1`,[a,b]);return c.rows.length>0?c.rows[0]:null}async findUrlMatch(a,b){let c=await e.db.query(`SELECT cq.* FROM content_queue cq
       WHERE MD5(cq.original_url) = $1 
       AND ($2 IS NULL OR cq.id != $2)
       ORDER BY cq.created_at ASC
       LIMIT 1`,[a,b]);return c.rows.length>0?c.rows[0]:null}async findImageMatch(a,b){let c=await e.db.query(`SELECT cq.* FROM content_queue cq
       WHERE MD5(cq.content_image_url) = $1 
       AND cq.content_image_url IS NOT NULL
       AND ($2 IS NULL OR cq.id != $2)
       ORDER BY cq.created_at ASC
       LIMIT 1`,[a,b]);return c.rows.length>0?c.rows[0]:null}async findVideoMatch(a,b){let c=await e.db.query(`SELECT cq.* FROM content_queue cq
       WHERE MD5(cq.content_video_url) = $1 
       AND cq.content_video_url IS NOT NULL
       AND ($2 IS NULL OR cq.id != $2)
       ORDER BY cq.created_at ASC
       LIMIT 1`,[a,b]);return c.rows.length>0?c.rows[0]:null}async findFuzzyMatches(a,b=10){if(!a.content_text||a.content_text.length<20)return[];this.generateFuzzyHash(a);let c=this.normalizeText(a.content_text),d=await e.db.query(`SELECT cq.*, ca.similarity_hash
       FROM content_queue cq
       LEFT JOIN content_analysis ca ON cq.id = ca.content_queue_id
       WHERE cq.content_text IS NOT NULL
       AND cq.id != $1
       AND length(cq.content_text) > 20
       ORDER BY cq.created_at DESC
       LIMIT 200`,[a.id]),f=[];for(let a of d.rows){let b=this.normalizeText(a.content_text),d=this.calculateTextSimilarity(c,b);d>=.7&&f.push({contentId:a.id,similarity:d,matchType:"text"})}return f.sort((a,b)=>b.similarity-a.similarity),f.slice(0,b)}async getContentById(a){let b=await e.db.query("SELECT * FROM content_queue WHERE id = $1",[a]);return b.rows.length>0?b.rows[0]:null}generateExactHash(a){let b=[a.content_text||"",a.content_image_url||"",a.content_video_url||"",a.original_url||""].join("|");return h().createHash("sha256").update(b).digest("hex")}generateFuzzyHash(a){let b=[this.normalizeText(a.content_text||""),a.content_image_url||"",a.content_video_url||""].join("|");return h().createHash("md5").update(b).digest("hex")}generateUrlHash(a){return h().createHash("md5").update(a.original_url||"").digest("hex")}generateImageHash(a){return h().createHash("md5").update(a.content_image_url||"").digest("hex")}generateVideoHash(a){return h().createHash("md5").update(a.content_video_url||"").digest("hex")}normalizeText(a){return a.toLowerCase().replace(/[^\w\s]/g,"").replace(/\s+/g," ").trim()}calculateTextSimilarity(a,b){if(!a||!b)return 0;if(a===b)return 1;let c=new Set(a.split(/\s+/)),d=new Set(b.split(/\s+/)),e=new Set([...c].filter(a=>d.has(a))),f=new Set([...c,...d]);return e.size/f.size}levenshteinDistance(a,b){let c=[],d=a.length,e=b.length;for(let a=0;a<=d;a++)c[a]=[a];for(let a=0;a<=e;a++)c[0][a]=a;for(let f=1;f<=d;f++)for(let d=1;d<=e;d++)a.charAt(f-1)===b.charAt(d-1)?c[f][d]=c[f-1][d-1]:c[f][d]=Math.min(c[f-1][d-1]+1,c[f][d-1]+1,c[f-1][d]+1);return c[d][e]}calculateLevenshteinSimilarity(a,b){let c=Math.max(a.length,b.length);if(0===c)return 1;let d=this.levenshteinDistance(a,b);return(c-d)/c}}let k=new j;d()}catch(a){d(a)}})}};