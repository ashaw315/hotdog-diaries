[
  {
    "file": ".github/workflows/auto-approve.yml",
    "name": "Auto-Approve Content",
    "on": {
      "schedule": [
        {
          "cron": "0 */6 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "force_approval": {
            "description": "Force approval of more content",
            "required": false,
            "default": "false",
            "type": "boolean"
          },
          "max_items": {
            "description": "Maximum items to approve",
            "required": false,
            "default": "200",
            "type": "string"
          },
          "min_confidence": {
            "description": "Minimum confidence score",
            "required": false,
            "default": "0.4",
            "type": "string"
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "auto-approve",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Check Auto-Approval Status",
            "uses": "",
            "run": "echo \"🔍 Checking auto-approval candidates...\"\n\nresponse=$(curl -L -s -w \"%{http_code}\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  \"${{ secrets.SITE_URL }}/api/admin/auto-approve\")\n\nhttp_code=\"${response: -3}\"\nbody=\"${response%???}\"\n\nif [ \"$http_code\" = \"200\" ]; then\n  echo \"✅ Status check successful\"\n  echo \"$body\" | jq -r '.estimation.recommendedAction // \"No action needed\"'\n  \n  # Extract candidate count for decision making\n  candidates=$(echo \"$body\" | jq -r '.totalCandidates // 0')\n  echo \"candidates=$candidates\" >> $GITHUB_OUTPUT\n  \n  echo \"📊 Found $candidates approval candidates\"\nelse\n  echo \"❌ Status check failed with code $http_code\"\n  echo \"$body\"\n  exit 1\nfi\n"
          },
          {
            "name": "Run Auto-Approval",
            "uses": "",
            "run": "echo \"🤖 Running auto-approval process...\"\n\n# Set parameters from workflow inputs or defaults\nFORCE_APPROVAL=\"${{ github.event.inputs.force_approval || 'false' }}\"\nMAX_ITEMS=\"${{ github.event.inputs.max_items || '200' }}\"\nMIN_CONFIDENCE=\"${{ github.event.inputs.min_confidence || '0.4' }}\"\n\necho \"⚙️ Parameters: force=$FORCE_APPROVAL, max=$MAX_ITEMS, min_confidence=$MIN_CONFIDENCE\"\n\nresponse=$(curl -L -s -w \"%{http_code}\" \\\n  -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -d \"{\n    \\\"forceApproval\\\": $FORCE_APPROVAL,\n    \\\"maxItems\\\": $MAX_ITEMS,\n    \\\"minConfidenceScore\\\": $MIN_CONFIDENCE\n  }\" \\\n  \"${{ secrets.SITE_URL }}/api/admin/auto-approve\")\n\nhttp_code=\"${response: -3}\"\nbody=\"${response%???}\"\n\nif [ \"$http_code\" = \"200\" ]; then\n  echo \"✅ Auto-approval completed successfully\"\n  echo \"$body\" | jq -r '.message'\n  \n  # Extract results for reporting\n  total_approved=$(echo \"$body\" | jq -r '.approvalResults.total // 0')\n  days_of_content=$(echo \"$body\" | jq -r '.updatedStats.daysOfContent // 0')\n  \n  echo \"📊 Results:\"\n  echo \"  • Total approved: $total_approved items\"\n  echo \"  • Days of content remaining: $days_of_content days\"\n  echo \"  • Breakdown: $(echo \"$body\" | jq -c '.approvalResults')\"\n  \n  # Check if we need alerts\n  if [ \"$days_of_content\" -lt 7 ]; then\n    echo \"⚠️ WARNING: Only $days_of_content days of content remaining!\"\n    echo \"::warning title=Low Content Buffer::Only $days_of_content days of content remaining. Consider running emergency scan.\"\n  fi\nelse\n  echo \"❌ Auto-approval failed with code $http_code\"\n  echo \"$body\"\n  echo \"::error title=Auto-Approval Failed::Auto-approval process failed with HTTP $http_code\"\n  exit 1\nfi\n"
          },
          {
            "name": "Skip Auto-Approval",
            "uses": "",
            "run": "echo \"✅ Auto-approval not needed\"\necho \"📊 Only ${{ steps.check-status.outputs.candidates }} candidates found (threshold: 20)\"\necho \"🎯 System is healthy - maintaining current approval levels\"\n"
          },
          {
            "name": "Verify Content Pipeline Health",
            "uses": "",
            "run": "echo \"🏥 Checking overall content pipeline health...\"\n\nresponse=$(curl -L -s -w \"%{http_code}\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  \"${{ secrets.SITE_URL }}/api/admin/automation-health\")\n\nhttp_code=\"${response: -3}\"\nbody=\"${response%???}\"\n\nif [ \"$http_code\" = \"200\" ]; then\n  overall_health=$(echo \"$body\" | jq -r '.overallHealth // \"unknown\"')\n  days_remaining=$(echo \"$body\" | jq -r '.contentSummary.daysRemaining // 0')\n  \n  echo \"📊 Overall Health: $overall_health\"\n  echo \"📅 Days Remaining: $days_remaining\"\n  \n  # Set workflow status based on health\n  case \"$overall_health\" in\n    \"critical\")\n      echo \"::error title=Critical Content Health::Content pipeline is in critical state\"\n      ;;\n    \"warning\") \n      echo \"::warning title=Content Health Warning::Content pipeline needs attention\"\n      ;;\n    \"healthy\")\n      echo \"✅ Content pipeline is healthy\"\n      ;;\n  esac\n  \n  # Output recommendations\n  recommendations=$(echo \"$body\" | jq -r '.recommendations[]?' 2>/dev/null || echo \"No specific recommendations\")\n  if [ \"$recommendations\" != \"No specific recommendations\" ]; then\n    echo \"💡 Recommendations:\"\n    echo \"$body\" | jq -r '.recommendations[]' | sed 's/^/  • /'\n  fi\nelse\n  echo \"⚠️ Could not verify pipeline health (HTTP $http_code)\"\nfi\n"
          },
          {
            "name": "Report Summary",
            "uses": "",
            "run": "echo \"📋 Auto-Approval Workflow Summary\"\necho \"=================================\"\necho \"⏰ Triggered: $(date -u)\"\necho \"🎯 Trigger: ${{ github.event_name }}\"\necho \"🏗️ Environment: $([ '${{ github.event_name }}' = 'workflow_dispatch' ] && echo 'Manual' || echo 'Scheduled')\"\necho \"📊 Candidates checked: ${{ steps.check-status.outputs.candidates || 'N/A' }}\"\necho \"✅ Workflow completed successfully\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.SITE_URL }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/auto-queue-manager.yml",
    "name": "Auto Queue Manager",
    "on": {
      "schedule": [
        {
          "cron": "0 */6 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "mode": {
            "description": "Scan mode",
            "required": false,
            "default": "auto",
            "type": "choice",
            "options": [
              "auto",
              "emergency",
              "status-only"
            ]
          },
          "force": {
            "description": "Force scan regardless of recommendations",
            "required": false,
            "default": false,
            "type": "boolean"
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "refresh-token",
        "steps": [],
        "secretRefs": []
      },
      {
        "jobName": "auto-queue-manager",
        "runsOn": "ubuntu-latest",
        "needs": "refresh-token",
        "steps": [
          {
            "name": "Check Queue Health",
            "uses": "",
            "run": "echo \"🩺 Checking queue health...\"\n\n# Get current queue health status\nHEALTH_RESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L \\\n  \"${{ secrets.SITE_URL }}/api/admin/queue-health\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --retry 2 --retry-delay 5 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$HEALTH_RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$HEALTH_RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"Queue Health HTTP Status: $HTTP_CODE\"\n\nif [[ \"$HTTP_CODE\" == \"200\" ]]; then\n  echo \"✅ Queue health check successful\"\n  \n  # Extract key metrics using jq\n  HEALTH_STATUS=$(echo \"$RESPONSE_BODY\" | jq -r '.health.status // \"unknown\"')\n  DAYS_CONTENT=$(echo \"$RESPONSE_BODY\" | jq -r '.queue.daysOfContent // 0')\n  APPROVED_CONTENT=$(echo \"$RESPONSE_BODY\" | jq -r '.queue.totalApproved // 0')\n  \n  echo \"📊 Queue Status: $HEALTH_STATUS\"\n  echo \"📅 Days of Content: $DAYS_CONTENT\"\n  echo \"✅ Approved Content: $APPROVED_CONTENT\"\n  \n  # Set outputs for next step\n  echo \"health_status=$HEALTH_STATUS\" >> $GITHUB_OUTPUT\n  echo \"days_content=$DAYS_CONTENT\" >> $GITHUB_OUTPUT\n  echo \"approved_content=$APPROVED_CONTENT\" >> $GITHUB_OUTPUT\n  echo \"health_check_success=true\" >> $GITHUB_OUTPUT\nelse\n  echo \"❌ Queue health check failed with HTTP $HTTP_CODE\"\n  echo \"Response: $RESPONSE_BODY\"\n  echo \"health_check_success=false\" >> $GITHUB_OUTPUT\nfi\n"
          },
          {
            "name": "Determine Scan Mode",
            "uses": "",
            "run": "# Get input mode or default to auto\nINPUT_MODE=\"${{ github.event.inputs.mode || 'auto' }}\"\nFORCE_SCAN=\"${{ github.event.inputs.force || 'false' }}\"\n\n# Get health metrics from previous step\nHEALTH_STATUS=\"${{ steps.queue-health.outputs.health_status }}\"\nDAYS_CONTENT=\"${{ steps.queue-health.outputs.days_content }}\"\nAPPROVED_CONTENT=\"${{ steps.queue-health.outputs.approved_content }}\"\n\necho \"🎯 Determining scan mode...\"\necho \"Input mode: $INPUT_MODE\"\necho \"Health status: $HEALTH_STATUS\"\necho \"Days of content: $DAYS_CONTENT\"\necho \"Force scan: $FORCE_SCAN\"\n\n# Determine final scan mode based on health\nFINAL_MODE=\"$INPUT_MODE\"\n\nif [[ \"$HEALTH_STATUS\" == \"emergency\" ]] || [[ \"${APPROVED_CONTENT%.*}\" -eq 0 ]]; then\n  FINAL_MODE=\"emergency\"\n  echo \"🚨 EMERGENCY: Queue is empty - forcing emergency mode\"\nelif [[ \"$HEALTH_STATUS\" == \"critical\" ]] && [[ \"$INPUT_MODE\" == \"auto\" ]]; then\n  FINAL_MODE=\"emergency\" \n  echo \"⚠️ CRITICAL: Queue is very low - upgrading to emergency mode\"\nelif [[ \"$FORCE_SCAN\" == \"true\" ]]; then\n  echo \"🔧 Force scan enabled - proceeding with requested mode\"\nfi\n\necho \"final_mode=$FINAL_MODE\" >> $GITHUB_OUTPUT\necho \"should_scan=true\" >> $GITHUB_OUTPUT\necho \"📋 Final scan mode: $FINAL_MODE\"\n"
          },
          {
            "name": "Execute Auto-Scan",
            "uses": "",
            "run": "SCAN_MODE=\"${{ steps.scan-mode.outputs.final_mode }}\"\n\necho \"🚀 Executing auto-scan with mode: $SCAN_MODE\"\n\n# Build request payload\nif [[ \"$SCAN_MODE\" == \"emergency\" ]]; then\n  PAYLOAD='{\"mode\": \"emergency\"}'\nelif [[ \"$SCAN_MODE\" == \"status-only\" ]]; then\n  PAYLOAD='{\"mode\": \"status-only\"}'\nelse\n  PAYLOAD='{\"mode\": \"auto\"}'\nfi\n\necho \"📤 Request payload: $PAYLOAD\"\n\n# Execute auto-scan\nSCAN_RESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \\\n  \"${{ secrets.SITE_URL }}/api/admin/auto-scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"$PAYLOAD\" \\\n  --retry 3 --retry-delay 10 2>&1 || true)\n\n# Extract results\nHTTP_CODE=$(echo \"$SCAN_RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$SCAN_RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"Auto-Scan HTTP Status: $HTTP_CODE\"\n\nif [[ \"$HTTP_CODE\" == \"200\" ]]; then\n  echo \"✅ Auto-scan completed successfully\"\n  \n  # Extract scan results\n  TRIGGERED=$(echo \"$RESPONSE_BODY\" | jq -r '.summary.totalTriggered // 0')\n  SKIPPED=$(echo \"$RESPONSE_BODY\" | jq -r '.summary.totalSkipped // 0') \n  ERRORS=$(echo \"$RESPONSE_BODY\" | jq -r '.summary.totalErrors // 0')\n  DAYS_AFTER=$(echo \"$RESPONSE_BODY\" | jq -r '.summary.queueDaysAfter // 0')\n  \n  echo \"📊 Scan Results:\"\n  echo \"  - Triggered: $TRIGGERED scans\"\n  echo \"  - Skipped: $SKIPPED scans\"\n  echo \"  - Errors: $ERRORS\"\n  echo \"  - Days of content after: $DAYS_AFTER\"\n  \n  # Show triggered scans\n  TRIGGERED_SCANS=$(echo \"$RESPONSE_BODY\" | jq -r '.triggeredScans[]? // empty')\n  if [[ -n \"$TRIGGERED_SCANS\" ]]; then\n    echo \"🎯 Triggered scans:\"\n    echo \"$TRIGGERED_SCANS\" | sed 's/^/  - /'\n  fi\n  \n  # Show any errors\n  SCAN_ERRORS=$(echo \"$RESPONSE_BODY\" | jq -r '.errors[]? // empty')\n  if [[ -n \"$SCAN_ERRORS\" ]]; then\n    echo \"⚠️ Scan errors:\"\n    echo \"$SCAN_ERRORS\" | sed 's/^/  - /'\n  fi\n  \nelse\n  echo \"❌ Auto-scan failed with HTTP $HTTP_CODE\"\n  echo \"Response: $RESPONSE_BODY\"\n  exit 1\nfi\n"
          },
          {
            "name": "Final Health Check",
            "uses": "",
            "run": "echo \"🔄 Performing final health check...\"\n\n# Brief delay to allow scan results to process\nsleep 30\n\n# Get updated queue health\nFINAL_HEALTH=$(curl -s -L \\\n  \"${{ secrets.SITE_URL }}/api/admin/queue-health\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --retry 2 2>/dev/null | jq -r '.health.status // \"unknown\"')\n\nFINAL_DAYS=$(curl -s -L \\\n  \"${{ secrets.SITE_URL }}/api/admin/queue-health\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --retry 2 2>/dev/null | jq -r '.queue.daysOfContent // 0')\n\necho \"📈 Final queue status: $FINAL_HEALTH\"\necho \"📅 Final days of content: $FINAL_DAYS\"\n\nif [[ \"$FINAL_HEALTH\" == \"healthy\" ]] || [[ \"$FINAL_HEALTH\" == \"warning\" ]]; then\n  echo \"✅ Queue is in acceptable condition\"\nelse\n  echo \"⚠️ Queue still needs attention: $FINAL_HEALTH\"\nfi\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Auto queue manager failed\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets\"\necho \"  2. Verify Vercel deployment status\"\necho \"  3. Check API endpoint availability\"\necho \"  4. Review platform API credentials\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS:\"\necho \"  - Manual content approval may be needed\"\necho \"  - Consider running emergency replenishment\"\necho \"  - Check individual platform scan workflows\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/ci-new.yml",
    "name": "CI Test",
    "on": {
      "push": {
        "branches": [
          "main"
        ]
      }
    },
    "jobs": [
      {
        "jobName": "test",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "steps": [
          {
            "name": "Checkout repository",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Cache node_modules",
            "uses": "actions/cache@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Simple test",
            "uses": "",
            "run": "echo \"✅ CI workflow syntax is working!\""
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/ci-test.yml",
    "name": "CI Test",
    "on": {
      "push": {
        "branches": [
          "main"
        ]
      }
    },
    "jobs": [
      {
        "jobName": "test",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "steps": [
          {
            "name": "Checkout repository",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Cache node_modules",
            "uses": "actions/cache@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Simple test",
            "uses": "",
            "run": "echo \"✅ CI workflow syntax is working!\""
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/ci.yml",
    "name": "CI",
    "on": {
      "push": {
        "branches": [
          "main",
          "develop"
        ]
      },
      "pull_request": {
        "branches": [
          "main"
        ]
      },
      "workflow_call": {
        "inputs": {
          "node-version": {
            "description": "Node.js version to use",
            "type": "string",
            "default": "20"
          },
          "cache-strategy": {
            "description": "Cache strategy for dependencies",
            "type": "string",
            "default": "aggressive"
          }
        },
        "outputs": {
          "test-results": {
            "description": "Test results summary",
            "value": "${{ jobs.test.outputs.results }}"
          }
        }
      }
    },
    "concurrency": {
      "group": "ci-${{ github.ref }}",
      "cancel-in-progress": true
    },
    "jobs": [
      {
        "jobName": "lint",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Install tsx for scripts",
            "uses": "",
            "run": "npm install --no-save tsx"
          },
          {
            "name": "Patch legacy path resolver",
            "uses": "",
            "run": "npx tsx scripts/patchPathResolver.ts"
          },
          {
            "name": "Validate route patterns",
            "uses": "",
            "run": "npx tsx scripts/validateRoutes.ts"
          },
          {
            "name": "Run ESLint",
            "uses": "",
            "run": "echo \"🔍 Running ESLint...\"\n# Run ESLint but don't fail the build on warnings - capture exit code separately\nnpx next lint --max-warnings=2000 2>&1 | tee lint-results.txt\nLINT_EXIT_CODE=${PIPESTATUS[0]}\n\n# Count warnings for reporting\nWARNING_COUNT=$(grep -c \"Warning:\" lint-results.txt || echo \"0\")\necho \"Found $WARNING_COUNT ESLint warnings\"\n\n# Only capture first 100 lines to avoid HEREDOC issues\necho \"lint-output<<EOF\" >> $GITHUB_OUTPUT\nhead -n 100 lint-results.txt >> $GITHUB_OUTPUT\necho \"EOF\" >> $GITHUB_OUTPUT\n\necho \"warning-count=$WARNING_COUNT\" >> $GITHUB_OUTPUT\n\n# Only fail if there are actual ESLint errors (not warnings)\nif [ $LINT_EXIT_CODE -ne 0 ] && grep -q \"Error:\" lint-results.txt; then\n  echo \"❌ ESLint found errors (not just warnings)\"\n  exit 1\nelse\n  echo \"✅ ESLint completed (warnings: $WARNING_COUNT)\"\n  exit 0\nfi\n"
          },
          {
            "name": "Check Prettier formatting",
            "uses": "",
            "run": "echo \"🎨 Checking code formatting...\"\nnpm run format:check || true\n"
          },
          {
            "name": "Upload lint results",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "typecheck",
        "runsOn": "ubuntu-latest",
        "timeout": 8,
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Run TypeScript compiler",
            "uses": "",
            "run": "echo \"🔍 Running TypeScript type checking...\"\nnpm run type-check 2>&1 | tee typecheck-results.txt\necho \"typecheck-output<<EOF\" >> $GITHUB_OUTPUT\ncat typecheck-results.txt >> $GITHUB_OUTPUT\necho \"EOF\" >> $GITHUB_OUTPUT\n"
          },
          {
            "name": "Upload typecheck results",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "test",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "env": {
          "DATABASE_URL_SQLITE": "./test_hotdog_diaries.db",
          "JWT_SECRET": "test-jwt-secret-for-ci"
        },
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Initialize test database",
            "uses": "",
            "run": "echo \"🗄️ Setting up test database...\"\nNODE_ENV=test npx tsx scripts/init-sqlite.ts || echo \"Database init attempted\"\n"
          },
          {
            "name": "Run unit tests",
            "uses": "",
            "run": "echo \"🧪 Running unit tests...\"\n# Run tests but don't fail CI on test failures\nnpm test 2>&1 | tee test-results.txt || true\n\n# Extract test summary\nTESTS_PASSED=$(grep -o \"Tests:.*passed\" test-results.txt | head -1 || echo \"Tests: unknown\")\nTESTS_FAILED=$(grep -o \"Tests:.*failed\" test-results.txt | head -1 || echo \"Tests: unknown\")\nTEST_SUITES=$(grep -o \"Test Suites:.*\" test-results.txt | head -1 || echo \"Test Suites: unknown\")\n\necho \"results=${TESTS_PASSED}\" >> $GITHUB_OUTPUT\necho \"failures=${TESTS_FAILED}\" >> $GITHUB_OUTPUT\necho \"suites=${TEST_SUITES}\" >> $GITHUB_OUTPUT\n\necho \"ℹ️ Test results: ${TEST_SUITES}\"\necho \"ℹ️ Individual tests: ${TESTS_PASSED}, ${TESTS_FAILED}\"\n"
          },
          {
            "name": "Run unit tests with coverage",
            "uses": "",
            "run": "echo \"📊 Running tests with coverage...\"\n# Run coverage but don't fail CI on coverage issues\nnpm run test:coverage || echo \"⚠️ Coverage completed with issues\"\n"
          },
          {
            "name": "Upload test results",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "planner-tests",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "env": {
          "SCAN_MIN_PER_PLATFORM": 40,
          "SCAN_MAX_PER_PLATFORM": 120,
          "SCAN_GLOBAL_MAX": 800,
          "SCAN_COOLDOWN_MIN": 180,
          "MIN_CONF": 0.7,
          "MIN_CANDIDATES": 20,
          "PLATFORM_ALLOW": "reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay"
        },
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Run planner contract tests",
            "uses": "",
            "run": "echo \"🧪 Running demand-driven scanner planner tests...\"\nnpm run test:planner 2>&1 | tee planner-test-results.txt\n\n# Extract test summary\nif grep -q \"tests passed\" planner-test-results.txt; then\n  echo \"✅ Planner tests passed\"\n  echo \"planner-results=passed\" >> $GITHUB_OUTPUT\nelse\n  echo \"❌ Planner tests failed\"\n  echo \"planner-results=failed\" >> $GITHUB_OUTPUT\nfi\n"
          },
          {
            "name": "Upload planner test results",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "security",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Install tsx for scripts",
            "uses": "",
            "run": "npm install --no-save tsx"
          },
          {
            "name": "Audit for legacy dependencies",
            "uses": "",
            "run": "echo \"🔍 Scanning for problematic legacy dependencies...\"\nnpx tsx scripts/findOffender.ts || (echo \"❌ Legacy modules found\" && exit 1)\necho \"✅ Dependency audit passed\"\n"
          },
          {
            "name": "Run security audit",
            "uses": "",
            "run": "echo \"🔒 Running npm security audit...\"\nnpm audit --audit-level=high || echo \"⚠️ Vulnerabilities found - review required\"\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "build",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": [
          "lint",
          "typecheck",
          "planner-tests"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Install tsx for scripts",
            "uses": "",
            "run": "npm install --no-save tsx"
          },
          {
            "name": "Patch legacy path resolver (build phase)",
            "uses": "",
            "run": "npx tsx scripts/patchPathResolver.ts"
          },
          {
            "name": "Validate route patterns (build phase)",
            "uses": "",
            "run": "npx tsx scripts/validateRoutes.ts"
          },
          {
            "name": "Cache Next.js build",
            "uses": "actions/cache@v4"
          },
          {
            "name": "Build application",
            "uses": "",
            "run": "echo \"🏗️ Building application...\"\nnpm run build\n"
          },
          {
            "name": "Verify build artifacts",
            "uses": "",
            "run": "echo \"✅ Verifying build output...\"\nls -la .next/\necho \"Build completed successfully\"\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "auto-healing",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": [
          "lint",
          "typecheck",
          "test",
          "planner-tests",
          "security",
          "build"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Install tsx for scripts",
            "uses": "",
            "run": "npm install --no-save tsx"
          },
          {
            "name": "Run critical failure gatekeeper",
            "uses": "",
            "run": "echo \"🛡️ Running CI Auto-Healing System...\"\nnpx tsx scripts/checkCriticalFailures.ts || GATEKEEPER_EXIT=$?\n\n# Check if auto-fixes were applied\nif [ -f \"reports/ci-health-gate.md\" ]; then\n  AUTO_FIXES=$(grep -c \"Auto-Fixes Applied\" reports/ci-health-gate.md || echo \"0\")\n  echo \"auto-fixes-applied=$AUTO_FIXES\" >> $GITHUB_OUTPUT\n  echo \"✅ Auto-healing analysis completed\"\nelse\n  echo \"auto-fixes-applied=0\" >> $GITHUB_OUTPUT\nfi\n\nexit ${GATEKEEPER_EXIT:-0}\n"
          },
          {
            "name": "Upload healing reports",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "Commit auto-fixes",
            "uses": "",
            "run": "echo \"🔧 Auto-fixes applied, committing changes...\"\ngit config --local user.email \"action@github.com\"\ngit config --local user.name \"GitHub Action Auto-Fix\"\ngit add -A\n\nif ! git diff --staged --quiet; then\n  git commit -m \"fix: auto-fix CI issues\n  \n  - Applied ${{ steps.gatekeeper.outputs.auto-fixes-applied }} automatic fixes\n  - Generated by CI Auto-Healing System\n  \n  [skip ci]\"\n  git push\n  echo \"✅ Auto-fixes committed and pushed\"\nfi\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "summary",
        "runsOn": "ubuntu-latest",
        "needs": [
          "lint",
          "typecheck",
          "test",
          "planner-tests",
          "security",
          "build"
        ],
        "steps": [
          {
            "name": "Generate CI summary",
            "uses": "",
            "run": "echo \"## 🚀 CI Results Summary\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Job | Status | Details |\" >> $GITHUB_STEP_SUMMARY\necho \"|-----|--------|---------|\" >> $GITHUB_STEP_SUMMARY\necho \"| Lint | ${{ needs.lint.result }} | ${{ needs.lint.outputs.lint-status }} |\" >> $GITHUB_STEP_SUMMARY\necho \"| TypeCheck | ${{ needs.typecheck.result }} | ${{ needs.typecheck.outputs.typecheck-status }} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Unit Tests | ${{ needs.test.result }} | ${{ needs.test.outputs.results }} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Planner Tests | ${{ needs.planner-tests.result }} | ${{ needs.planner-tests.outputs.planner-status }} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Security | ${{ needs.security.result }} | Dependency audit |\" >> $GITHUB_STEP_SUMMARY\necho \"| Build | ${{ needs.build.result }} | Build verification |\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Overall status\nif [[ \"${{ needs.lint.result }}\" == \"success\" && \"${{ needs.typecheck.result }}\" == \"success\" && \"${{ needs.test.result }}\" == \"success\" && \"${{ needs.planner-tests.result }}\" == \"success\" && \"${{ needs.security.result }}\" == \"success\" && \"${{ needs.build.result }}\" == \"success\" ]]; then\n  echo \"## ✅ All CI checks passed!\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"## ❌ Some CI checks failed - Auto-healing may have been triggered\" >> $GITHUB_STEP_SUMMARY\nfi\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/cleanup-duplicates.yml",
    "name": "Database Cleanup",
    "on": {
      "schedule": [
        {
          "cron": "0 6 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "dry_run": {
            "description": "Dry run (no actual deletion)",
            "required": false,
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "permissions": {
      "contents": "read"
    },
    "jobs": [
      {
        "jobName": "cleanup-duplicates",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Cleanup Duplicates",
            "uses": "",
            "run": "echo \"🧹 Starting duplicate cleanup...\"\n\n# Call the cleanup API endpoint\nresponse=$(curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/cleanup-duplicates\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"dry_run\": ${{ github.event.inputs.dry_run || false }}}' \\\n  --fail-with-body \\\n  -w \"\\n%{http_code}\")\n\n# Extract HTTP status code\nhttp_code=$(echo \"$response\" | tail -n 1)\nbody=$(echo \"$response\" | head -n -1)\n\necho \"Response: $body\"\n\nif [ \"$http_code\" -ne 200 ]; then\n  echo \"❌ Cleanup failed with status $http_code\"\n  exit 1\nfi\n\necho \"✅ Cleanup completed successfully\"\n"
          },
          {
            "name": "Check Duplicate Status",
            "uses": "",
            "run": "echo \"📊 Checking for remaining duplicates...\"\n\n# Call the monitor endpoint\nresponse=$(curl -L -X GET \"${{ secrets.SITE_URL }}/api/admin/monitor/duplicates\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --fail-with-body)\n\necho \"Duplicate status: $response\"\n\n# Parse response and check if duplicates exist\nif echo \"$response\" | grep -q '\"duplicates_found\":0'; then\n  echo \"✅ No duplicates found\"\nelse\n  echo \"⚠️  Some duplicates may still exist\"\nfi\n"
          },
          {
            "name": "Log Failure Details",
            "uses": "",
            "run": "echo \"🚨 Duplicate cleanup job failed at $(date)\"\necho \"Check the workflow logs for details\"\necho \"Workflow run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "sync-posted-flags",
        "runsOn": "ubuntu-latest",
        "needs": "cleanup-duplicates",
        "steps": [
          {
            "name": "Sync is_posted Flags",
            "uses": "",
            "run": "echo \"🔄 Syncing is_posted flags...\"\n\nresponse=$(curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/sync/posted-flags\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --fail-with-body)\n\necho \"Sync response: $response\"\necho \"✅ Sync completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/daily-ingestion-report.yml",
    "name": "Daily Ingestion Balance Report",
    "on": {
      "schedule": [
        {
          "cron": "0 9 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "format": {
            "description": "Output format",
            "required": false,
            "default": "table",
            "type": "choice",
            "options": [
              "table",
              "json"
            ]
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "ingestion-report",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Generate Ingestion Balance Report",
            "uses": "",
            "run": "if [ \"${{ github.event.inputs.format }}\" = \"json\" ]; then\n  npx tsx scripts/ingestion-balance-report.ts --format=json\nelse\n  npx tsx scripts/ingestion-balance-report.ts\nfi\n"
          },
          {
            "name": "Check Alert Thresholds",
            "uses": "",
            "run": "npx tsx scripts/ingestion-balance-report.ts --alert-thresholds"
          },
          {
            "name": "Create Issue on Alerts",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/daily-report.yml",
    "name": "Daily Summary Report",
    "on": {
      "schedule": [
        {
          "cron": "0 0 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "generate-report",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Generate Daily Report",
            "uses": "",
            "run": "echo \"📊 Generating daily summary report...\"\n\n# Get comprehensive stats from schedule endpoint\nSTATS=$(curl -s \"${{ secrets.SITE_URL }}/api/admin/schedule\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Accept: application/json\")\n\nif [ $? -ne 0 ]; then\n  echo \"❌ Failed to fetch daily stats\"\n  exit 1\nfi\n\n# Extract key metrics\nPOSTS_TODAY=$(echo \"$STATS\" | jq -r '.stats.todaysPosts // 0')\nQUEUE_SIZE=$(echo \"$STATS\" | jq -r '.queueStatus.totalPosted // 0')\nAPPROVED=$(echo \"$STATS\" | jq -r '.queueStatus.totalApproved // 0')\nDAYS_LEFT=$(echo \"scale=1; $APPROVED / 6\" | bc -l)\n\n# Get posting schedule status\nSCHEDULE=$(curl -s \"${{ secrets.SITE_URL }}/api/admin/schedule\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\")\n\nMISSED_POSTS=$(echo \"$SCHEDULE\" | jq -r '[.schedule.todaysSchedule[] | select(.posted == false and (.time | strptime(\"%H:%M\") | mktime) < now)] | length')\n\necho \"📈 Daily Report Generated:\"\necho \"  Posts Today: $POSTS_TODAY\"\necho \"  Missed Posts: $MISSED_POSTS\"\necho \"  Queue Size: $QUEUE_SIZE\"\necho \"  Approved: $APPROVED\"\necho \"  Days of Content: $DAYS_LEFT\"\n\n# Save report to file\ncat << EOF > daily-report.md\n# Hotdog Diaries Daily Report\n**Date:** $(date -u +\"%Y-%m-%d\")\n\n## 📊 Performance Metrics\n- **Posts Today:** $POSTS_TODAY / 6 expected\n- **Missed Posts:** $MISSED_POSTS\n- **Success Rate:** $(echo \"scale=1; $POSTS_TODAY * 100 / 6\" | bc -l)%\n\n## 📦 Content Queue Status\n- **Total Items:** $QUEUE_SIZE\n- **Approved & Ready:** $APPROVED\n- **Days of Content:** $DAYS_LEFT days\n- **Health Status:** $([ $(echo \"$DAYS_LEFT > 3\" | bc -l) -eq 1 ] && echo \"✅ Healthy\" || echo \"⚠️ Low\")\n\n## 🔧 Recommended Actions\n$(if [ $MISSED_POSTS -gt 0 ]; then echo \"- 🚨 **URGENT:** Run catch-up posting for $MISSED_POSTS missed meals\"; fi)\n$(if [ $(echo \"$DAYS_LEFT < 3\" | bc -l) -eq 1 ]; then echo \"- 📡 **HIGH PRIORITY:** Emergency content scanning needed\"; fi)\n$(if [ $(echo \"$DAYS_LEFT < 7\" | bc -l) -eq 1 ]; then echo \"- 🔍 **NORMAL:** Schedule regular c"
          },
          {
            "name": "Check for Critical Issues",
            "uses": "",
            "run": "echo \"🚨 Checking for critical issues...\"\n\nSTATS=$(curl -s \"${{ secrets.SITE_URL }}/api/admin/schedule\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\")\n\nAPPROVED=$(echo \"$STATS\" | jq -r '.queueStatus.totalApproved // 0')\nDAYS_LEFT=$(echo \"scale=1; $APPROVED / 6\" | bc -l)\n\n# Check if we need immediate action\nif [ $(echo \"$DAYS_LEFT < 1\" | bc -l) -eq 1 ]; then\n  echo \"🚨 CRITICAL ALERT: Less than 1 day of content remaining!\"\n  echo \"Triggering emergency scan workflow...\"\n  \n  # Could trigger emergency scan here\n  curl -X POST \\\n    -H \"Authorization: token ${{ secrets.GITHUB_TOKEN }}\" \\\n    -H \"Accept: application/vnd.github.v3+json\" \\\n    \"https://api.github.com/repos/${{ github.repository }}/actions/workflows/queue-monitor.yml/dispatches\" \\\n    -d '{\"ref\":\"main\"}'\n  \nelif [ $(echo \"$DAYS_LEFT < 3\" | bc -l) -eq 1 ]; then\n  echo \"⚠️ WARNING: Less than 3 days of content remaining\"\n  \nelse\n  echo \"✅ Queue status is acceptable ($DAYS_LEFT days)\"\nfi\n"
          },
          {
            "name": "Archive Report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.GITHUB_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/deploy-gate.yml",
    "name": "Deploy Gate",
    "on": {
      "deployment_status": null,
      "push": {
        "branches": [
          "main"
        ]
      },
      "workflow_run": {
        "workflows": [
          "Vercel Production Deployment"
        ],
        "types": [
          "completed"
        ]
      }
    },
    "permissions": {
      "contents": "read",
      "issues": "write"
    },
    "jobs": [
      {
        "jobName": "auth-token-validation",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Wait for deployment",
            "uses": "",
            "run": "echo \"⏳ Waiting for deployment to be available...\"\nsleep 30\n"
          },
          {
            "name": "Test health probe with valid token",
            "uses": "",
            "run": "echo \"🔍 Testing auth token health probe...\"\n\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  \"${{ env.PROD_URL }}/api/admin/health/auth-token\")\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"HTTP Status: $HTTP_STATUS\"\necho \"Response Body: $BODY\"\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Auth token validation passed\"\n  \n  # Verify response contains success code\n  if echo \"$BODY\" | jq -e '.code == \"AUTH_TOKEN_VALID\"' > /dev/null; then\n    echo \"✅ Response contains valid success code\"\n  else\n    echo \"❌ Response missing valid success code\"\n    exit 1\n  fi\nelse\n  echo \"❌ Auth token validation failed with status $HTTP_STATUS\"\n  \n  # Check if it's an auth mismatch\n  if [ \"$HTTP_STATUS\" -eq 401 ]; then\n    CODE=$(echo \"$BODY\" | jq -r '.code // \"unknown\"')\n    if [ \"$CODE\" = \"AUTH_TOKEN_MISMATCH\" ]; then\n      echo \"🚨 AUTH_TOKEN_MISMATCH detected - deployment blocked!\"\n      echo \"The AUTH_TOKEN secret may be incorrect or expired.\"\n    fi\n  fi\n  \n  exit 1\nfi\n"
          },
          {
            "name": "Test health probe with invalid token",
            "uses": "",
            "run": "echo \"🧪 Testing auth token health probe with invalid token...\"\n\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer invalid-token-12345\" \\\n  \"${{ env.PROD_URL }}/api/admin/health/auth-token\")\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"HTTP Status: $HTTP_STATUS\"\necho \"Response Body: $BODY\"\n\nif [ \"$HTTP_STATUS\" -eq 401 ]; then\n  echo \"✅ Invalid token correctly rejected\"\n  \n  # Verify response contains mismatch code\n  CODE=$(echo \"$BODY\" | jq -r '.code // \"unknown\"')\n  if [ \"$CODE\" = \"AUTH_TOKEN_MISMATCH\" ]; then\n    echo \"✅ Response contains correct error code: AUTH_TOKEN_MISMATCH\"\n  else\n    echo \"⚠️ Response contains unexpected error code: $CODE\"\n  fi\nelse\n  echo \"❌ Invalid token should have been rejected with 401\"\n  exit 1\nfi\n"
          },
          {
            "name": "Test health probe without token",
            "uses": "",
            "run": "echo \"🧪 Testing auth token health probe without token...\"\n\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  \"${{ env.PROD_URL }}/api/admin/health/auth-token\")\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"HTTP Status: $HTTP_STATUS\"\necho \"Response Body: $BODY\"\n\nif [ \"$HTTP_STATUS\" -eq 401 ]; then\n  echo \"✅ Missing token correctly rejected\"\n  \n  # Verify response contains missing token code\n  CODE=$(echo \"$BODY\" | jq -r '.code // \"unknown\"')\n  if [ \"$CODE\" = \"AUTH_TOKEN_MISSING\" ]; then\n    echo \"✅ Response contains correct error code: AUTH_TOKEN_MISSING\"\n  else\n    echo \"⚠️ Response contains unexpected error code: $CODE\"\n  fi\nelse\n  echo \"❌ Missing token should have been rejected with 401\"\n  exit 1\nfi\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "comprehensive-health-check",
        "runsOn": "ubuntu-latest",
        "needs": "auth-token-validation",
        "steps": [
          {
            "name": "Deep health check",
            "uses": "",
            "run": "echo \"🏥 Running comprehensive health validation...\"\n\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  \"${{ env.PROD_URL }}/api/admin/health/deep\")\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"HTTP Status: $HTTP_STATUS\"\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Deep health check passed\"\n  \n  # Verify response structure\n  OK_STATUS=$(echo \"$BODY\" | jq -r '.ok // false')\n  if [ \"$OK_STATUS\" = \"true\" ]; then\n    echo \"✅ Health status is OK\"\n    \n    # Show component health\n    echo \"📊 Component Health:\"\n    echo \"$BODY\" | jq '.components // {}' || echo \"No component details available\"\n    \n  else\n    echo \"❌ Health status indicates issues\"\n    echo \"$BODY\" | jq '.components // {}' || echo \"No component details available\"\n    exit 1\n  fi\nelse\n  echo \"❌ Deep health check failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\n  exit 1\nfi\n"
          },
          {
            "name": "Admin endpoint smoke test",
            "uses": "",
            "run": "echo \"💨 Running admin endpoint smoke test...\"\n\n# Test a few critical admin endpoints\nENDPOINTS=(\n  \"/api/admin/dashboard/stats\"\n  \"/api/admin/queue/health\"\n  \"/api/admin/platforms/status\"\n)\n\nfor ENDPOINT in \"${ENDPOINTS[@]}\"; do\n  echo \"Testing $ENDPOINT...\"\n  \n  RESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n    -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n    \"${{ env.PROD_URL }}$ENDPOINT\")\n  \n  HTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\n  \n  if [ \"$HTTP_STATUS\" -eq 200 ]; then\n    echo \"✅ $ENDPOINT responding\"\n  else\n    echo \"❌ $ENDPOINT failed with status $HTTP_STATUS\"\n    # Don't fail the entire gate for individual endpoint issues\n    # Just log them for monitoring\n  fi\ndone\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "deployment-gate-result",
        "runsOn": "ubuntu-latest",
        "needs": [
          "auth-token-validation",
          "comprehensive-health-check"
        ],
        "steps": [
          {
            "name": "Check gate results",
            "uses": "",
            "run": "echo \"🚪 Deployment Gate Results\"\necho \"==========================\"\n\nAUTH_RESULT=\"${{ needs.auth-token-validation.result }}\"\nHEALTH_RESULT=\"${{ needs.comprehensive-health-check.result }}\"\n\necho \"Auth Token Validation: $AUTH_RESULT\"\necho \"Health Check: $HEALTH_RESULT\"\n\nif [ \"$AUTH_RESULT\" = \"success\" ] && [ \"$HEALTH_RESULT\" = \"success\" ]; then\n  echo \"\"\n  echo \"✅ DEPLOYMENT GATE PASSED\"\n  echo \"All security and health validations successful.\"\n  echo \"Deployment is approved for production traffic.\"\nelse\n  echo \"\"\n  echo \"❌ DEPLOYMENT GATE FAILED\"\n  echo \"Security or health validations failed.\"\n  echo \"Deployment should be rolled back or investigated.\"\n  exit 1\nfi\n"
          },
          {
            "name": "✅ Deployment Success",
            "uses": "",
            "run": "echo \"🎉 DEPLOYMENT GATE PASSED\"\necho \"=========================\"\necho \"✅ Auth Token Validation: Success\"\necho \"✅ Comprehensive Health Check: Success\"\necho \"✅ Admin Endpoint Smoke Test: Success\"\necho \"\"\necho \"🚀 Deployment approved for production traffic\"\necho \"🌐 Production URL: ${{ env.PROD_URL }}\"\necho \"🏥 Health Probe: ${{ env.PROD_URL }}/api/admin/health/auth-token\"\necho \"\"\necho \"## 🎉 Deployment Gate Success\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Deployment**: \\`${{ github.sha }}\\`\" >> $GITHUB_STEP_SUMMARY\necho \"**Timestamp**: $(date -u -Iseconds)\" >> $GITHUB_STEP_SUMMARY\necho \"**Environment**: Production\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### ✅ Validation Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"- ✅ **Auth Token Validation**: Passed\" >> $GITHUB_STEP_SUMMARY\necho \"- ✅ **Comprehensive Health Check**: Passed\" >> $GITHUB_STEP_SUMMARY\necho \"- ✅ **Admin Endpoint Smoke Test**: Passed\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"🚀 All security and health validations passed - deployment approved!\" >> $GITHUB_STEP_SUMMARY\n"
          },
          {
            "name": "Create deployment failure issue",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/deployment-gate.yml",
    "name": "🚪 Deployment Gate",
    "on": {
      "workflow_dispatch": {
        "inputs": {
          "target_url": {
            "description": "Deployment base URL (e.g. https://hotdog-diaries.vercel.app)",
            "required": false,
            "type": "string"
          }
        }
      },
      "deployment_status": null,
      "workflow_call": {
        "inputs": {
          "target_url": {
            "description": "Deployment base URL",
            "required": false,
            "type": "string"
          }
        },
        "secrets": {
          "AUTH_TOKEN": {
            "description": "Admin authentication token",
            "required": true
          }
        }
      }
    },
    "permissions": {
      "contents": "read"
    },
    "jobs": [
      {
        "jobName": "gate",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "env": {
          "TARGET_URL": "${{ inputs.target_url || github.event.deployment_status.environment_url || vars.SITE_URL || secrets.SITE_URL }}",
          "AUTH_TOKEN": "${{ secrets.AUTH_TOKEN }}"
        },
        "steps": [
          {
            "name": "🧪 Preflight Validation",
            "uses": "",
            "run": "set -euo pipefail\necho \"🔍 Validating deployment gate requirements...\"\necho \"Event: ${{ github.event_name }}\"\necho \"Environment URL: ${{ github.event.deployment_status.environment_url || 'none' }}\"\necho \"Target URL: ${TARGET_URL:-<empty>}\"\n\nmissing=0\nif [ -z \"${TARGET_URL:-}\" ]; then\n  echo \"::error title=Missing Target URL::No TARGET_URL available. Provide 'inputs.target_url' OR set repository variable 'SITE_URL' OR ensure 'deployment_status.environment_url' is present.\"\n  missing=1\nfi\n\nif [ -z \"${AUTH_TOKEN:-}\" ]; then\n  echo \"::error title=Missing Auth Token::AUTH_TOKEN secret not configured. Add repository secret AUTH_TOKEN with admin JWT token.\"\n  missing=1\nfi\n\nif [ \"$missing\" -ne 0 ]; then\n  echo \"❌ Preflight failed — required context not available.\"\n  echo \"::error::Deployment gate cannot proceed without TARGET_URL and AUTH_TOKEN\"\n  exit 1\nfi\n\necho \"✅ Preflight validation passed\"\necho \"🎯 Target: ${TARGET_URL}\"\n"
          },
          {
            "name": "🔐 Authentication Validation",
            "uses": "",
            "run": "set -euo pipefail\necho \"🔐 Validating admin authentication token...\"\n\nresponse=$(curl -fsS --retry 3 --retry-delay 2 --retry-connrefused -w \"HTTP_CODE:%{http_code}\" \\\n  -H \"x-admin-token: ${AUTH_TOKEN}\" \\\n  -H \"Authorization: Bearer ${AUTH_TOKEN}\" \\\n  \"${TARGET_URL}/api/admin/health/auth-token\")\n\nhttp_code=$(echo \"$response\" | grep -o \"HTTP_CODE:[0-9]*\" | cut -d: -f2)\nbody=$(echo \"$response\" | sed 's/HTTP_CODE:[0-9]*$//')\n\nif [ \"$http_code\" != \"200\" ]; then\n  echo \"❌ Auth validation failed with HTTP $http_code\"\n  echo \"Response: $body\"\n  exit 1\nfi\n\necho \"✅ Authentication token valid\"\necho \"$body\" | jq . || echo \"$body\"\n"
          },
          {
            "name": "💚 Deep Health Check",
            "uses": "",
            "run": "set -euo pipefail\necho \"💚 Running comprehensive system health check...\"\n\nresponse=$(curl -fsS --retry 3 --retry-delay 2 --retry-connrefused -w \"HTTP_CODE:%{http_code}\" \\\n  -H \"x-admin-token: ${AUTH_TOKEN}\" \\\n  -H \"Authorization: Bearer ${AUTH_TOKEN}\" \\\n  \"${TARGET_URL}/api/admin/health/deep\")\n\nhttp_code=$(echo \"$response\" | grep -o \"HTTP_CODE:[0-9]*\" | cut -d: -f2)\nbody=$(echo \"$response\" | sed 's/HTTP_CODE:[0-9]*$//')\n\nif [ \"$http_code\" != \"200\" ]; then\n  echo \"❌ Health check failed with HTTP $http_code\"\n  echo \"Response: $body\"\n  exit 1\nfi\n\necho \"✅ Deep health check passed\"\necho \"$body\" | jq '{\n  database: .database.status,\n  apis: (.apis | length),\n  scheduler: .scheduler.status,\n  overall: .status\n}' || echo \"$body\"\n"
          },
          {
            "name": "✅ Gate Summary",
            "uses": "",
            "run": "echo \"## 🚪 Deployment Gate Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Check | Status |\" >> $GITHUB_STEP_SUMMARY\necho \"|-------|--------|\" >> $GITHUB_STEP_SUMMARY\necho \"| Auth Token | ${{ steps.auth.outcome == 'success' && '✅ Valid' || '❌ Failed' }} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Health Check | ${{ steps.health.outcome == 'success' && '✅ Healthy' || '❌ Failed' }} |\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Target:** \\`${TARGET_URL}\\`\" >> $GITHUB_STEP_SUMMARY\n\necho \"🚪 Deployment Gate Results\"\necho \"==========================\"\necho \"Auth Token Validation: ${{ steps.auth.outcome }}\"\necho \"Health Check:          ${{ steps.health.outcome }}\"\n"
          },
          {
            "name": "❌ Fail on Security or Health Issues",
            "uses": "",
            "run": "echo \"❌ DEPLOYMENT GATE FAILED\"\necho \"Security or health validations failed - deployment blocked\"\necho \"::error title=Gate Failed::One or more security/health checks failed\"\nexit 1\n"
          },
          {
            "name": "🎉 Gate Success",
            "uses": "",
            "run": "echo \"🎉 DEPLOYMENT GATE PASSED\"\necho \"All security and health validations successful\"\necho \"Deployment is cleared to proceed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/e2e.yml",
    "parseError": "YAMLException: can not read an implicit mapping pair; a colon is missed (134:13)\n\n 131 |         browser: ${{ fromJSON(\n 132 |           needs.should-run.outputs.browser  ...\n 133 |           format('[\"{0}\"]', needs.should-ru ...\n 134 |         ) }}\n-------------------^\n 135 |     steps:\n 136 |       - name: Checkout code"
  },
  {
    "file": ".github/workflows/housekeeping.yml",
    "name": "Housekeeping",
    "on": {
      "schedule": [
        {
          "cron": "0 3 * * 1"
        },
        {
          "cron": "0 6 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "tasks": {
            "description": "Tasks to run (comma-separated: cleanup, dead-links, licenses, audit, queue-monitor, secrets)",
            "type": "string",
            "default": "all"
          },
          "force-cleanup": {
            "description": "Force aggressive cleanup",
            "type": "boolean",
            "default": false
          }
        }
      },
      "workflow_call": {
        "inputs": {
          "tasks": {
            "description": "Tasks to run",
            "type": "string",
            "default": "all"
          },
          "force-cleanup": {
            "description": "Force aggressive cleanup",
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "concurrency": {
      "group": "housekeeping-${{ github.ref }}",
      "cancel-in-progress": true
    },
    "jobs": [
      {
        "jobName": "determine-tasks",
        "runsOn": "ubuntu-latest",
        "timeout": 2,
        "steps": [
          {
            "name": "Determine housekeeping strategy",
            "uses": "",
            "run": "TASKS=\"${{ inputs.tasks || 'all' }}\"\nFORCE_CLEANUP=\"${{ inputs.force-cleanup || 'false' }}\"\nSCHEDULE_TYPE=\"manual\"\n\n# Determine tasks based on schedule\nif [[ \"${{ github.event_name }}\" == \"schedule\" ]]; then\n  SCHEDULE_TYPE=\"scheduled\"\n  HOUR=$(date +%H)\n  DAY=$(date +%u)  # 1=Monday, 7=Sunday\n  \n  if [[ $HOUR -eq 3 && $DAY -eq 1 ]]; then\n    # Weekly comprehensive housekeeping\n    TASKS=\"cleanup,dead-links,licenses,audit,queue-monitor,secrets\"\n    FORCE_CLEANUP=\"true\"\n    echo \"🏠 Weekly comprehensive housekeeping\"\n  elif [[ $HOUR -eq 6 ]]; then\n    # Daily light housekeeping\n    TASKS=\"cleanup,queue-monitor\"\n    FORCE_CLEANUP=\"false\"\n    echo \"🧹 Daily light housekeeping\"\n  fi\nfi\n\nif [[ \"$TASKS\" == \"all\" ]]; then\n  TASKS=\"cleanup,dead-links,licenses,audit,queue-monitor,secrets\"\nfi\n\necho \"tasks=$TASKS\" >> $GITHUB_OUTPUT\necho \"schedule-type=$SCHEDULE_TYPE\" >> $GITHUB_OUTPUT\necho \"force-cleanup=$FORCE_CLEANUP\" >> $GITHUB_OUTPUT\necho \"Selected tasks: $TASKS (force: $FORCE_CLEANUP)\"\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "cleanup-duplicates",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Clean up duplicate content",
            "uses": "",
            "run": "echo \"🧹 Cleaning up duplicate content...\"\n\nAUTH_TOKEN=\"${{ secrets.AUTH_TOKEN }}\"\nFORCE_CLEANUP=\"${{ needs.determine-tasks.outputs.force-cleanup }}\"\n\n# Call the cleanup API endpoint\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -X POST \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"force\\\": $FORCE_CLEANUP}\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/cleanup/duplicates\" \\\n  --max-time 300)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Duplicate cleanup completed\"\n  echo \"$BODY\" > cleanup-duplicates-report.json\nelse\n  echo \"⚠️ Duplicate cleanup failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\nfi\n"
          },
          {
            "name": "Upload cleanup report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "dead-links-check",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Check for dead links",
            "uses": "",
            "run": "echo \"🔗 Checking for dead links in content...\"\n\n# Run dead link detection script\nnpm run check:dead-links || echo \"Dead link check completed with warnings\"\n\n# Count and report results\nif [ -f \"reports/dead-links.json\" ]; then\n  DEAD_COUNT=$(jq '.deadLinks | length' reports/dead-links.json 2>/dev/null || echo \"0\")\n  echo \"Found $DEAD_COUNT dead links\"\n  \n  if [ \"$DEAD_COUNT\" -gt 0 ]; then\n    echo \"⚠️ Dead links detected - content may need review\"\n  else\n    echo \"✅ No dead links found\"\n  fi\nfi\n"
          },
          {
            "name": "Upload dead links report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "license-audit",
        "runsOn": "ubuntu-latest",
        "timeout": 8,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Audit licenses",
            "uses": "",
            "run": "echo \"📜 Auditing dependency licenses...\"\n\n# Generate license report\nnpm run licenses:check || echo \"License check completed\"\n\n# Check for problematic licenses\nif [ -f \"reports/licenses.json\" ]; then\n  PROBLEMATIC=$(jq '.problematic | length' reports/licenses.json 2>/dev/null || echo \"0\")\n  echo \"Found $PROBLEMATIC potentially problematic licenses\"\n  \n  if [ \"$PROBLEMATIC\" -gt 0 ]; then\n    echo \"⚠️ License issues detected - manual review required\"\n  else\n    echo \"✅ All licenses appear compatible\"\n  fi\nfi\n"
          },
          {
            "name": "Upload license report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "security-audit",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Run security audit",
            "uses": "",
            "run": "echo \"🔒 Running security audit...\"\n\n# Run npm audit\nnpm audit --audit-level=moderate > security-audit.txt 2>&1 || echo \"Audit completed with findings\"\n\n# Count vulnerabilities\nHIGH_VULNS=$(grep -c \"high\" security-audit.txt || echo \"0\")\nCRITICAL_VULNS=$(grep -c \"critical\" security-audit.txt || echo \"0\")\n\necho \"Found $CRITICAL_VULNS critical and $HIGH_VULNS high severity vulnerabilities\"\n\nif [ \"$CRITICAL_VULNS\" -gt 0 ]; then\n  echo \"❌ Critical vulnerabilities detected - immediate action required\"\n  exit 1\nelif [ \"$HIGH_VULNS\" -gt 0 ]; then\n  echo \"⚠️ High severity vulnerabilities detected - review recommended\"\nelse\n  echo \"✅ No critical or high severity vulnerabilities\"\nfi\n"
          },
          {
            "name": "Upload security audit report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "queue-monitor",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Monitor content queue health",
            "uses": "",
            "run": "echo \"📊 Monitoring content queue health...\"\n\nAUTH_TOKEN=\"${{ secrets.AUTH_TOKEN }}\"\n\n# Get queue metrics\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/metrics\" \\\n  --max-time 30)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Queue monitoring completed\"\n  echo \"$BODY\" > queue-health.json\n  \n  # Extract key metrics if possible\n  if command -v jq >/dev/null 2>&1; then\n    TOTAL_CONTENT=$(echo \"$BODY\" | jq '.totalContent // 0' 2>/dev/null || echo \"unknown\")\n    APPROVED_CONTENT=$(echo \"$BODY\" | jq '.approvedContent // 0' 2>/dev/null || echo \"unknown\")\n    echo \"📈 Queue stats: $TOTAL_CONTENT total, $APPROVED_CONTENT approved\"\n  fi\nelse\n  echo \"⚠️ Queue monitoring failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\nfi\n"
          },
          {
            "name": "Upload queue health report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "secrets-validation",
        "runsOn": "ubuntu-latest",
        "timeout": 8,
        "needs": "determine-tasks",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Validate secrets configuration",
            "uses": "",
            "run": "echo \"🔐 Validating secrets configuration...\"\n\n# Check essential secrets\nMISSING_SECRETS=\"\"\n\nif [[ -z \"${{ secrets.SUPABASE_URL }}\" ]]; then\n  MISSING_SECRETS=\"$MISSING_SECRETS SUPABASE_URL\"\nfi\n\nif [[ -z \"${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}\" ]]; then\n  MISSING_SECRETS=\"$MISSING_SECRETS SUPABASE_SERVICE_ROLE_KEY\"\nfi\n\nif [[ -z \"${{ secrets.AUTH_TOKEN }}\" ]]; then\n  MISSING_SECRETS=\"$MISSING_SECRETS AUTH_TOKEN\"\nfi\n\nif [[ -z \"${{ secrets.DATABASE_URL }}\" ]]; then\n  MISSING_SECRETS=\"$MISSING_SECRETS DATABASE_URL\"\nfi\n\n# Report results\nif [[ -n \"$MISSING_SECRETS\" ]]; then\n  echo \"❌ Missing essential secrets:$MISSING_SECRETS\"\n  echo \"missing-secrets=$MISSING_SECRETS\" >> $GITHUB_OUTPUT\n  exit 1\nelse\n  echo \"✅ All essential secrets are configured\"\nfi\n\n# Check API keys\nAPI_KEYS=\"\"\nif [[ -n \"${{ secrets.REDDIT_CLIENT_ID }}\" ]]; then\n  API_KEYS=\"$API_KEYS reddit\"\nfi\nif [[ -n \"${{ secrets.YOUTUBE_API_KEY }}\" ]]; then\n  API_KEYS=\"$API_KEYS youtube\"\nfi\nif [[ -n \"${{ secrets.GIPHY_API_KEY }}\" ]]; then\n  API_KEYS=\"$API_KEYS giphy\"\nfi\n\necho \"📊 Configured API integrations:$API_KEYS\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SUPABASE_URL }}",
          "{{ secrets.SUPABASE_SERVICE_ROLE_KEY }}",
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.DATABASE_URL }}",
          "{{ secrets.REDDIT_CLIENT_ID }}",
          "{{ secrets.YOUTUBE_API_KEY }}",
          "{{ secrets.GIPHY_API_KEY }}"
        ]
      },
      {
        "jobName": "summary",
        "runsOn": "ubuntu-latest",
        "needs": [
          "determine-tasks",
          "cleanup-duplicates",
          "dead-links-check",
          "license-audit",
          "security-audit",
          "queue-monitor",
          "secrets-validation"
        ],
        "steps": [
          {
            "name": "Generate housekeeping summary",
            "uses": "",
            "run": "echo \"## 🏠 Housekeeping Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Tasks:** ${{ needs.determine-tasks.outputs.tasks }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Schedule Type:** ${{ needs.determine-tasks.outputs.schedule-type }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Force Cleanup:** ${{ needs.determine-tasks.outputs.force-cleanup }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Trigger:** ${{ github.event_name }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Task | Status | Notes |\" >> $GITHUB_STEP_SUMMARY\necho \"|------|--------|-------|\" >> $GITHUB_STEP_SUMMARY\n\n# Add task statuses\nif [[ \"${{ needs.cleanup-duplicates.result }}\" != \"\" ]]; then\n  echo \"| Cleanup Duplicates | ${{ needs.cleanup-duplicates.result }} | Content deduplication |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.dead-links-check.result }}\" != \"\" ]]; then\n  echo \"| Dead Links Check | ${{ needs.dead-links-check.result }} | URL validation |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.license-audit.result }}\" != \"\" ]]; then\n  echo \"| License Audit | ${{ needs.license-audit.result }} | Dependency licensing |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.security-audit.result }}\" != \"\" ]]; then\n  echo \"| Security Audit | ${{ needs.security-audit.result }} | Vulnerability scanning |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.queue-monitor.result }}\" != \"\" ]]; then\n  echo \"| Queue Monitor | ${{ needs.queue-monitor.result }} | Content queue health |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.secrets-validation.result }}\" != \"\" ]]; then\n  echo \"| Secrets Validation | ${{ needs.secrets-validation.result }} | Configuration check |\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Overall status\nFAILED_TASKS=0\n\nif [[ \"${{ needs.cleanup-duplicates.result }}\" == \"failure\" ]]; then\n  ((FAILED_TASKS++))\nfi\nif [[ \"${{ needs.dead-links-check.result }}\" == \"failure\" ]]; then\n  ((FAILED_TASKS++))\nfi\nif [[ \"${{ needs.license-audit.result }}\" == \"failure\" ]]; then\n  ((FAILE"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/manual-operations.yml",
    "name": "Manual Operations",
    "on": {
      "workflow_dispatch": {
        "inputs": {
          "operation": {
            "description": "Operation to perform",
            "required": true,
            "type": "choice",
            "options": [
              "post-now",
              "scan-all-emergency",
              "scan-all-normal",
              "catch-up-missed-posts",
              "approve-pending",
              "system-health-check",
              "clear-queue-test",
              "fix-duplicates"
            ]
          },
          "count": {
            "description": "Number of times (for catch-up posts)",
            "required": false,
            "default": "1",
            "type": "string"
          },
          "platform": {
            "description": "Specific platform (for single platform scans)",
            "required": false,
            "type": "choice",
            "options": [
              "all",
              "reddit",
              "youtube",
              "giphy",
              "pixabay",
              "bluesky",
              "imgur",
              "lemmy",
              "tumblr"
            ]
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "execute-operation",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Execute Operation",
            "uses": "",
            "run": "case \"${{ github.event.inputs.operation }}\" in\n  \"post-now\")\n    echo \"🚀 Posting content immediately...\"\n    curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n      -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n      -H \"Content-Type: application/json\" \\\n      -d '{\"immediate\": true}' \\\n      --fail --show-error\n    ;;\n    \n  \"catch-up-missed-posts\")\n    echo \"📅 Catching up ${{ github.event.inputs.count }} missed posts...\"\n    for i in $(seq 1 ${{ github.event.inputs.count }}); do\n      echo \"  Posting #$i...\"\n      curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n        -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n        -H \"Content-Type: application/json\" \\\n        -d \"{\\\"catchUp\\\": true, \\\"sequence\\\": $i}\" \\\n        --fail --show-error\n      \n      if [ $i -lt ${{ github.event.inputs.count }} ]; then\n        echo \"  Waiting 10 seconds before next post...\"\n        sleep 10\n      fi\n    done\n    ;;\n    \n  \"scan-all-emergency\")\n    echo \"🚨 EMERGENCY: Scanning all platforms with auto-approval...\"\n    curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/emergency-scan\" \\\n      -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n      -H \"Content-Type: application/json\" \\\n      -d '{\"autoApprove\": true, \"maxItems\": 100}' \\\n      --fail --show-error\n    ;;\n    \n  \"scan-all-normal\")\n    echo \"📡 Scanning all platforms (normal mode)...\"\n    curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/scan-all\" \\\n      -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n      -H \"Content-Type: application/json\" \\\n      -d '{\"maxItems\": 50}' \\\n      --fail --show-error\n    ;;\n    \n  \"approve-pending\")\n    echo \"✅ Auto-approving pending content...\"\n    curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/auto-approve\" \\\n      -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n      -H \"Content-Type: application/json\" \\\n      -d '{\"maxItems\": 30, \"onlyHighConfidence\": true}' \\\n      --fail "
          },
          {
            "name": "Report Operation Results",
            "uses": "",
            "run": "echo \"📊 Operation completed: ${{ github.event.inputs.operation }}\"\nif [ \"${{ github.event.inputs.count }}\" != \"1\" ]; then\n  echo \"Count: ${{ github.event.inputs.count }}\"\nfi\nif [ \"${{ github.event.inputs.platform }}\" != \"all\" ]; then\n  echo \"Platform: ${{ github.event.inputs.platform }}\"\nfi\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/meta-ci-audit.yml",
    "name": "Meta CI Audit",
    "on": {
      "schedule": [
        {
          "cron": "0 8 * * 1"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "audit-ci-health",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "steps": [
          {
            "name": "Checkout repository",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "🧠 Install tsx (temporary CI dependency)",
            "uses": "",
            "run": "npm install --no-save tsx"
          },
          {
            "name": "Run CI health audit",
            "uses": "",
            "run": "npx tsx scripts/validateRefactorPlan.ts"
          },
          {
            "name": "Generate health report",
            "uses": "",
            "run": "npx tsx scripts/auditWorkflows.ts"
          },
          {
            "name": "Notify on failure",
            "uses": "slackapi/slack-github-action@v1.27.0"
          },
          {
            "name": "Post success summary",
            "uses": "slackapi/slack-github-action@v1.27.0"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/phase3-auto-healing.yml",
    "name": "Phase 3 CI Auto-Healing: Security & Build Diagnostics",
    "on": {
      "workflow_call": {
        "inputs": {
          "trigger_deep_remediation": {
            "description": "Force deep remediation even if not triggered by failures",
            "required": false,
            "type": "boolean",
            "default": false
          }
        },
        "outputs": {
          "remediation_applied": {
            "description": "Whether Phase 3 auto-healing was applied",
            "value": "${{ jobs.deep-remediation.outputs.remediation_applied }}"
          },
          "security_score_improvement": {
            "description": "Security score improvement from remediation",
            "value": "${{ jobs.deep-remediation.outputs.security_improvement }}"
          },
          "build_diagnostic_available": {
            "description": "Whether build diagnostics were generated",
            "value": "${{ jobs.deep-remediation.outputs.build_diagnostics }}"
          }
        }
      },
      "workflow_dispatch": {
        "inputs": {
          "force_aggressive_mode": {
            "description": "Use aggressive security remediation",
            "required": false,
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "deep-remediation",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with caching",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci --prefer-offline --no-audit --no-fund\nnpm install --no-save tsx\n"
          },
          {
            "name": "Phase 3.1 - Security Deep Remediation",
            "uses": "",
            "run": "echo \"🛡️ Running Phase 3 Security Deep Remediation...\"\n\n# Set aggressive mode based on input or critical vulnerability count\nAGGRESSIVE_FLAG=\"\"\nif [[ \"${{ inputs.force_aggressive_mode }}\" == \"true\" ]]; then\n  AGGRESSIVE_FLAG=\"--aggressive\"\nfi\n\n# Run security deep fix\nnpx tsx scripts/securityDeepFix.ts $AGGRESSIVE_FLAG || true\n\n# Check if remediation was effective\nif [[ -f \"reports/security-deep-fix.md\" ]]; then\n  echo \"security_report_generated=true\" >> $GITHUB_OUTPUT\n  \n  # Extract effectiveness score if available\n  if grep -q \"Effectiveness Score:\" reports/security-deep-fix.md; then\n    EFFECTIVENESS=$(grep \"Effectiveness Score:\" reports/security-deep-fix.md | head -1 | grep -oE '[0-9]+' || echo \"0\")\n    echo \"effectiveness_score=$EFFECTIVENESS\" >> $GITHUB_OUTPUT\n  fi\nfi\n"
          },
          {
            "name": "Phase 3.2 - Build Failure Diagnostics",
            "uses": "",
            "run": "echo \"🏗️ Running Phase 3 Build Failure Diagnostics...\"\n\n# Run build diagnostics with comprehensive logging\nnpx tsx scripts/analyzeBuildFailure.ts --verbose --save-logs || true\n\n# Check if diagnostics were generated\nif [[ -f \"reports/build-diagnostics.md\" ]]; then\n  echo \"build_report_generated=true\" >> $GITHUB_OUTPUT\n  \n  # Check if quick fixes were identified\n  if grep -q \"Quick Fixes\" reports/build-diagnostics.md; then\n    QUICK_FIXES=$(grep -c \"Quick Fixes\" reports/build-diagnostics.md || echo \"0\")\n    echo \"quick_fixes_available=$QUICK_FIXES\" >> $GITHUB_OUTPUT\n  fi\nfi\n"
          },
          {
            "name": "Phase 3.3 - Apply Quick Fixes",
            "uses": "",
            "run": "echo \"⚡ Applying automated quick fixes...\"\n\n# Clear Next.js cache if build issues detected\nif [[ -d \".next\" ]]; then\n  echo \"🧹 Clearing Next.js cache...\"\n  rm -rf .next\n  echo \"cache_cleared=true\" >> $GITHUB_OUTPUT\nfi\n\n# Reinstall dependencies if dependency issues detected\nif grep -q \"dependency\" reports/build-diagnostics.md; then\n  echo \"📦 Reinstalling dependencies...\"\n  rm -f package-lock.json\n  npm install\n  echo \"dependencies_reinstalled=true\" >> $GITHUB_OUTPUT\nfi\n"
          },
          {
            "name": "Phase 3.4 - Re-run Critical Checks",
            "uses": "",
            "run": "echo \"🔄 Re-running critical checks after remediation...\"\n\n# Re-run the main gatekeeper to measure improvement\nnpx tsx scripts/checkCriticalFailures.ts --report-only || true\n\n# Extract final health score\nif [[ -f \"reports/ci-health-gate.md\" ]]; then\n  if grep -q \"Confidence Score:\" reports/ci-health-gate.md; then\n    FINAL_SCORE=$(grep \"Confidence Score:\" reports/ci-health-gate.md | head -1 | grep -oE '[0-9]+' || echo \"0\")\n    echo \"final_health_score=$FINAL_SCORE\" >> $GITHUB_OUTPUT\n  fi\nfi\n"
          },
          {
            "name": "Summarize Remediation Results",
            "uses": "",
            "run": "echo \"📊 Summarizing Phase 3 Auto-Healing Results...\"\n\nAPPLIED=\"false\"\nSECURITY_SCORE=\"0\"\nBUILD_REPORT=\"false\"\n\n# Check if security remediation was applied\nif [[ \"${{ steps.security-remediation.outputs.security_report_generated }}\" == \"true\" ]]; then\n  APPLIED=\"true\"\n  SECURITY_SCORE=\"${{ steps.security-remediation.outputs.effectiveness_score }}\"\nfi\n\n# Check if build diagnostics were generated\nif [[ \"${{ steps.build-diagnostics.outputs.build_report_generated }}\" == \"true\" ]]; then\n  BUILD_REPORT=\"true\"\nfi\n\necho \"applied=$APPLIED\" >> $GITHUB_OUTPUT\necho \"security_score=$SECURITY_SCORE\" >> $GITHUB_OUTPUT\necho \"build_report=$BUILD_REPORT\" >> $GITHUB_OUTPUT\n\n# Create summary for GitHub\ncat >> $GITHUB_STEP_SUMMARY << 'EOF'\n## 🛡️ Phase 3 Auto-Healing Summary\n\n### Security Deep Remediation\n- **Applied:** ${{ steps.security-remediation.outputs.security_report_generated == 'true' && '✅ Yes' || '❌ No' }}\n- **Effectiveness Score:** ${{ steps.security-remediation.outputs.effectiveness_score || 'N/A' }}/100\n\n### Build Diagnostics\n- **Generated:** ${{ steps.build-diagnostics.outputs.build_report_generated == 'true' && '✅ Yes' || '❌ No' }}\n- **Quick Fixes Available:** ${{ steps.build-diagnostics.outputs.quick_fixes_available || '0' }}\n\n### Quick Fixes Applied\n- **Cache Cleared:** ${{ steps.apply-quick-fixes.outputs.cache_cleared == 'true' && '✅ Yes' || '❌ No' }}\n- **Dependencies Reinstalled:** ${{ steps.apply-quick-fixes.outputs.dependencies_reinstalled == 'true' && '✅ Yes' || '❌ No' }}\n\n### Final Health Score\n- **Post-Remediation Score:** ${{ steps.post-remediation-check.outputs.final_health_score || 'N/A' }}/100\n\n### 📋 Generated Reports\n- Security Deep Fix: `reports/security-deep-fix.md`\n- Build Diagnostics: `reports/build-diagnostics.md`\n- CI Health Gate: `reports/ci-health-gate.md`\nEOF\n"
          },
          {
            "name": "Upload Remediation Reports",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "Comment on PR with Remediation Results",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "trigger-recheck",
        "runsOn": "ubuntu-latest",
        "needs": "deep-remediation",
        "steps": [
          {
            "name": "Checkout code for re-dispatch",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "🔄 Trigger Post-Remediation CI Run",
            "uses": "",
            "run": "echo \"🚀 Triggering repository_dispatch for post-remediation CI...\"\n\n# Verify token is available\nif [ -z \"$GH_TOKEN\" ]; then\n  echo \"❌ CI_REDISPATCH_TOKEN secret not found\"\n  echo \"📋 Please follow docs/PHASE4_SECURE_TOKEN_SETUP.md to configure the token\"\n  exit 1\nfi\n\n# Prepare client payload\nSECURITY_IMPROVEMENT=\"${{ needs.deep-remediation.outputs.security_improvement }}\"\nBUILD_DIAGNOSTICS=\"${{ needs.deep-remediation.outputs.build_diagnostic_available }}\"\n\n# Create dispatch event with secure token\nHTTP_STATUS=$(curl -s -o /dev/null -w \"%{http_code}\" -X POST \\\n  -H \"Accept: application/vnd.github.v3+json\" \\\n  -H \"Authorization: Bearer $GH_TOKEN\" \\\n  https://api.github.com/repos/${{ github.repository }}/dispatches \\\n  -d \"{\n    \\\"event_type\\\": \\\"post-remediation-check\\\",\n    \\\"client_payload\\\": {\n      \\\"security_improvement\\\": \\\"$SECURITY_IMPROVEMENT\\\",\n      \\\"build_diagnostics\\\": \\\"$BUILD_DIAGNOSTICS\\\",\n      \\\"triggered_by\\\": \\\"phase3-auto-healing\\\",\n      \\\"commit_sha\\\": \\\"${{ github.sha }}\\\",\n      \\\"remediation_timestamp\\\": \\\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\\\"\n    }\n  }\")\n\n# Check response status\ncase $HTTP_STATUS in\n  200|201|204)\n    echo \"✅ Repository dispatch successful (HTTP $HTTP_STATUS)\"\n    echo \"🔄 Post-remediation validation workflow should start shortly\"\n    ;;\n  401)\n    echo \"❌ Authentication failed (HTTP 401)\"\n    echo \"🔧 Check CI_REDISPATCH_TOKEN secret configuration\"\n    exit 1\n    ;;\n  403)\n    echo \"❌ Forbidden (HTTP 403)\"\n    echo \"🔧 Token may lack required permissions (repo, workflow scopes needed)\"\n    exit 1\n    ;;\n  404)\n    echo \"❌ Repository not found (HTTP 404)\"\n    echo \"🔧 Check repository path or token repository access\"\n    exit 1\n    ;;\n  *)\n    echo \"❌ Unexpected response (HTTP $HTTP_STATUS)\"\n    echo \"🔧 Check GitHub API status and token configuration\"\n    exit 1\n    ;;\nesac\n"
          },
          {
            "name": "📊 Record Re-Dispatch Metrics",
            "uses": "",
            "run": "echo \"📈 Phase 4 Re-Dispatch Metrics:\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"- **Trigger Time:** $(date -u +%Y-%m-%dT%H:%M:%SZ)\" >> $GITHUB_STEP_SUMMARY\necho \"- **Security Improvement:** ${{ needs.deep-remediation.outputs.security_improvement }}/100\" >> $GITHUB_STEP_SUMMARY\necho \"- **Build Diagnostics:** ${{ needs.deep-remediation.outputs.build_diagnostic_available == 'true' && 'Available' || 'Not Generated' }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Remediation Applied:** ✅ Yes\" >> $GITHUB_STEP_SUMMARY\necho \"- **Post-Validation:** 🔄 Triggered\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"> Post-remediation validation will run independently to verify fixes.\" >> $GITHUB_STEP_SUMMARY\n"
          },
          {
            "name": "🏷️ Add Remediation Success Labels",
            "uses": "",
            "run": "echo \"🏷️ Adding success labels to PR...\"\n\n# Add labels indicating successful auto-healing\ncurl -X POST \\\n  -H \"Accept: application/vnd.github.v3+json\" \\\n  -H \"Authorization: Bearer $GH_TOKEN\" \\\n  https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/labels \\\n  -d '{\"labels\": [\"auto-healing-applied\", \"security-improved\", \"phase3-remediation\"]}'\n\necho \"✅ Labels added successfully\"\n"
          },
          {
            "name": "📝 Update PR with Remediation Summary",
            "uses": "",
            "run": "echo \"📝 Posting remediation summary to PR...\"\n\n# Create detailed PR comment\ncat > pr_comment.md << 'EOF'\n## 🛡️ Phase 3 Auto-Healing Complete\n\n### 📊 Remediation Results\n- **Security Score Improvement:** ${{ needs.deep-remediation.outputs.security_improvement }}/100\n- **Build Diagnostics:** ${{ needs.deep-remediation.outputs.build_diagnostic_available == 'true' && '✅ Generated' || '❌ Not needed' }}\n- **Automated Fixes Applied:** ✅ Yes\n\n### 🔄 Next Steps\n1. **Post-Remediation Validation:** Automatically triggered\n2. **Review Reports:** Check workflow artifacts for detailed analysis\n3. **Manual Review:** Address any remaining issues in security reports\n\n### 📋 Available Reports\n- 🛡️ Security Deep Fix Report\n- 🏗️ Build Diagnostics Report\n- 📊 Updated CI Health Gate Report\n\n> **Note:** This comment was generated by Phase 3 Auto-Healing system. \n> Post-remediation validation is running independently.\nEOF\n\n# Post comment to PR\ncurl -X POST \\\n  -H \"Accept: application/vnd.github.v3+json\" \\\n  -H \"Authorization: Bearer $GH_TOKEN\" \\\n  https://api.github.com/repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/comments \\\n  -d \"{\\\"body\\\": $(cat pr_comment.md | jq -Rs .)}\"\n\necho \"✅ PR comment posted successfully\"\n"
          },
          {
            "name": "🔍 Verify Re-Dispatch Success",
            "uses": "",
            "run": "echo \"🔍 Verifying Phase 4 re-dispatch completed successfully...\"\necho \"\"\necho \"✅ Repository dispatch event sent\"\necho \"✅ Remediation metrics recorded\"\necho \"✅ PR labels and comments updated (if applicable)\"\necho \"\"\necho \"🎯 Phase 4 Secure Re-Dispatch System: OPERATIONAL\"\necho \"\"\necho \"📋 Post-remediation validation should begin within 1-2 minutes\"\necho \"📊 Check the 'Actions' tab for 'Post-Remediation Check' workflow\"\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/planner-contract.yml",
    "name": "📋 Planner Contract",
    "on": {
      "schedule": [
        {
          "cron": "30 3 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "test_scenarios": {
            "description": "Test scenarios to run (all,basic,edge,stress)",
            "type": "choice",
            "default": "all",
            "options": [
              "all",
              "basic",
              "edge",
              "stress"
            ]
          },
          "fail_fast": {
            "description": "Stop on first test failure",
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "concurrency": {
      "group": "planner-contract-${{ github.ref }}",
      "cancel-in-progress": true
    },
    "jobs": [
      {
        "jobName": "planner-contract",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "permissions": {
          "contents": "read",
          "issues": "write"
        },
        "steps": [
          {
            "name": "📥 Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "🔧 Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "📦 Install dependencies",
            "uses": "",
            "run": "echo \"🔧 Installing test dependencies...\"\nnpm ci --prefer-offline --no-audit\n"
          },
          {
            "name": "🧪 Run planner unit tests",
            "uses": "",
            "run": "echo \"🧪 Running comprehensive planner unit tests...\"\n\n# Set test configuration\nexport SCAN_MIN_PER_PLATFORM=40\nexport SCAN_MAX_PER_PLATFORM=120\nexport SCAN_GLOBAL_MAX=800\nexport SCAN_COOLDOWN_MIN=180\nexport MIN_CONF=0.70\nexport MIN_CANDIDATES=20\nexport PLATFORM_ALLOW=\"reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay\"\n\n# Run Node.js tests with timeout and detailed output\ntimeout 300s node --test --test-reporter=spec scripts/scan-plan.test.mjs > test_output.txt 2>&1\nTEST_EXIT_CODE=$?\n\necho \"TEST_EXIT_CODE=$TEST_EXIT_CODE\" >> $GITHUB_ENV\n\n# Display results\ncat test_output.txt\n\nif [ $TEST_EXIT_CODE -eq 0 ]; then\n  echo \"✅ All planner unit tests passed\"\n  echo \"UNIT_TESTS_STATUS=passed\" >> $GITHUB_ENV\nelse\n  echo \"❌ Planner unit tests failed with exit code: $TEST_EXIT_CODE\"\n  echo \"UNIT_TESTS_STATUS=failed\" >> $GITHUB_ENV\nfi\n"
          },
          {
            "name": "🔍 Contract validation scenarios",
            "uses": "",
            "run": "echo \"🔍 Running contract validation scenarios...\"\n\n# Test 1: Global cap enforcement\necho \"📊 Testing global cap enforcement...\"\nnode -e \"\nimport { spawn } from 'node:child_process';\nimport { writeFile } from 'node:fs/promises';\n\nconst wrapper = \\`\n  globalThis.fetch = async (url) => {\n    if (url.includes('/api/system/metrics')) {\n      return new Response(JSON.stringify({\n        queue_depth_by_platform: { reddit: 500, youtube: 400 },\n        last_scan_times: {}\n      }), { status: 200, headers: {'content-type':'application/json'}});\n    }\n    return new Response('[]', { status: 200, headers: {'content-type':'application/json'}});\n  };\n  import('./scripts/scan-plan.mjs').catch(e => { console.error(e); process.exit(1); });\n\\`;\n\nawait writeFile('__tmp_global_cap_test.mjs', wrapper);\n\nconst proc = spawn('node', ['__tmp_global_cap_test.mjs'], {\n  env: {\n    ...process.env,\n    TARGET_URL: 'https://example.com',\n    SUPABASE_URL: 'https://supabase.local',\n    SUPABASE_SERVICE_ROLE_KEY: 'test',\n    SCAN_GLOBAL_MAX: '800'\n  }\n});\n\nlet stdout = '';\nproc.stdout.on('data', d => stdout += d.toString());\n\nconst code = await new Promise(res => proc.on('close', res));\n\nif (stdout.includes('global_cap_reached')) {\n  console.log('✅ Global cap enforcement: PASSED');\n} else {\n  console.log('❌ Global cap enforcement: FAILED');\n  console.log('Output:', stdout);\n  process.exit(1);\n}\n\" || exit 1\n\necho \"CONTRACT_VALIDATION_STATUS=passed\" >> $GITHUB_ENV\n"
          },
          {
            "name": "🚀 Stress test scenarios",
            "uses": "",
            "run": "echo \"🚀 Running stress test scenarios...\"\n\n# Test with extreme platform counts\nnode -e \"\nimport { spawn } from 'node:child_process';\nimport { writeFile } from 'node:fs/promises';\n\n// Generate 50 platforms with various queue depths\nconst platforms = {};\nfor (let i = 0; i < 50; i++) {\n  platforms[\\`platform\\${i}\\`] = Math.floor(Math.random() * 200);\n}\n\nconst wrapper = \\`\n  globalThis.fetch = async (url) => {\n    if (url.includes('/api/system/metrics')) {\n      return new Response(JSON.stringify({\n        queue_depth_by_platform: ${JSON.stringify(platforms)},\n        last_scan_times: {}\n      }), { status: 200, headers: {'content-type':'application/json'}});\n    }\n    // Generate large supabase response\n    const rows = Array.from({length: 1000}, (_, i) => ({\n      source_platform: \\`platform\\${i % 50}\\`,\n      confidence_score: Math.random(),\n      ingest_priority: 0,\n      is_posted: false,\n      is_approved: true\n    }));\n    return new Response(JSON.stringify(rows), { status: 200, headers: {'content-type':'application/json'}});\n  };\n  import('./scripts/scan-plan.mjs').catch(e => { console.error(e); process.exit(1); });\n\\`;\n\nawait writeFile('__tmp_stress_test.mjs', wrapper);\n\nconst start = Date.now();\nconst proc = spawn('node', ['__tmp_stress_test.mjs'], {\n  env: {\n    ...process.env,\n    TARGET_URL: 'https://example.com',\n    SUPABASE_URL: 'https://supabase.local',  \n    SUPABASE_SERVICE_ROLE_KEY: 'test',\n    PLATFORM_ALLOW: Object.keys(platforms).join(',')\n  }\n});\n\nconst code = await new Promise(res => proc.on('close', res));\nconst duration = Date.now() - start;\n\nif (code === 0 && duration < 5000) {\n  console.log(\\`✅ Stress test: PASSED (completed in \\${duration}ms)\\`);\n} else {\n  console.log(\\`❌ Stress test: FAILED (exit code: \\${code}, duration: \\${duration}ms)\\`);\n  process.exit(1);\n}\n\" || exit 1\n\necho \"STRESS_TESTS_STATUS=passed\" >> $GITHUB_ENV\n"
          },
          {
            "name": "📊 Generate contract summary",
            "uses": "",
            "run": "echo \"## 📋 Planner Contract Validation Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Date:** $(date -u -Iseconds)\" >> $GITHUB_STEP_SUMMARY\necho \"**Test Scenarios:** ${{ inputs.test_scenarios || 'all' }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Results table\necho \"| Test Category | Status | Notes |\" >> $GITHUB_STEP_SUMMARY\necho \"|---------------|--------|-------|\" >> $GITHUB_STEP_SUMMARY\n\nif [ \"${{ env.UNIT_TESTS_STATUS }}\" = \"passed\" ]; then\n  echo \"| Unit Tests | ✅ Passed | All core logic validated |\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"| Unit Tests | ❌ Failed | Critical planner logic broken |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [ \"${{ env.CONTRACT_VALIDATION_STATUS }}\" = \"passed\" ]; then\n  echo \"| Contract Validation | ✅ Passed | Policy enforcement working |\" >> $GITHUB_STEP_SUMMARY\nelif [ \"${{ env.CONTRACT_VALIDATION_STATUS }}\" = \"\" ]; then\n  echo \"| Contract Validation | ⏭️ Skipped | Not run in this scenario |\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"| Contract Validation | ❌ Failed | Policy violations detected |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [ \"${{ env.STRESS_TESTS_STATUS }}\" = \"passed\" ]; then\n  echo \"| Stress Tests | ✅ Passed | Performance within limits |\" >> $GITHUB_STEP_SUMMARY\nelif [ \"${{ env.STRESS_TESTS_STATUS }}\" = \"\" ]; then\n  echo \"| Stress Tests | ⏭️ Skipped | Not run in this scenario |\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"| Stress Tests | ❌ Failed | Performance degradation |\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Overall status\nif [ \"${{ env.UNIT_TESTS_STATUS }}\" = \"passed\" ] && \\\n   ( [ \"${{ env.CONTRACT_VALIDATION_STATUS }}\" = \"passed\" ] || [ \"${{ env.CONTRACT_VALIDATION_STATUS }}\" = \"\" ] ) && \\\n   ( [ \"${{ env.STRESS_TESTS_STATUS }}\" = \"passed\" ] || [ \"${{ env.STRESS_TESTS_STATUS }}\" = \"\" ] ); then\n  echo \"### 🎉 Overall Status: **HEALTHY**\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"The demand-driven scanner planner is operating within contract specificat"
          },
          {
            "name": "🧹 Cleanup test artifacts",
            "uses": "",
            "run": "rm -f __tmp_*.mjs test_output.txt scan_plan.json scan_matrix.json\n"
          },
          {
            "name": "📤 Upload test artifacts",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "🚨 Create issue on contract violation",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/post-breakfast.yml",
    "name": "Post Breakfast Content",
    "on": {
      "schedule": [
        {
          "cron": "0 7 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "refresh-token",
        "steps": [],
        "secretRefs": []
      },
      {
        "jobName": "post-breakfast",
        "runsOn": "ubuntu-latest",
        "needs": "refresh-token",
        "steps": [
          {
            "name": "Post Breakfast Content",
            "uses": "",
            "run": "echo \"🌅 Posting breakfast content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Breakfast content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Breakfast content posted successfully\"\n# Optional: Send success notification\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Breakfast posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post-deploy-check.yml",
    "name": "Post-Deploy Check",
    "on": {
      "deployment_status": null,
      "push": {
        "branches": [
          "main"
        ]
      },
      "workflow_run": {
        "workflows": [
          "Vercel Production Deployment"
        ],
        "types": [
          "completed"
        ]
      },
      "workflow_dispatch": {
        "inputs": {
          "skip_refill_check": {
            "description": "Skip refill dry-run check",
            "type": "boolean",
            "default": false
          },
          "target_url": {
            "description": "Target URL to check (defaults to production)",
            "type": "string",
            "default": "https://hotdog-diaries.vercel.app"
          }
        }
      },
      "workflow_call": {
        "inputs": {
          "skip_refill_check": {
            "description": "Skip refill dry-run check",
            "type": "boolean",
            "default": false
          },
          "target_url": {
            "description": "Target URL to check",
            "type": "string",
            "default": "https://hotdog-diaries.vercel.app"
          }
        }
      }
    },
    "concurrency": {
      "group": "post-deploy-${{ github.ref }}",
      "cancel-in-progress": false
    },
    "permissions": {
      "contents": "read",
      "issues": "write"
    },
    "jobs": [
      {
        "jobName": "health-check",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Wait for deployment readiness",
            "uses": "",
            "run": "echo \"⏳ Waiting for deployment to be ready...\"\nsleep 30\n"
          },
          {
            "name": "Test deep health endpoint",
            "uses": "",
            "run": "echo \"🏥 Testing /admin/health/deep endpoint...\"\n\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  --max-time 30 \\\n  \"$PROD_URL/api/admin/health/deep\")\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"HTTP Status: $HTTP_STATUS\"\necho \"Response Body: $BODY\"\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Deep health check passed\"\n  \n  # Verify 'ok' status in response\n  OK_STATUS=$(echo \"$BODY\" | jq -r '.ok // false')\n  if [ \"$OK_STATUS\" = \"true\" ]; then\n    echo \"✅ Health status is OK\"\n    echo \"status=healthy\" >> $GITHUB_OUTPUT\n    \n    # Extract component details for artifact\n    echo \"$BODY\" | jq '.components // {}' > health_components.json\n    \n  else\n    echo \"❌ Health status indicates issues\"\n    echo \"status=degraded\" >> $GITHUB_OUTPUT\n    echo \"$BODY\" | jq '.components // {}' > health_components.json\n    \n    # Don't fail immediately - continue to refill check\n    echo \"⚠️ Health check shows degraded status but continuing...\"\n  fi\nelse\n  echo \"❌ Deep health check failed with status $HTTP_STATUS\"\n  echo \"status=failed\" >> $GITHUB_OUTPUT\n  echo '{\"error\": \"health_check_failed\", \"status\": '$HTTP_STATUS'}' > health_components.json\n  exit 1\nfi\n"
          },
          {
            "name": "Get system metrics snapshot",
            "uses": "",
            "run": "echo \"📊 Collecting system metrics snapshot...\"\n\nMETRICS_RESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  --max-time 15 \\\n  \"$PROD_URL/api/system/metrics\")\n\nMETRICS_HTTP_STATUS=$(echo $METRICS_RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nMETRICS_BODY=$(echo $METRICS_RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"Metrics HTTP Status: $METRICS_HTTP_STATUS\"\n\nif [ \"$METRICS_HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ System metrics collected\"\n  echo \"$METRICS_BODY\" > metrics_snapshot.json\n  echo \"snapshot=available\" >> $GITHUB_OUTPUT\n  \n  # Extract key metrics for logs\n  QUEUE_DEPTH=$(echo \"$METRICS_BODY\" | jq '[.queue_depth_by_platform | to_entries[]] | map(.value) | add // 0')\n  POSTS_TODAY=$(echo \"$METRICS_BODY\" | jq '.posts_today // 0')\n  HEALTH_STATUS=$(echo \"$METRICS_BODY\" | jq -r '.health_status // \"unknown\"')\n  \n  echo \"📈 Key Metrics:\"\n  echo \"  Total queue depth: $QUEUE_DEPTH\"\n  echo \"  Posts today: $POSTS_TODAY\"\n  echo \"  Health status: $HEALTH_STATUS\"\n  \nelse\n  echo \"⚠️ Could not collect metrics (status $METRICS_HTTP_STATUS)\"\n  echo '{\"error\": \"metrics_unavailable\", \"timestamp\": \"'$(date -Iseconds)'\"}' > metrics_snapshot.json\n  echo \"snapshot=failed\" >> $GITHUB_OUTPUT\nfi\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "refill-check",
        "runsOn": "ubuntu-latest",
        "timeout": 8,
        "needs": "health-check",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Test two-day forecast endpoint",
            "uses": "",
            "run": "echo \"🔮 Testing two-day forecast capability...\"\n\n# Get today and tomorrow dates\nTODAY=$(date -Iseconds | cut -d'T' -f1)\nTOMORROW=$(date -d \"+1 day\" -Iseconds | cut -d'T' -f1)\n\necho \"Testing forecast for: $TODAY and $TOMORROW\"\n\n# Test today's forecast\nTODAY_RESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  --max-time 30 \\\n  \"$PROD_URL/api/admin/schedule/forecast?date=$TODAY\")\n\nTODAY_HTTP_STATUS=$(echo $TODAY_RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nTODAY_BODY=$(echo $TODAY_RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\n# Test tomorrow's forecast\nTOMORROW_RESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  --max-time 30 \\\n  \"$PROD_URL/api/admin/schedule/forecast?date=$TOMORROW\")\n\nTOMORROW_HTTP_STATUS=$(echo $TOMORROW_RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nTOMORROW_BODY=$(echo $TOMORROW_RESPONSE | sed -e 's/HTTPSTATUS:.*//g')\n\necho \"Today forecast status: $TODAY_HTTP_STATUS\"\necho \"Tomorrow forecast status: $TOMORROW_HTTP_STATUS\"\n\n# Validate both days have 6 slots\nif [ \"$TODAY_HTTP_STATUS\" -eq 200 ] && [ \"$TOMORROW_HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Forecast endpoints responding\"\n  \n  # Count slots for today\n  TODAY_SLOTS=$(echo \"$TODAY_BODY\" | jq '.slots | length // 0')\n  TODAY_FILLED=$(echo \"$TODAY_BODY\" | jq '[.slots[] | select(.content_id != null)] | length // 0')\n  \n  # Count slots for tomorrow  \n  TOMORROW_SLOTS=$(echo \"$TOMORROW_BODY\" | jq '.slots | length // 0')\n  TOMORROW_FILLED=$(echo \"$TOMORROW_BODY\" | jq '[.slots[] | select(.content_id != null)] | length // 0')\n  \n  echo \"📅 Today: $TODAY_FILLED/$TODAY_SLOTS slots filled\"\n  echo \"📅 Tomorrow: $TOMORROW_FILLED/$TOMORROW_SLOTS slots filled\"\n  \n  # Check if we have 6/6 for both days\n  if [ \"$TODAY_SLOTS\" -eq 6 ] && [ \"$TOMORROW_SLOTS\" -eq 6 ]; then\n    echo \"✅ Both days have 6 time slots configured\"\n    \n    # Check fill status - warn if not fully filled but don't fail\n    TOTAL_FILLED=$((TODAY_FILLED "
          },
          {
            "name": "Diversity policy evaluation (warn-only)",
            "uses": "",
            "run": "echo \"🌈 Evaluating diversity policy...\"\n\nDIVERSITY_SCORE=\"${{ steps.refill.outputs.diversity_score }}\"\n\nif [ -n \"$DIVERSITY_SCORE\" ]; then\n  # Convert to integer percentage for comparison\n  DIVERSITY_PCT=$(echo \"$DIVERSITY_SCORE * 100\" | bc -l | cut -d'.' -f1)\n  \n  echo \"Diversity score: $DIVERSITY_SCORE ($DIVERSITY_PCT%)\"\n  \n  if [ \"$DIVERSITY_PCT\" -ge 80 ]; then\n    echo \"✅ Excellent diversity ($DIVERSITY_PCT% >= 80%)\"\n  elif [ \"$DIVERSITY_PCT\" -ge 60 ]; then\n    echo \"🟡 Good diversity ($DIVERSITY_PCT% >= 60%)\"\n  elif [ \"$DIVERSITY_PCT\" -ge 40 ]; then\n    echo \"🟠 Moderate diversity ($DIVERSITY_PCT% >= 40%)\"\n  else\n    echo \"🔴 Low diversity ($DIVERSITY_PCT% < 40%)\"\n    echo \"⚠️ Consider running content scans to improve platform diversity\"\n  fi\n  \n  # This is warn-only, so don't fail the deployment\n  echo \"📋 Diversity policy result: INFORMATIONAL (warn-only)\"\nelse\n  echo \"⚠️ Could not calculate diversity score\"\nfi\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "upload-artifacts",
        "runsOn": "ubuntu-latest",
        "needs": [
          "health-check",
          "refill-check"
        ],
        "steps": [
          {
            "name": "Download artifacts from previous jobs",
            "uses": "",
            "run": "echo \"📦 Collecting deployment artifacts...\"\nmkdir -p deployment_artifacts\n\n# Create summary artifact\ncat > deployment_artifacts/deployment_summary.json << EOF\n{\n  \"timestamp\": \"$(date -Iseconds)\",\n  \"deployment_sha\": \"${{ github.sha }}\",\n  \"workflow_run\": \"${{ github.run_id }}\",\n  \"health_status\": \"${{ needs.health-check.outputs.health-status }}\",\n  \"refill_status\": \"${{ needs.refill-check.outputs.refill-status }}\",\n  \"diversity_score\": \"${{ needs.refill-check.outputs.diversity_score }}\",\n  \"environment\": \"production\",\n  \"success\": ${{ needs.health-check.outputs.health-status != 'failed' && needs.refill-check.outputs.refill-status != 'failed' }}\n}\nEOF\n"
          },
          {
            "name": "Collect current metrics snapshot",
            "uses": "",
            "run": "echo \"📊 Collecting final metrics snapshot...\"\n\nFINAL_METRICS=$(curl -s --max-time 15 \"$PROD_URL/api/system/metrics\" || echo '{\"error\": \"collection_failed\"}')\necho \"$FINAL_METRICS\" > deployment_artifacts/final_metrics_snapshot.json\n\n# Extract summary for logs\nif echo \"$FINAL_METRICS\" | jq -e '.timestamp' > /dev/null 2>&1; then\n  HEALTH_STATUS=$(echo \"$FINAL_METRICS\" | jq -r '.health_status // \"unknown\"')\n  TOTAL_QUEUE=$(echo \"$FINAL_METRICS\" | jq '[.queue_depth_by_platform | to_entries[]] | map(.value) | add // 0')\n  POSTS_TODAY=$(echo \"$FINAL_METRICS\" | jq '.posts_today // 0')\n  \n  echo \"📈 Final Metrics Summary:\"\n  echo \"  Health: $HEALTH_STATUS\"\n  echo \"  Queue Depth: $TOTAL_QUEUE\"\n  echo \"  Posts Today: $POSTS_TODAY\"\nelse\n  echo \"⚠️ Could not collect final metrics\"\nfi\n"
          },
          {
            "name": "Upload deployment artifacts",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "Generate deployment report",
            "uses": "",
            "run": "echo \"📋 Post-Deploy Check Report\"\necho \"==========================\"\necho \"Deployment: ${{ github.sha }}\"\necho \"Timestamp: $(date -Iseconds)\"\necho \"Workflow: ${{ github.run_id }}\"\necho \"\"\necho \"Results:\"\necho \"  Health Check: ${{ needs.health-check.outputs.health-status }}\"\necho \"  Refill Check: ${{ needs.refill-check.outputs.refill-status }}\"\necho \"  Diversity Score: ${{ needs.refill-check.outputs.diversity_score }}\"\necho \"\"\n\nOVERALL_SUCCESS=\"${{ needs.health-check.outputs.health-status != 'failed' && needs.refill-check.outputs.refill-status != 'failed' }}\"\n\nif [ \"$OVERALL_SUCCESS\" = \"true\" ]; then\n  echo \"✅ DEPLOYMENT VALIDATION PASSED\"\n  echo \"All post-deploy checks completed successfully\"\nelse\n  echo \"❌ DEPLOYMENT VALIDATION FAILED\"\n  echo \"One or more critical checks failed\"\n  exit 1\nfi\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "notification",
        "runsOn": "ubuntu-latest",
        "needs": [
          "health-check",
          "refill-check",
          "upload-artifacts"
        ],
        "steps": [
          {
            "name": "✅ Success Summary",
            "uses": "",
            "run": "echo \"🎉 POST-DEPLOY VALIDATION SUCCESS\"\necho \"==================================\"\necho \"✅ Health Check: ${{ needs.health-check.outputs.health-status }}\"\necho \"✅ Refill Check: ${{ needs.refill-check.outputs.refill-status }}\"\necho \"📊 Diversity Score: ${{ needs.refill-check.outputs.diversity_score }}\"\necho \"\"\necho \"🚀 System Status: All validation checks passed\"\necho \"🌐 Production URL: ${{ env.PROD_URL }}\"\necho \"📦 Artifacts: Metrics snapshot and deployment data uploaded\"\necho \"\"\necho \"## ✅ Post-Deploy Validation Success\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Deployment**: \\`${{ github.sha }}\\`\" >> $GITHUB_STEP_SUMMARY\necho \"**Timestamp**: $(date -u -Iseconds)\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### 📊 Validation Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"- **Health Check**: ${{ needs.health-check.outputs.health-status }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Refill Check**: ${{ needs.refill-check.outputs.refill-status }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Diversity Score**: ${{ needs.refill-check.outputs.diversity_score }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"🎉 All post-deployment validation checks passed successfully!\" >> $GITHUB_STEP_SUMMARY\n  \n"
          },
          {
            "name": "Create failure notification",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/post-dinner.yml",
    "name": "Post Dinner Content",
    "on": {
      "schedule": [
        {
          "cron": "0 18 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "post-dinner",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Post Dinner Content",
            "uses": "",
            "run": "echo \"🍽️ Posting dinner content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Dinner content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Dinner content posted successfully\"\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Dinner posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post-evening.yml",
    "name": "Post Evening Content",
    "on": {
      "schedule": [
        {
          "cron": "0 20 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "post-evening",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Post Evening Content",
            "uses": "",
            "run": "echo \"🌙 Posting evening content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Evening content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Evening content posted successfully\"\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Evening posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post-late-night.yml",
    "name": "Post Late Night Content",
    "on": {
      "schedule": [
        {
          "cron": "30 22 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "post-late-night",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Post Late Night Content",
            "uses": "",
            "run": "echo \"🌃 Posting late night content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Late night content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Late night content posted successfully\"\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Late night posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post-lunch.yml",
    "name": "Post Lunch Content",
    "on": {
      "schedule": [
        {
          "cron": "0 12 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "post-lunch",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Post Lunch Content",
            "uses": "",
            "run": "echo \"🥪 Posting lunch content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Lunch content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Lunch content posted successfully\"\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Lunch posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post-remediation-check.yml",
    "name": "Post-Remediation Validation",
    "on": {
      "repository_dispatch": {
        "types": [
          "post-remediation-check"
        ]
      },
      "workflow_dispatch": {
        "inputs": {
          "manual_trigger": {
            "description": "Manually trigger post-remediation validation",
            "required": false,
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "validate-remediation",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "steps": [
          {
            "name": "Checkout repository",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "📊 Extract Remediation Context",
            "uses": "",
            "run": "echo \"🔍 Extracting remediation context from dispatch payload...\"\n\n# Extract data from repository_dispatch payload\nSECURITY_IMPROVEMENT=\"${{ github.event.client_payload.security_improvement }}\"\nBUILD_DIAGNOSTICS=\"${{ github.event.client_payload.build_diagnostics }}\"\nTRIGGERED_BY=\"${{ github.event.client_payload.triggered_by }}\"\nCOMMIT_SHA=\"${{ github.event.client_payload.commit_sha }}\"\nREMEDIATION_TIME=\"${{ github.event.client_payload.remediation_timestamp }}\"\n\n# Set defaults for manual triggers\nif [ \"${{ github.event_name }}\" = \"workflow_dispatch\" ]; then\n  SECURITY_IMPROVEMENT=\"unknown\"\n  BUILD_DIAGNOSTICS=\"unknown\"\n  TRIGGERED_BY=\"manual\"\n  COMMIT_SHA=\"${{ github.sha }}\"\n  REMEDIATION_TIME=\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\nfi\n\necho \"security_improvement=$SECURITY_IMPROVEMENT\" >> $GITHUB_OUTPUT\necho \"build_diagnostics=$BUILD_DIAGNOSTICS\" >> $GITHUB_OUTPUT\necho \"triggered_by=$TRIGGERED_BY\" >> $GITHUB_OUTPUT\necho \"commit_sha=$COMMIT_SHA\" >> $GITHUB_OUTPUT\necho \"remediation_time=$REMEDIATION_TIME\" >> $GITHUB_OUTPUT\n\necho \"📋 Remediation Context:\"\necho \"- Security Improvement: $SECURITY_IMPROVEMENT\"\necho \"- Build Diagnostics: $BUILD_DIAGNOSTICS\"\necho \"- Triggered By: $TRIGGERED_BY\"\necho \"- Commit SHA: $COMMIT_SHA\"\necho \"- Remediation Time: $REMEDIATION_TIME\"\n"
          },
          {
            "name": "Setup Node.js with caching",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci --prefer-offline --no-audit --no-fund\nnpm install --no-save tsx\n"
          },
          {
            "name": "🧪 Re-run CI Health Checks",
            "uses": "",
            "run": "echo \"🧪 Re-running CI health checks to validate remediation...\"\n\n# Run the critical failure gatekeeper in report-only mode\nnpx tsx scripts/checkCriticalFailures.ts --report-only || true\n\n# Extract health metrics from the report\nif [[ -f \"reports/ci-health-gate.md\" ]]; then\n  echo \"health_report_generated=true\" >> $GITHUB_OUTPUT\n  \n  # Extract confidence score\n  if grep -q \"Confidence Score:\" reports/ci-health-gate.md; then\n    CONFIDENCE=$(grep \"Confidence Score:\" reports/ci-health-gate.md | head -1 | grep -oE '[0-9]+' || echo \"0\")\n    echo \"confidence_score=$CONFIDENCE\" >> $GITHUB_OUTPUT\n    echo \"📊 Current confidence score: $CONFIDENCE/100\"\n  fi\n  \n  # Check CI readiness\n  if grep -q \"CI Readiness: ✅ Ready\" reports/ci-health-gate.md; then\n    echo \"ci_ready=true\" >> $GITHUB_OUTPUT\n    echo \"✅ CI is ready to proceed\"\n  else\n    echo \"ci_ready=false\" >> $GITHUB_OUTPUT\n    echo \"❌ CI is still blocked\"\n  fi\n  \n  # Check for remaining blockers\n  BLOCKERS=$(grep -c \"Blocking Issues:\" reports/ci-health-gate.md || echo \"0\")\n  echo \"blocking_issues=$BLOCKERS\" >> $GITHUB_OUTPUT\nelse\n  echo \"health_report_generated=false\" >> $GITHUB_OUTPUT\n  echo \"ci_ready=false\" >> $GITHUB_OUTPUT\n  echo \"confidence_score=0\" >> $GITHUB_OUTPUT\nfi\n"
          },
          {
            "name": "🔍 Validate Specific Components",
            "uses": "",
            "run": "echo \"🔍 Validating specific components after remediation...\"\n\n# Test lint status\necho \"📝 Testing lint status...\"\nif npm run lint:check 2>/dev/null || true; then\n  echo \"lint_status=pass\" >> $GITHUB_OUTPUT\n  echo \"✅ Lint checks passing\"\nelse\n  echo \"lint_status=fail\" >> $GITHUB_OUTPUT\n  echo \"❌ Lint checks still failing\"\nfi\n\n# Test security status (basic check)\necho \"🔒 Testing security status...\"\nif npm audit --audit-level=critical 2>/dev/null; then\n  echo \"security_status=pass\" >> $GITHUB_OUTPUT\n  echo \"✅ No critical security vulnerabilities\"\nelse\n  echo \"security_status=fail\" >> $GITHUB_OUTPUT\n  echo \"⚠️ Critical security vulnerabilities remain\"\nfi\n\n# Test build status\necho \"🏗️ Testing build status...\"\nif timeout 120 npm run build 2>/dev/null; then\n  echo \"build_status=pass\" >> $GITHUB_OUTPUT\n  echo \"✅ Build completed successfully\"\nelse\n  echo \"build_status=fail\" >> $GITHUB_OUTPUT\n  echo \"❌ Build still failing\"\nfi\n"
          },
          {
            "name": "📈 Calculate Remediation Effectiveness",
            "uses": "",
            "run": "echo \"📈 Calculating remediation effectiveness...\"\n\n# Get current health metrics\nCONFIDENCE=\"${{ steps.health-recheck.outputs.confidence_score }}\"\nCI_READY=\"${{ steps.health-recheck.outputs.ci_ready }}\"\nLINT_STATUS=\"${{ steps.component-validation.outputs.lint_status }}\"\nSECURITY_STATUS=\"${{ steps.component-validation.outputs.security_status }}\"\nBUILD_STATUS=\"${{ steps.component-validation.outputs.build_status }}\"\n\n# Calculate effectiveness score\nEFFECTIVENESS=0\n\n# Base score from confidence\nif [[ \"$CONFIDENCE\" =~ ^[0-9]+$ ]]; then\n  EFFECTIVENESS=$CONFIDENCE\nfi\n\n# Bonus points for component health\n[[ \"$LINT_STATUS\" == \"pass\" ]] && EFFECTIVENESS=$((EFFECTIVENESS + 5))\n[[ \"$SECURITY_STATUS\" == \"pass\" ]] && EFFECTIVENESS=$((EFFECTIVENESS + 10))\n[[ \"$BUILD_STATUS\" == \"pass\" ]] && EFFECTIVENESS=$((EFFECTIVENESS + 15))\n[[ \"$CI_READY\" == \"true\" ]] && EFFECTIVENESS=$((EFFECTIVENESS + 20))\n\n# Cap at 100\n[[ $EFFECTIVENESS -gt 100 ]] && EFFECTIVENESS=100\n\necho \"effectiveness_score=$EFFECTIVENESS\" >> $GITHUB_OUTPUT\necho \"📊 Remediation effectiveness: $EFFECTIVENESS/100\"\n\n# Determine overall status\nif [[ $EFFECTIVENESS -ge 80 && \"$CI_READY\" == \"true\" ]]; then\n  echo \"overall_status=success\" >> $GITHUB_OUTPUT\n  echo \"✅ Remediation was highly effective\"\nelif [[ $EFFECTIVENESS -ge 60 ]]; then\n  echo \"overall_status=partial\" >> $GITHUB_OUTPUT\n  echo \"⚠️ Remediation was partially effective\"\nelse\n  echo \"overall_status=failed\" >> $GITHUB_OUTPUT\n  echo \"❌ Remediation was not effective\"\nfi\n"
          },
          {
            "name": "🚨 Check Rollback Requirements",
            "uses": "",
            "run": "echo \"🚨 Checking if rollback is required...\"\n\nEFFECTIVENESS=\"${{ steps.effectiveness.outputs.effectiveness_score }}\"\nCI_READY=\"${{ steps.health-recheck.outputs.ci_ready }}\"\n\necho \"Current effectiveness: $EFFECTIVENESS/100\"\necho \"CI Ready: $CI_READY\"\n\n# Determine if rollback is needed\nif [[ $EFFECTIVENESS -lt 30 && \"$CI_READY\" == \"false\" ]]; then\n  echo \"rollback_required=true\" >> $GITHUB_OUTPUT\n  echo \"🚨 ROLLBACK REQUIRED: Health critically low after remediation\"\n  echo \"rollback_reason=Health score $EFFECTIVENESS < 30 and CI still blocked\" >> $GITHUB_OUTPUT\nelse\n  echo \"rollback_required=false\" >> $GITHUB_OUTPUT\n  echo \"✅ No rollback required\"\nfi\n"
          },
          {
            "name": "📊 Generate Validation Summary",
            "uses": "",
            "run": "echo \"📊 Post-Remediation Validation Summary\" >> $GITHUB_STEP_SUMMARY\necho \"=======================================\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\necho \"### 🎯 Remediation Context\" >> $GITHUB_STEP_SUMMARY\necho \"- **Triggered By:** ${{ steps.context.outputs.triggered_by }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Commit SHA:** ${{ steps.context.outputs.commit_sha }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Remediation Time:** ${{ steps.context.outputs.remediation_time }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Security Improvement:** ${{ steps.context.outputs.security_improvement }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\necho \"### 📈 Validation Results\" >> $GITHUB_STEP_SUMMARY\necho \"- **Overall Status:** ${{ steps.effectiveness.outputs.overall_status }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Effectiveness Score:** ${{ steps.effectiveness.outputs.effectiveness_score }}/100\" >> $GITHUB_STEP_SUMMARY\necho \"- **Confidence Score:** ${{ steps.health-recheck.outputs.confidence_score }}/100\" >> $GITHUB_STEP_SUMMARY\necho \"- **CI Ready:** ${{ steps.health-recheck.outputs.ci_ready == 'true' && '✅ Yes' || '❌ No' }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\necho \"### 🔍 Component Status\" >> $GITHUB_STEP_SUMMARY\necho \"- **Lint:** ${{ steps.component-validation.outputs.lint_status == 'pass' && '✅ Pass' || '❌ Fail' }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Security:** ${{ steps.component-validation.outputs.security_status == 'pass' && '✅ Pass' || '❌ Fail' }}\" >> $GITHUB_STEP_SUMMARY\necho \"- **Build:** ${{ steps.component-validation.outputs.build_status == 'pass' && '✅ Pass' || '❌ Fail' }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\nif [[ \"${{ steps.rollback-check.outputs.rollback_required }}\" == \"true\" ]]; then\n  echo \"### 🚨 Rollback Required\" >> $GITHUB_STEP_SUMMARY\n  echo \"**Reason:** ${{ steps.rollback-check.outputs.rollback_reason }}\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"### 📋 Next Actions\" >> $GI"
          },
          {
            "name": "Upload Post-Remediation Reports",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📝 Update Original PR with Validation Results",
            "uses": "",
            "run": "echo \"📝 Updating original PR with validation results...\"\n\n# Find PR associated with the commit SHA\nCOMMIT_SHA=\"${{ steps.context.outputs.commit_sha }}\"\n\n# Create validation results comment\ncat > validation_comment.md << EOF\n## 🧪 Post-Remediation Validation Results\n\n**Validation Time:** $(date -u +%Y-%m-%dT%H:%M:%SZ)  \n**Triggered By:** ${{ steps.context.outputs.triggered_by }}\n\n### 📊 Results Summary\n- **Overall Status:** ${{ steps.effectiveness.outputs.overall_status == 'success' && '✅ Success' || steps.effectiveness.outputs.overall_status == 'partial' && '⚠️ Partial' || '❌ Failed' }}\n- **Effectiveness Score:** ${{ steps.effectiveness.outputs.effectiveness_score }}/100\n- **CI Ready:** ${{ steps.health-recheck.outputs.ci_ready == 'true' && '✅ Yes' || '❌ No' }}\n\n### 🔍 Component Validation\n- **Lint:** ${{ steps.component-validation.outputs.lint_status == 'pass' && '✅' || '❌' }}\n- **Security:** ${{ steps.component-validation.outputs.security_status == 'pass' && '✅' || '❌' }}\n- **Build:** ${{ steps.component-validation.outputs.build_status == 'pass' && '✅' || '❌' }}\n\n${{ steps.rollback-check.outputs.rollback_required == 'true' && '### 🚨 Rollback Required\\n**Reason:** Health critically low after remediation\\n' || '' }}\n\n> **Note:** This validation ran independently after Phase 3 auto-healing completed.\nEOF\n\necho \"✅ Validation results prepared for PR update\"\n"
          },
          {
            "name": "🎯 Final Validation Status",
            "uses": "",
            "run": "echo \"🎯 Post-Remediation Validation Complete\"\necho \"=======================================\"\necho \"\"\necho \"📊 Overall Status: ${{ steps.effectiveness.outputs.overall_status }}\"\necho \"📈 Effectiveness: ${{ steps.effectiveness.outputs.effectiveness_score }}/100\"\necho \"🚀 CI Ready: ${{ steps.health-recheck.outputs.ci_ready }}\"\necho \"\"\n\nif [[ \"${{ steps.effectiveness.outputs.overall_status }}\" == \"success\" ]]; then\n  echo \"✅ Phase 3 auto-healing was successful!\"\n  echo \"🎉 CI pipeline can proceed normally\"\n  exit 0\nelif [[ \"${{ steps.effectiveness.outputs.overall_status }}\" == \"partial\" ]]; then\n  echo \"⚠️ Phase 3 auto-healing was partially successful\"\n  echo \"🔧 Some manual intervention may be needed\"\n  exit 0\nelse\n  echo \"❌ Phase 3 auto-healing was not effective\"\n  echo \"🚨 Manual intervention required\"\n  if [[ \"${{ steps.rollback-check.outputs.rollback_required }}\" == \"true\" ]]; then\n    echo \"🔄 Consider rollback due to critically low health\"\n  fi\n  exit 1\nfi\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/post-snack.yml",
    "name": "Post Afternoon Snack",
    "on": {
      "schedule": [
        {
          "cron": "0 15 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "post-snack",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Post Snack Content",
            "uses": "",
            "run": "echo \"🍿 Posting afternoon snack content...\"\n\n# Store response in variable for error analysis\nRESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \"${{ secrets.SITE_URL }}/api/admin/posting/post-now\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"immediate\": true}' \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\necho \"HTTP Status: $HTTP_CODE\"\necho \"Response: $RESPONSE_BODY\"\n\n# Check for specific error conditions\nif [[ \"$HTTP_CODE\" == \"401\" ]]; then\n  echo \"❌ CRITICAL: Authentication failed - AUTH_TOKEN is invalid or expired\"\n  echo \"This indicates a security breach recovery issue - AUTH_TOKEN needs to be updated in GitHub secrets\"\n  exit 1\nelif [[ \"$HTTP_CODE\" != \"200\" ]]; then\n  echo \"❌ FAILED: API returned HTTP $HTTP_CODE\"\n  echo \"Response body: $RESPONSE_BODY\"\n  exit 1\nelse\n  echo \"✅ SUCCESS: Snack content posted (HTTP $HTTP_CODE)\"\nfi\n"
          },
          {
            "name": "Verify Post Success",
            "uses": "",
            "run": "echo \"✅ Snack content posted successfully\"\n"
          },
          {
            "name": "Handle Failure",
            "uses": "",
            "run": "echo \"❌ CRITICAL: Snack posting failed - this may indicate:\"\necho \"  1. AUTH_TOKEN is invalid/expired (most common after security breach)\"\necho \"  2. API endpoint is down\"\necho \"  3. No approved content available\"\necho \"  4. Database connectivity issues\"\necho \"\"\necho \"🔧 TROUBLESHOOTING STEPS:\"\necho \"  1. Check AUTH_TOKEN in GitHub secrets matches current production token\"\necho \"  2. Verify Vercel deployment is live\"\necho \"  3. Check content queue has approved posts available\"\necho \"  4. Review API logs in Vercel dashboard\"\necho \"\"\necho \"📞 IMMEDIATE ACTIONS REQUIRED:\"\necho \"  - Update AUTH_TOKEN in GitHub secrets if authentication failed\"\necho \"  - Run content approval if queue is empty\"\necho \"  - Check Vercel deployment status\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/post.yml",
    "name": "Content Posting",
    "on": {
      "schedule": [
        {
          "cron": "0 13 * * *"
        },
        {
          "cron": "0 17 * * *"
        },
        {
          "cron": "0 20 * * *"
        },
        {
          "cron": "0 23 * * *"
        },
        {
          "cron": "0 2 * * *"
        },
        {
          "cron": "30 4 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "slot": {
            "description": "Time slot to post (breakfast, lunch, snack, dinner, evening, late-night, or manual)",
            "type": "choice",
            "options": [
              "manual",
              "breakfast",
              "lunch",
              "snack",
              "dinner",
              "evening",
              "late-night"
            ],
            "default": "manual"
          },
          "dry-run": {
            "description": "Dry run mode (preview only)",
            "type": "boolean",
            "default": false
          }
        }
      },
      "workflow_call": {
        "inputs": {
          "slot": {
            "description": "Time slot to post",
            "type": "string",
            "default": "manual"
          },
          "dry-run": {
            "description": "Dry run mode",
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "concurrency": {
      "group": "posting-${{ github.ref }}-${{ inputs.slot || 'scheduled' }}",
      "cancel-in-progress": false
    },
    "jobs": [
      {
        "jobName": "determine-slot",
        "runsOn": "ubuntu-latest",
        "timeout": 2,
        "steps": [
          {
            "name": "Determine posting strategy",
            "uses": "",
            "run": "SLOT=\"${{ inputs.slot || 'manual' }}\"\nDRY_RUN=\"${{ inputs.dry-run || 'false' }}\"\nSLOT_INDEX=\"0\"\n\n# Determine slot based on schedule\nif [[ \"${{ github.event_name }}\" == \"schedule\" ]]; then\n  HOUR=$(date +%H)\n  MINUTE=$(date +%M)\n  \n  if [[ $HOUR -eq 13 && $MINUTE -eq 0 ]]; then\n    SLOT=\"breakfast\"\n    SLOT_INDEX=\"0\"\n    echo \"🌅 Breakfast posting slot (8:00 AM ET)\"\n  elif [[ $HOUR -eq 17 && $MINUTE -eq 0 ]]; then\n    SLOT=\"lunch\"\n    SLOT_INDEX=\"1\"\n    echo \"🍽️ Lunch posting slot (12:00 PM ET)\"\n  elif [[ $HOUR -eq 20 && $MINUTE -eq 0 ]]; then\n    SLOT=\"snack\"\n    SLOT_INDEX=\"2\"\n    echo \"🍿 Snack posting slot (3:00 PM ET)\"\n  elif [[ $HOUR -eq 23 && $MINUTE -eq 0 ]]; then\n    SLOT=\"dinner\"\n    SLOT_INDEX=\"3\"\n    echo \"🍽️ Dinner posting slot (6:00 PM ET)\"\n  elif [[ $HOUR -eq 2 && $MINUTE -eq 0 ]]; then\n    SLOT=\"evening\"\n    SLOT_INDEX=\"4\"\n    echo \"🌆 Evening posting slot (9:00 PM ET)\"\n  elif [[ $HOUR -eq 4 && $MINUTE -eq 30 ]]; then\n    SLOT=\"late-night\"\n    SLOT_INDEX=\"5\"\n    echo \"🌙 Late night posting slot (11:30 PM ET)\"\n  fi\nelse\n  # Map manual slots to indices\n  case \"$SLOT\" in\n    breakfast) SLOT_INDEX=\"0\" ;;\n    lunch) SLOT_INDEX=\"1\" ;;\n    snack) SLOT_INDEX=\"2\" ;;\n    dinner) SLOT_INDEX=\"3\" ;;\n    evening) SLOT_INDEX=\"4\" ;;\n    late-night) SLOT_INDEX=\"5\" ;;\n    manual) SLOT_INDEX=\"6\" ;;\n  esac\nfi\n\necho \"slot=$SLOT\" >> $GITHUB_OUTPUT\necho \"slot-index=$SLOT_INDEX\" >> $GITHUB_OUTPUT\necho \"dry-run=$DRY_RUN\" >> $GITHUB_OUTPUT\necho \"auth-token=${{ secrets.AUTH_TOKEN }}\" >> $GITHUB_OUTPUT\necho \"Selected slot: $SLOT (index: $SLOT_INDEX), dry-run: $DRY_RUN\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "pre-post-check",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "needs": "determine-slot",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Validate posting conditions",
            "uses": "",
            "run": "echo \"🔍 Validating posting conditions for slot: ${{ needs.determine-slot.outputs.slot }}...\"\n\nAUTH_TOKEN=\"${{ needs.determine-slot.outputs.auth-token }}\"\nSLOT_INDEX=\"${{ needs.determine-slot.outputs.slot-index }}\"\nTODAY=$(date +%Y-%m-%d)\n\n# Check if content is available for this slot\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/schedule/forecast?date=$TODAY\" \\\n  --max-time 30)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\nCAN_POST=\"false\"\nCONTENT_AVAILABLE=\"false\"\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Schedule API accessible\"\n  CONTENT_AVAILABLE=\"true\"\n  \n  # Check if this slot hasn't been posted yet today\n  # This is a simplified check - you'd parse the JSON response\n  if [[ \"$BODY\" == *\"upcoming\"* ]]; then\n    CAN_POST=\"true\"\n    echo \"✅ Content ready for posting\"\n  else\n    echo \"⚠️ Content may already be posted for this slot\"\n  fi\nelse\n  echo \"❌ Schedule API not accessible (status: $HTTP_STATUS)\"\nfi\n\n# Dry run mode always allows posting for testing\nif [[ \"${{ needs.determine-slot.outputs.dry-run }}\" == \"true\" ]]; then\n  CAN_POST=\"true\"\n  echo \"🧪 Dry run mode - posting validation bypassed\"\nfi\n\necho \"can-post=$CAN_POST\" >> $GITHUB_OUTPUT\necho \"content-available=$CONTENT_AVAILABLE\" >> $GITHUB_OUTPUT\necho \"Validation result: can-post=$CAN_POST, content-available=$CONTENT_AVAILABLE\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "post-content",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": [
          "determine-slot",
          "pre-post-check"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Execute content posting",
            "uses": "",
            "run": "echo \"📤 Posting content for slot: ${{ needs.determine-slot.outputs.slot }}...\"\n\nAUTH_TOKEN=\"${{ needs.determine-slot.outputs.auth-token }}\"\nSLOT=\"${{ needs.determine-slot.outputs.slot }}\"\nSLOT_INDEX=\"${{ needs.determine-slot.outputs.slot-index }}\"\nDRY_RUN=\"${{ needs.determine-slot.outputs.dry-run }}\"\n\n# Prepare the posting request\nJSON_PAYLOAD=$(cat <<EOF\n{\n  \"slot\": \"$SLOT\",\n  \"slotIndex\": $SLOT_INDEX,\n  \"dryRun\": $DRY_RUN\n}\nEOF\n)\n\n# Execute the post\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -X POST \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"$JSON_PAYLOAD\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/post\" \\\n  --max-time 300)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\necho \"post-status=$HTTP_STATUS\" >> $GITHUB_OUTPUT\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  if [[ \"$DRY_RUN\" == \"true\" ]]; then\n    echo \"✅ Dry run completed successfully\"\n    echo \"post-id=dry-run-$(date +%s)\" >> $GITHUB_OUTPUT\n  else\n    echo \"✅ Content posted successfully\"\n    # Extract post ID from response if available\n    POST_ID=$(echo \"$BODY\" | grep -o '\"id\":\"[^\"]*\"' | cut -d'\"' -f4 || echo \"posted-$(date +%s)\")\n    echo \"post-id=$POST_ID\" >> $GITHUB_OUTPUT\n  fi\n  \n  echo \"Response: $BODY\"\nelse\n  echo \"❌ Content posting failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\n  exit 1\nfi\n"
          },
          {
            "name": "Upload posting logs",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "post-validation",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "needs": [
          "determine-slot",
          "post-content"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Validate post success",
            "uses": "",
            "run": "echo \"✅ Validating successful post: ${{ needs.post-content.outputs.post-id }}...\"\n\nAUTH_TOKEN=\"${{ needs.determine-slot.outputs.auth-token }}\"\nSLOT=\"${{ needs.determine-slot.outputs.slot }}\"\nDRY_RUN=\"${{ needs.determine-slot.outputs.dry-run }}\"\n\nif [[ \"$DRY_RUN\" == \"true\" ]]; then\n  echo \"🧪 Dry run mode - post validation skipped\"\nelse\n  # Verify the content was actually posted\n  sleep 10  # Give the system time to update\n  \n  # Check the schedule to see if the content is marked as posted\n  TODAY=$(date +%Y-%m-%d)\n  RESPONSE=$(curl -s \\\n    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n    \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/schedule/forecast?date=$TODAY\" \\\n    --max-time 30)\n  \n  if [[ \"$RESPONSE\" == *\"posted\"* ]]; then\n    echo \"✅ Post validation confirmed - content appears in schedule as posted\"\n  else\n    echo \"⚠️ Post validation warning - content may not be marked as posted yet\"\n  fi\nfi\n\necho \"🎉 Posting workflow completed for slot: $SLOT\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "summary",
        "runsOn": "ubuntu-latest",
        "needs": [
          "determine-slot",
          "pre-post-check",
          "post-content",
          "post-validation"
        ],
        "steps": [
          {
            "name": "Generate posting summary",
            "uses": "",
            "run": "echo \"## 📤 Content Posting Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Slot:** ${{ needs.determine-slot.outputs.slot }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Slot Index:** ${{ needs.determine-slot.outputs.slot-index }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Dry Run:** ${{ needs.determine-slot.outputs.dry-run }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Trigger:** ${{ github.event_name }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Step | Status | Details |\" >> $GITHUB_STEP_SUMMARY\necho \"|------|--------|---------|\" >> $GITHUB_STEP_SUMMARY\necho \"| Pre-Check | ${{ needs.pre-post-check.result }} | Can post: ${{ needs.pre-post-check.outputs.can-post }} |\" >> $GITHUB_STEP_SUMMARY\n\nif [[ \"${{ needs.post-content.result }}\" != \"\" ]]; then\n  echo \"| Posting | ${{ needs.post-content.result }} | Status: ${{ needs.post-content.outputs.post-status }} |\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"| Posting | skipped | Pre-checks failed |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.post-validation.result }}\" != \"\" ]]; then\n  echo \"| Validation | ${{ needs.post-validation.result }} | Post verification |\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Overall status\nif [[ \"${{ needs.post-content.result }}\" == \"success\" ]]; then\n  if [[ \"${{ needs.determine-slot.outputs.dry-run }}\" == \"true\" ]]; then\n    echo \"## 🧪 Dry run completed successfully\" >> $GITHUB_STEP_SUMMARY\n    echo \"Content would have been posted for **${{ needs.determine-slot.outputs.slot }}** slot.\" >> $GITHUB_STEP_SUMMARY\n  else\n    echo \"## ✅ Content posted successfully\" >> $GITHUB_STEP_SUMMARY\n    echo \"**Post ID:** ${{ needs.post-content.outputs.post-id }}\" >> $GITHUB_STEP_SUMMARY\n    echo \"Posted for **${{ needs.determine-slot.outputs.slot }}** slot.\" >> $GITHUB_STEP_SUMMARY\n  fi\nelif [[ \"${{ needs.pre-post-check.outputs.can-post }}\" == \"false\" ]]; then\n  echo \"## ℹ️ Posting skipped\" >> $GITHUB_STEP_SUMMARY\n  echo \"Content was not available or already posted for this sl"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/production-audit.yml",
    "name": "🔍 Production Audit",
    "on": {
      "schedule": [
        {
          "cron": "0 9 * * 2"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "force_run": {
            "description": "Force run audit even if recent run exists",
            "required": false,
            "type": "boolean",
            "default": false
          },
          "audit_window_days": {
            "description": "Number of days to audit (default: 7)",
            "required": false,
            "type": "number",
            "default": 7
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "production-audit",
        "runsOn": "ubuntu-latest",
        "timeout": 20,
        "permissions": {
          "contents": "read",
          "actions": "read",
          "issues": "write"
        },
        "steps": [
          {
            "name": "📥 Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "🔧 Install dependencies",
            "uses": "",
            "run": "# Install required tools for audit script\nsudo apt-get update\nsudo apt-get install -y bc jq curl\n"
          },
          {
            "name": "🔐 Configure environment",
            "uses": "",
            "run": "echo \"APP_ORIGIN=${{ env.PRODUCTION_URL }}\" >> $GITHUB_ENV\necho \"GITHUB_REPO=${{ env.GITHUB_REPO }}\" >> $GITHUB_ENV\n\n# Validate required secrets are available\nif [[ -z \"${{ secrets.AUTH_TOKEN }}\" ]]; then\n  echo \"❌ AUTH_TOKEN secret not configured\"\n  exit 1\nfi\n\nif [[ -z \"${{ secrets.SUPABASE_URL }}\" ]]; then\n  echo \"❌ SUPABASE_URL secret not configured\"  \n  exit 1\nfi\n\nif [[ -z \"${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}\" ]]; then\n  echo \"❌ SUPABASE_SERVICE_ROLE_KEY secret not configured\"\n  exit 1\nfi\n\necho \"✅ All required secrets available\"\n"
          },
          {
            "name": "🔍 Run production audit",
            "uses": "",
            "run": "echo \"🔍 Starting 7-day production audit...\"\necho \"Target: $APP_ORIGIN\"\necho \"Repository: $GITHUB_REPO\"\necho \"\"\n\n# Make audit script executable\nchmod +x scripts/production-audit.sh\n\n# Run audit and capture exit code\nset +e  # Don't exit on failure, we want to capture results\n\nif scripts/production-audit.sh; then\n  AUDIT_EXIT_CODE=0\n  echo \"✅ Production audit completed successfully\"\nelse\n  AUDIT_EXIT_CODE=$?\n  echo \"❌ Production audit detected issues (exit code: $AUDIT_EXIT_CODE)\"\nfi\n\necho \"AUDIT_EXIT_CODE=$AUDIT_EXIT_CODE\" >> $GITHUB_ENV\n\n# Check if artifacts were generated\nif [[ -d \"prod_audit_artifacts\" ]]; then\n  echo \"📊 Audit artifacts generated:\"\n  ls -la prod_audit_artifacts/\n  \n  # Extract key metrics for summary\n  if [[ -f \"prod_audit_artifacts/production_audit_$(date +%F).md\" ]]; then\n    echo \"📋 Audit report available\"\n    \n    # Extract summary information if available\n    if grep -q \"Total posts (7d):\" prod_audit_artifacts/production_audit_*.md; then\n      TOTAL_POSTS=$(grep \"Total posts (7d):\" prod_audit_artifacts/production_audit_*.md | grep -o '[0-9]\\+' | head -1)\n      echo \"TOTAL_POSTS=${TOTAL_POSTS:-0}\" >> $GITHUB_ENV\n    fi\n    \n    if grep -q \"Platform diversity:\" prod_audit_artifacts/production_audit_*.md; then\n      PLATFORM_COUNT=$(grep \"Platform diversity:\" prod_audit_artifacts/production_audit_*.md | grep -o '[0-9]\\+' | head -1)\n      echo \"PLATFORM_COUNT=${PLATFORM_COUNT:-0}\" >> $GITHUB_ENV\n    fi\n  fi\nelse\n  echo \"⚠️ No audit artifacts generated\"\nfi\n"
          },
          {
            "name": "📤 Upload audit artifacts",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📤 Upload latest audit (overwrites)",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📊 Generate audit summary",
            "uses": "",
            "run": "echo \"## 🔍 Production Audit Summary\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Date:** $(date -u -Iseconds)\" >> $GITHUB_STEP_SUMMARY\necho \"**Target:** $APP_ORIGIN\" >> $GITHUB_STEP_SUMMARY\necho \"**Audit Window:** 7 days\" >> $GITHUB_STEP_SUMMARY\necho \"**Exit Code:** ${AUDIT_EXIT_CODE:-unknown}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Status badge\nif [[ \"${AUDIT_EXIT_CODE:-1}\" -eq 0 ]]; then\n  echo \"**Status:** 🟢 **HEALTHY** - No issues detected\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"**Status:** 🔴 **ISSUES DETECTED** - Requires attention\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### 📊 Key Metrics\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Metric | Value |\" >> $GITHUB_STEP_SUMMARY\necho \"|--------|-------|\" >> $GITHUB_STEP_SUMMARY\necho \"| Posts (7d) | ${TOTAL_POSTS:-N/A} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Unique Platforms | ${PLATFORM_COUNT:-N/A} |\" >> $GITHUB_STEP_SUMMARY\necho \"| Audit Status | $([ \"${AUDIT_EXIT_CODE:-1}\" -eq 0 ] && echo \"✅ Passed\" || echo \"❌ Failed\") |\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Add artifacts info\necho \"### 📁 Generated Artifacts\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"- **Latest:** \\`production-audit-latest\\`\" >> $GITHUB_STEP_SUMMARY\necho \"- **Versioned:** \\`production-audit-${{ github.run_number }}\\`\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Include audit report summary if available\nif [[ -f prod_audit_artifacts/production_audit_*.md ]]; then\n  echo \"### 📋 Audit Report\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"\\`\\`\\`\" >> $GITHUB_STEP_SUMMARY\n  head -20 prod_audit_artifacts/production_audit_*.md | grep -E \"^(#|##|\\*|-|[0-9])\" >> $GITHUB_STEP_SUMMARY || echo \"Report preview not available\" >> $GITHUB_STEP_SUMMARY\n  echo \"\\`\\`\\`\" >> $GITHUB_STEP_SUMMARY\nfi\n"
          },
          {
            "name": "🚨 Create issue on critical failure",
            "uses": "actions/github-script@v7"
          },
          {
            "name": "✅ Success notification",
            "uses": "",
            "run": "echo \"🎉 Production audit completed successfully!\"\necho \"\"\necho \"📊 Audit summary:\"\necho \"  - Target: $APP_ORIGIN\"\necho \"  - Window: 7 days\"\necho \"  - Posts: ${TOTAL_POSTS:-N/A}\"\necho \"  - Platforms: ${PLATFORM_COUNT:-N/A}\"\necho \"  - Status: ✅ Healthy\"\necho \"\"\necho \"🔍 Production system is operating within normal parameters.\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}",
          "{{ secrets.SUPABASE_URL }}",
          "{{ secrets.SUPABASE_SERVICE_ROLE_KEY }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/queue-monitor-hook.yml",
    "name": "Queue Monitor Hook",
    "on": {
      "workflow_call": {
        "inputs": {
          "trigger_source": {
            "description": "Source that triggered this hook",
            "required": true,
            "type": "string"
          },
          "post_count": {
            "description": "Number of posts just made",
            "required": false,
            "default": "1",
            "type": "string"
          }
        },
        "secrets": {
          "SITE_URL": {
            "required": true
          },
          "AUTH_TOKEN": {
            "required": true
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "queue-monitor",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Check Queue Health After Posting",
            "uses": "",
            "run": "echo \"🩺 Checking queue health after posting from ${{ inputs.trigger_source }}...\"\n\n# Get current queue health\nHEALTH_RESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L \\\n  \"${{ secrets.SITE_URL }}/api/admin/queue-health\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  --retry 2 --retry-delay 5 2>&1 || true)\n\n# Extract HTTP code and response body\nHTTP_CODE=$(echo \"$HEALTH_RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nRESPONSE_BODY=$(echo \"$HEALTH_RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\nif [[ \"$HTTP_CODE\" == \"200\" ]]; then\n  echo \"✅ Queue health check successful\"\n  \n  # Extract key metrics\n  HEALTH_STATUS=$(echo \"$RESPONSE_BODY\" | jq -r '.health.status // \"unknown\"')\n  DAYS_CONTENT=$(echo \"$RESPONSE_BODY\" | jq -r '.queue.daysOfContent // 0')\n  APPROVED_CONTENT=$(echo \"$RESPONSE_BODY\" | jq -r '.queue.totalApproved // 0')\n  NEEDS_SCANNING=$(echo \"$RESPONSE_BODY\" | jq -r '.queue.needsScanning // false')\n  \n  echo \"📊 Queue Status: $HEALTH_STATUS\"\n  echo \"📅 Days of Content: $DAYS_CONTENT\"\n  echo \"✅ Approved Content: $APPROVED_CONTENT\"\n  echo \"🔍 Needs Scanning: $NEEDS_SCANNING\"\n  \n  # Set outputs for auto-scan decision\n  echo \"health_status=$HEALTH_STATUS\" >> $GITHUB_OUTPUT\n  echo \"days_content=$DAYS_CONTENT\" >> $GITHUB_OUTPUT\n  echo \"approved_content=$APPROVED_CONTENT\" >> $GITHUB_OUTPUT\n  echo \"needs_scanning=$NEEDS_SCANNING\" >> $GITHUB_OUTPUT\n  echo \"should_auto_scan=false\" >> $GITHUB_OUTPUT\n  \n  # Determine if we should trigger auto-scan\n  if [[ \"$HEALTH_STATUS\" == \"critical\" ]] || [[ \"$HEALTH_STATUS\" == \"emergency\" ]]; then\n    echo \"🚨 CRITICAL/EMERGENCY: Auto-scan will be triggered\"\n    echo \"should_auto_scan=true\" >> $GITHUB_OUTPUT\n  elif [[ \"$NEEDS_SCANNING\" == \"true\" ]] && [[ \"${DAYS_CONTENT%.*}\" -lt 3 ]]; then\n    echo \"⚠️ WARNING: Low content - auto-scan will be triggered\"\n    echo \"should_auto_scan=true\" >> $GITHUB_OUTPUT\n  else\n    echo \"✅ Queue is healthy - no auto-scan needed\"\n  fi\n  \nelse\n  echo \"❌ Queue health check failed with H"
          },
          {
            "name": "Trigger Auto-Scan if Needed",
            "uses": "",
            "run": "HEALTH_STATUS=\"${{ steps.health-check.outputs.health_status }}\"\nDAYS_CONTENT=\"${{ steps.health-check.outputs.days_content }}\"\n\necho \"🚀 Triggering auto-scan due to low queue...\"\necho \"Health Status: $HEALTH_STATUS\"\necho \"Days of Content: $DAYS_CONTENT\"\n\n# Determine scan mode based on urgency\nif [[ \"$HEALTH_STATUS\" == \"emergency\" ]]; then\n  SCAN_MODE=\"emergency\"\n  echo \"🆘 Using EMERGENCY mode\"\nelif [[ \"$HEALTH_STATUS\" == \"critical\" ]]; then\n  SCAN_MODE=\"emergency\"\n  echo \"🚨 Using EMERGENCY mode for critical status\"\nelse\n  SCAN_MODE=\"auto\"\n  echo \"🤖 Using AUTO mode\"\nfi\n\n# Trigger auto-scan\nAUTO_SCAN_RESPONSE=$(curl -s -w \"HTTP_CODE:%{http_code}\" -L -X POST \\\n  \"${{ secrets.SITE_URL }}/api/admin/auto-scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"mode\\\": \\\"$SCAN_MODE\\\", \\\"triggeredBy\\\": \\\"queue-monitor-hook-${{ inputs.trigger_source }}\\\"}\" \\\n  --retry 2 --retry-delay 10 2>&1 || true)\n\n# Extract results\nAUTO_HTTP_CODE=$(echo \"$AUTO_SCAN_RESPONSE\" | grep -o 'HTTP_CODE:[0-9]*' | cut -d':' -f2)\nAUTO_RESPONSE_BODY=$(echo \"$AUTO_SCAN_RESPONSE\" | sed 's/HTTP_CODE:[0-9]*$//')\n\nif [[ \"$AUTO_HTTP_CODE\" == \"200\" ]]; then\n  echo \"✅ Auto-scan triggered successfully\"\n  \n  # Extract scan results\n  TRIGGERED=$(echo \"$AUTO_RESPONSE_BODY\" | jq -r '.summary.totalTriggered // 0')\n  ERRORS=$(echo \"$AUTO_RESPONSE_BODY\" | jq -r '.summary.totalErrors // 0')\n  \n  echo \"📊 Auto-scan Results:\"\n  echo \"  - Triggered: $TRIGGERED scans\"\n  echo \"  - Errors: $ERRORS\"\n  \n  if [[ \"$TRIGGERED\" -gt 0 ]]; then\n    echo \"🎯 Platforms scanned:\"\n    echo \"$AUTO_RESPONSE_BODY\" | jq -r '.triggeredScans[]? // empty' | sed 's/^/  - /'\n  fi\n  \n  if [[ \"$ERRORS\" -gt 0 ]]; then\n    echo \"⚠️ Scan errors occurred:\"\n    echo \"$AUTO_RESPONSE_BODY\" | jq -r '.errors[]? // empty' | sed 's/^/  - /'\n  fi\n  \nelse\n  echo \"❌ Auto-scan failed with HTTP $AUTO_HTTP_CODE\"\n  echo \"Response: $AUTO_RESPONSE_BODY\"\n  # Don't fail the hook - the original posting was s"
          },
          {
            "name": "Log Hook Completion",
            "uses": "",
            "run": "HEALTH_STATUS=\"${{ steps.health-check.outputs.health_status || 'unknown' }}\"\nSHOULD_SCAN=\"${{ steps.health-check.outputs.should_auto_scan || 'false' }}\"\n\necho \"📋 Queue Monitor Hook Summary:\"\necho \"  - Triggered by: ${{ inputs.trigger_source }}\"\necho \"  - Posts made: ${{ inputs.post_count }}\"\necho \"  - Queue health: $HEALTH_STATUS\"\necho \"  - Auto-scan triggered: $SHOULD_SCAN\"\necho \"  - Hook completed: $(date -u)\"\n\nif [[ \"$SHOULD_SCAN\" == \"true\" ]]; then\n  echo \"✅ Queue monitoring and auto-replenishment completed\"\nelse\n  echo \"✅ Queue monitoring completed - no action needed\"\nfi\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/queue-monitor.yml",
    "name": "Monitor Queue Health & Scan if Needed",
    "on": {
      "schedule": [
        {
          "cron": "0 */3 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "check-queue-health",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Check Queue Status",
            "uses": "",
            "run": "echo \"🔍 Checking queue health...\"\n\nSTATUS=$(curl -L -s \"${{ secrets.SITE_URL }}/api/admin/schedule\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Accept: application/json\")\n\nif [ $? -ne 0 ]; then\n  echo \"❌ Failed to fetch queue status\"\n  echo \"needs_scan=true\" >> $GITHUB_OUTPUT\n  echo \"urgency=critical\" >> $GITHUB_OUTPUT\n  echo \"days_left=0\" >> $GITHUB_OUTPUT\n  echo \"approved_count=0\" >> $GITHUB_OUTPUT\n  exit 1\nfi\n\nAPPROVED_COUNT=$(echo \"$STATUS\" | jq -r '.queueStatus.totalApproved // 0')\nDAYS_OF_CONTENT=$(echo \"scale=1; $APPROVED_COUNT / 6\" | bc -l)\n\necho \"📊 Queue Status: $APPROVED_COUNT approved items = $DAYS_OF_CONTENT days\"\necho \"approved_count=$APPROVED_COUNT\" >> $GITHUB_OUTPUT\necho \"days_left=$DAYS_OF_CONTENT\" >> $GITHUB_OUTPUT\n\n# Determine if we need to scan\nif (( $(echo \"$DAYS_OF_CONTENT < 1\" | bc -l) )); then\n  echo \"🚨 CRITICAL: Less than 1 day of content!\"\n  echo \"needs_scan=true\" >> $GITHUB_OUTPUT\n  echo \"urgency=critical\" >> $GITHUB_OUTPUT\nelif (( $(echo \"$DAYS_OF_CONTENT < 3\" | bc -l) )); then\n  echo \"⚠️ WARNING: Less than 3 days of content\"\n  echo \"needs_scan=true\" >> $GITHUB_OUTPUT\n  echo \"urgency=high\" >> $GITHUB_OUTPUT\nelif (( $(echo \"$DAYS_OF_CONTENT < 7\" | bc -l) )); then\n  echo \"📡 Normal scan needed (less than 7 days)\"\n  echo \"needs_scan=true\" >> $GITHUB_OUTPUT\n  echo \"urgency=normal\" >> $GITHUB_OUTPUT\nelse\n  echo \"✅ Queue is healthy ($DAYS_OF_CONTENT days)\"\n  echo \"needs_scan=false\" >> $GITHUB_OUTPUT\n  echo \"urgency=none\" >> $GITHUB_OUTPUT\nfi\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "scan-platforms",
        "runsOn": "ubuntu-latest",
        "needs": "check-queue-health",
        "steps": [
          {
            "name": "Emergency Scan All Platforms",
            "uses": "",
            "run": "echo \"🚨 EMERGENCY: Scanning all platforms with auto-approval\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/emergency-scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"autoApprove\": true, \"maxItems\": 100, \"platforms\": [\"reddit\", \"youtube\", \"giphy\", \"pixabay\", \"bluesky\", \"imgur\", \"lemmy\", \"tumblr\"]}' \\\n  --fail --show-error --retry 2\n"
          },
          {
            "name": "High Priority Scan",
            "uses": "",
            "run": "echo \"⚠️ HIGH PRIORITY: Scanning top platforms\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/priority-scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"platforms\": [\"reddit\", \"youtube\", \"giphy\", \"pixabay\"], \"maxItems\": 50}' \\\n  --fail --show-error --retry 2\n"
          },
          {
            "name": "Normal Scan",
            "uses": "",
            "run": "echo \"📡 Normal scan of select platforms\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/content/normal-scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"platforms\": [\"reddit\", \"giphy\", \"bluesky\"], \"maxItems\": 25}' \\\n  --fail --show-error --retry 2\n"
          },
          {
            "name": "Report Scan Results",
            "uses": "",
            "run": "echo \"📊 Scan completed for urgency level: ${{ needs.check-queue-health.outputs.urgency }}\"\necho \"Queue had ${{ needs.check-queue-health.outputs.approved_count }} approved items\"\necho \"Estimated ${{ needs.check-queue-health.outputs.days_left }} days of content\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/runbook-artifact.yml",
    "name": "📋 Generate Runbook Artifacts",
    "on": {
      "push": {
        "branches": [
          "main"
        ],
        "paths": [
          "docs/runbook.md",
          "scripts/md-to-pdf.ts",
          ".github/workflows/runbook-artifact.yml"
        ]
      },
      "workflow_dispatch": {
        "inputs": {
          "force_regenerate": {
            "description": "Force regenerate all artifacts",
            "required": false,
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "generate-runbook-artifacts",
        "runsOn": "ubuntu-latest",
        "permissions": {
          "contents": "read",
          "actions": "write"
        },
        "steps": [
          {
            "name": "📥 Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "📋 Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "📦 Install dependencies",
            "uses": "",
            "run": "npm ci\n# Install additional system dependencies for PDF generation\nsudo apt-get update\nsudo apt-get install -y fonts-liberation fonts-dejavu-core\n"
          },
          {
            "name": "📄 Generate PDF from Markdown",
            "uses": "",
            "run": "echo \"🔄 Generating runbook PDF...\"\nnpm run runbook:pdf\n\n# Verify PDF was generated\nif [ ! -f \"docs/runbook.pdf\" ]; then\n  echo \"❌ PDF generation failed\"\n  exit 1\nfi\n\n# Get file size for logging\nPDF_SIZE=$(du -h docs/runbook.pdf | cut -f1)\necho \"✅ PDF generated successfully ($PDF_SIZE)\"\n"
          },
          {
            "name": "📊 Generate metadata",
            "uses": "",
            "run": "echo \"📊 Generating artifact metadata...\"\n\ncat > docs/runbook-metadata.json << EOF\n{\n  \"generated_at\": \"$(date -u -Iseconds)\",\n  \"git_commit\": \"${{ github.sha }}\",\n  \"git_ref\": \"${{ github.ref }}\",\n  \"workflow_run_id\": \"${{ github.run_id }}\",\n  \"workflow_run_number\": \"${{ github.run_number }}\",\n  \"triggered_by\": \"${{ github.event_name }}\",\n  \"actor\": \"${{ github.actor }}\",\n  \"repository\": \"${{ github.repository }}\",\n  \"pdf_size_bytes\": $(stat -c%s docs/runbook.pdf),\n  \"pdf_checksum_sha256\": \"$(sha256sum docs/runbook.pdf | cut -d' ' -f1)\",\n  \"source_files\": [\n    \"docs/runbook.md\",\n    \"scripts/md-to-pdf.ts\"\n  ],\n  \"format_version\": \"1.0.0\"\n}\nEOF\n\necho \"✅ Metadata generated\"\ncat docs/runbook-metadata.json\n"
          },
          {
            "name": "🔍 Validate artifacts",
            "uses": "",
            "run": "echo \"🔍 Validating generated artifacts...\"\n\n# Check PDF is valid (basic validation)\nif file docs/runbook.pdf | grep -q \"PDF\"; then\n  echo \"✅ PDF format validated\"\nelse\n  echo \"❌ Invalid PDF format\"\n  exit 1\nfi\n\n# Check metadata is valid JSON\nif jq . docs/runbook-metadata.json > /dev/null; then\n  echo \"✅ Metadata JSON validated\"\nelse\n  echo \"❌ Invalid metadata JSON\"\n  exit 1\nfi\n\n# Check file sizes are reasonable\nPDF_SIZE_BYTES=$(stat -c%s docs/runbook.pdf)\nif [ $PDF_SIZE_BYTES -lt 10000 ]; then\n  echo \"❌ PDF suspiciously small ($PDF_SIZE_BYTES bytes)\"\n  exit 1\nelif [ $PDF_SIZE_BYTES -gt 50000000 ]; then\n  echo \"❌ PDF suspiciously large ($PDF_SIZE_BYTES bytes)\"\n  exit 1\nelse\n  echo \"✅ PDF size reasonable ($PDF_SIZE_BYTES bytes)\"\nfi\n"
          },
          {
            "name": "📤 Upload runbook artifacts",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📤 Upload latest runbook (overwrites)",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📋 Generate summary",
            "uses": "",
            "run": "echo \"## 📋 Runbook Artifacts Generated\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Generated at:** $(date -u -Iseconds)\" >> $GITHUB_STEP_SUMMARY\necho \"**Commit:** \\`${{ github.sha }}\\`\" >> $GITHUB_STEP_SUMMARY\necho \"**Triggered by:** ${{ github.event_name }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### 📄 Generated Files\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| File | Size | SHA256 |\" >> $GITHUB_STEP_SUMMARY\necho \"|------|------|---------|\" >> $GITHUB_STEP_SUMMARY\necho \"| \\`docs/runbook.pdf\\` | $(du -h docs/runbook.pdf | cut -f1) | \\`$(sha256sum docs/runbook.pdf | cut -d' ' -f1 | head -c16)...\\` |\" >> $GITHUB_STEP_SUMMARY\necho \"| \\`docs/runbook.md\\` | $(du -h docs/runbook.md | cut -f1) | \\`$(sha256sum docs/runbook.md | cut -d' ' -f1 | head -c16)...\\` |\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"### 📤 Artifact Downloads\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"- **Versioned:** \\`sre-runbook-${{ github.run_number }}\\`\" >> $GITHUB_STEP_SUMMARY\necho \"- **Latest:** \\`sre-runbook-latest\\`\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"✅ All artifacts generated successfully!\" >> $GITHUB_STEP_SUMMARY\n"
          },
          {
            "name": "✅ Complete",
            "uses": "",
            "run": "echo \"🎉 Runbook artifact generation completed successfully!\"\necho \"\"\necho \"📦 Artifacts available:\"\necho \"  - sre-runbook-${{ github.run_number }} (versioned)\"\necho \"  - sre-runbook-latest (always current)\"\necho \"\"\necho \"📄 Generated files:\"\nls -la docs/runbook.*\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/scan-bluesky.yml",
    "name": "Scan Bluesky for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 1,9,17 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-bluesky",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Bluesky",
            "uses": "",
            "run": "echo \"🦋 Scanning Bluesky for hotdog posts...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/bluesky/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2 --retry-delay 5\n\necho \"✅ Bluesky scan completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"❌ Bluesky scanning failed - will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-giphy.yml",
    "name": "Scan Giphy for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 2,10,18 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-giphy",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Giphy",
            "uses": "",
            "run": "echo \"🎭 Scanning Giphy for hotdog GIFs...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/giphy/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2 --retry-delay 5\n\necho \"✅ Giphy scan completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"❌ Giphy scanning failed - will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-imgur.yml",
    "name": "Scan Imgur for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 4,12,20 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-imgur",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Imgur",
            "uses": "",
            "run": "echo \"🖼️ Scanning Imgur for hotdog images...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/imgur/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2 --retry-delay 5\n\necho \"✅ Imgur scan completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"❌ Imgur scanning failed - will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-lemmy.yml",
    "name": "Scan Lemmy for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 5,13,21 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-lemmy",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Lemmy",
            "uses": "",
            "run": "echo \"🌐 Scanning Lemmy for hotdog content...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/lemmy/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 10}' \\\n  --fail --show-error --retry 2 --retry-delay 5 || echo \"⚠️ Lemmy scan failed (continuing)\"\n\necho \"✅ Lemmy scan attempt completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"⚠️ Lemmy scanning failed - this is expected occasionally\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-niche-platforms.yml",
    "name": "Scan Niche Platforms",
    "on": {
      "schedule": [
        {
          "cron": "0 6,14,22 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-lemmy",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Lemmy",
            "uses": "",
            "run": "echo \"🌐 Scanning Lemmy for hotdog content...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/lemmy/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 10}' \\\n  --fail --show-error --retry 2 || echo \"⚠️ Lemmy scan failed (continuing)\"\n\necho \"✅ Lemmy scan attempt completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "scan-tumblr",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Tumblr",
            "uses": "",
            "run": "echo \"🎨 Scanning Tumblr for hotdog content...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/tumblr/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 10}' \\\n  --fail --show-error --retry 2 || echo \"⚠️ Tumblr scan failed (continuing)\"\n\necho \"✅ Tumblr scan attempt completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-pixabay.yml",
    "name": "Scan Pixabay for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 3,11,19 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-pixabay",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Pixabay",
            "uses": "",
            "run": "echo \"📸 Scanning Pixabay for hotdog images...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/pixabay/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2 --retry-delay 5\n\necho \"✅ Pixabay scan completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"❌ Pixabay scanning failed - will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-reddit.yml",
    "name": "Scan Reddit for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 2,10,18 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-reddit",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Reddit",
            "uses": "",
            "run": "echo \"🤖 Scanning Reddit for hotdog content...\"\n\nRESULT=$(curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/reddit/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 20}' \\\n  --silent --show-error --retry 2)\n\nif [ $? -eq 0 ]; then\n  FOUND=$(echo \"$RESULT\" | jq -r '.totalFound // 0')\n  PROCESSED=$(echo \"$RESULT\" | jq -r '.processed // 0')\n  echo \"✅ Reddit scan successful: Found $FOUND, processed $PROCESSED\"\nelse\n  echo \"❌ Reddit scan failed\"\n  exit 1\nfi\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"❌ Reddit scanning failed - will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-social-platforms.yml",
    "name": "Scan Social Platforms",
    "on": {
      "schedule": [
        {
          "cron": "0 1,9,17 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-giphy",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Giphy",
            "uses": "",
            "run": "echo \"🎭 Scanning Giphy for hotdog GIFs...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/giphy/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2\n\necho \"✅ Giphy scan completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "scan-bluesky",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Bluesky",
            "uses": "",
            "run": "echo \"🦋 Scanning Bluesky for hotdog posts...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/bluesky/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2\n\necho \"✅ Bluesky scan completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "scan-imgur",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Imgur",
            "uses": "",
            "run": "echo \"🖼️ Scanning Imgur for hotdog images...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/imgur/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2\n\necho \"✅ Imgur scan completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "scan-pixabay",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Pixabay",
            "uses": "",
            "run": "echo \"📸 Scanning Pixabay for hotdog images...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/pixabay/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 15}' \\\n  --fail --show-error --retry 2\n\necho \"✅ Pixabay scan completed\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-tumblr.yml",
    "name": "Scan Tumblr for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 6,14,22 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-tumblr",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan Tumblr",
            "uses": "",
            "run": "echo \"🎨 Scanning Tumblr for hotdog content...\"\n\ncurl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/tumblr/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 10}' \\\n  --fail --show-error --retry 2 --retry-delay 5 || echo \"⚠️ Tumblr scan failed (continuing)\"\n\necho \"✅ Tumblr scan attempt completed\"\n"
          },
          {
            "name": "Handle Scan Failure",
            "uses": "",
            "run": "echo \"⚠️ Tumblr scanning failed - this is expected occasionally\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scan-youtube.yml",
    "name": "Scan YouTube for Content",
    "on": {
      "schedule": [
        {
          "cron": "0 4,16 * * *"
        }
      ],
      "workflow_dispatch": null
    },
    "jobs": [
      {
        "jobName": "scan-youtube",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Scan YouTube",
            "uses": "",
            "run": "echo \"🎬 Scanning YouTube for hotdog content...\"\n\nRESULT=$(curl -L -X POST \"${{ secrets.SITE_URL }}/api/admin/youtube/scan\" \\\n  -H \"Authorization: Bearer ${{ secrets.AUTH_TOKEN }}\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"maxPosts\": 10}' \\\n  --silent --show-error --retry 2)\n\nif [ $? -eq 0 ]; then\n  FOUND=$(echo \"$RESULT\" | jq -r '.totalFound // 0')\n  PROCESSED=$(echo \"$RESULT\" | jq -r '.processed // 0')\n  echo \"✅ YouTube scan successful: Found $FOUND, processed $PROCESSED\"\nelse\n  echo \"❌ YouTube scan failed (possibly quota exceeded)\"\nfi\n"
          },
          {
            "name": "Handle Quota Issues",
            "uses": "",
            "run": "echo \"⚠️ YouTube scan failed - likely quota limit reached\"\necho \"Will retry on next scheduled run\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL }}",
          "{{ secrets.AUTH_TOKEN }}"
        ]
      }
    ]
  },
  {
    "file": ".github/workflows/scanners.yml",
    "name": "Content Scanners",
    "on": {
      "schedule": [
        {
          "cron": "0 */4 * * *"
        },
        {
          "cron": "30 */6 * * *"
        },
        {
          "cron": "15 */8 * * *"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "platforms": {
            "description": "Platforms to scan (comma-separated: reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay,niche)",
            "type": "string",
            "default": "all"
          },
          "max-posts": {
            "description": "Maximum posts per platform",
            "type": "number",
            "default": 50
          }
        }
      },
      "workflow_call": {
        "inputs": {
          "platforms": {
            "description": "Platforms to scan",
            "type": "string",
            "default": "all"
          },
          "max-posts": {
            "description": "Maximum posts per platform",
            "type": "number",
            "default": 50
          }
        }
      }
    },
    "concurrency": {
      "group": "scanners-${{ github.ref }}",
      "cancel-in-progress": false
    },
    "jobs": [
      {
        "jobName": "plan-scans",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "env": {
          "TARGET_URL": "${{ vars.SITE_URL || secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}",
          "SUPABASE_URL": "${{ secrets.SUPABASE_URL }}",
          "SUPABASE_SERVICE_ROLE_KEY": "${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}",
          "SCAN_MIN_PER_PLATFORM": "${{ vars.SCAN_MIN_PER_PLATFORM || '40' }}",
          "SCAN_MAX_PER_PLATFORM": "${{ vars.SCAN_MAX_PER_PLATFORM || '120' }}",
          "SCAN_GLOBAL_MAX": "${{ vars.SCAN_GLOBAL_MAX || '800' }}",
          "SCAN_COOLDOWN_MIN": "${{ vars.SCAN_COOLDOWN_MIN || '180' }}",
          "MIN_CONF": "${{ vars.MIN_CONF || '0.70' }}",
          "MIN_CANDIDATES": "${{ vars.MIN_CANDIDATES || '20' }}",
          "PLATFORM_ALLOW": "${{ vars.PLATFORM_ALLOW || 'reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay' }}"
        },
        "steps": [
          {
            "name": "",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "echo \"📦 Installing dependencies for planner tests...\"\nnpm ci --prefer-offline --no-audit --no-fund\n"
          },
          {
            "name": "Runtime policy guard",
            "uses": "",
            "run": "echo \"🛡️ Running runtime policy enforcement...\"\n\n# Verify planner tests pass before allowing scans\nif ! npm run test:planner --silent >/dev/null 2>&1; then\n  echo \"❌ POLICY VIOLATION: Planner contract tests failed\"\n  echo \"🚨 Blocking scan execution for safety\"\n  echo \"policy-violation=true\" >> $GITHUB_OUTPUT\n  exit 1\nfi\n\necho \"✅ Policy guard passed - planner behavior validated\"\necho \"policy-violation=false\" >> $GITHUB_OUTPUT\n"
          },
          {
            "name": "Build scan plan",
            "uses": "",
            "run": "echo \"🔍 Analyzing queue depths and planning scans...\"\nnode scripts/scan-plan.mjs 2>&1 | tee plan_stdout.txt || true\n\n# Check if matrix has any work\nif [ -f scan_matrix.json ]; then\n  matrix=$(cat scan_matrix.json)\n  has_work=$(echo \"$matrix\" | jq -r 'if .include | length > 0 then \"true\" else \"false\" end')\nelse\n  matrix='{\"include\":[]}'\n  has_work='false'\nfi\n\n# Output for next job\necho \"matrix=$matrix\" >> $GITHUB_OUTPUT\necho \"has_work=$has_work\" >> $GITHUB_OUTPUT\n\n# Handle policy guard results\npolicy_status=\"Unknown\"\nif [ \"${{ steps.policy-guard.outputs.policy-violation }}\" = \"true\" ]; then\n  policy_status=\"❌ VIOLATION - Scan blocked\"\n  echo \"reason=policy_violation\" >> $GITHUB_OUTPUT\nelif [ \"${{ steps.policy-guard.outputs.policy-violation }}\" = \"false\" ]; then\n  policy_status=\"✅ Passed\"\nfi\n\n# Summary for UI\necho \"## 📊 Scan Planning Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Policy Guard:** $policy_status\" >> $GITHUB_STEP_SUMMARY\n\nif [ -f scan_plan.json ]; then\n  reason=$(jq -r '.analysis.reason // \"unknown\"' scan_plan.json)\n  echo \"reason=$reason\" >> $GITHUB_OUTPUT\n  echo \"**Reason:** $reason\" >> $GITHUB_STEP_SUMMARY\n  echo \"**Platforms to scan:** $(echo \"$matrix\" | jq -r '.include | length')\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  \n  if [ \"$has_work\" = \"true\" ]; then\n    echo \"### Platforms Needing Content\" >> $GITHUB_STEP_SUMMARY\n    echo \"| Platform | Desired Posts |\" >> $GITHUB_STEP_SUMMARY\n    echo \"|----------|---------------|\" >> $GITHUB_STEP_SUMMARY\n    echo \"$matrix\" | jq -r '.include[] | \"| \\(.platform) | \\(.desired) |\"' >> $GITHUB_STEP_SUMMARY\n  else\n    echo \"✅ All platforms have sufficient content queued!\" >> $GITHUB_STEP_SUMMARY\n  fi\nelse\n  echo \"**Status:** Scan planning blocked due to policy violation\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"⚠️ **SAFETY BLOCK**: Planner contract tests failed. Scans are disabled until issues are resolved.\" >> $GITHUB_STEP_SUMMARY\nfi\n"
          },
          {
            "name": "Upload plan artifacts",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ vars.SITE_URL || secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}",
          "{{ secrets.SUPABASE_URL }}",
          "{{ secrets.SUPABASE_SERVICE_ROLE_KEY }}",
          "{{ vars.SCAN_MIN_PER_PLATFORM || '40' }}",
          "{{ vars.SCAN_MAX_PER_PLATFORM || '120' }}",
          "{{ vars.SCAN_GLOBAL_MAX || '800' }}",
          "{{ vars.SCAN_COOLDOWN_MIN || '180' }}",
          "{{ vars.MIN_CONF || '0.70' }}",
          "{{ vars.MIN_CANDIDATES || '20' }}",
          "{{ vars.PLATFORM_ALLOW || 'reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay' }}"
        ]
      },
      {
        "jobName": "determine-platforms",
        "runsOn": "ubuntu-latest",
        "timeout": 2,
        "steps": [
          {
            "name": "Determine scan strategy",
            "uses": "",
            "run": "PLATFORMS=\"${{ inputs.platforms || 'all' }}\"\nSCHEDULE_TYPE=\"manual\"\n\n# Determine platforms based on trigger\nif [[ \"${{ github.event_name }}\" == \"schedule\" ]]; then\n  SCHEDULE_TYPE=\"scheduled\"\n  \n  # Determine which platforms based on cron time\n  HOUR=$(date +%H)\n  MINUTE=$(date +%M)\n  \n  if [[ $MINUTE -eq 0 ]]; then\n    # Every 4 hours (0, 4, 8, 12, 16, 20) - high volume\n    PLATFORMS=\"reddit,youtube,giphy\"\n    echo \"🔄 High-volume scan: reddit,youtube,giphy\"\n  elif [[ $MINUTE -eq 30 ]]; then\n    # Every 6 hours (00:30, 06:30, 12:30, 18:30) - medium volume  \n    PLATFORMS=\"imgur,bluesky,tumblr\"\n    echo \"🔄 Medium-volume scan: imgur,bluesky,tumblr\"\n  elif [[ $MINUTE -eq 15 ]]; then\n    # Every 8 hours (00:15, 08:15, 16:15) - low volume\n    PLATFORMS=\"lemmy,pixabay,niche\"\n    echo \"🔄 Low-volume scan: lemmy,pixabay,niche\"\n  fi\nfi\n\nif [[ \"$PLATFORMS\" == \"all\" ]]; then\n  PLATFORMS=\"reddit,youtube,giphy,imgur,bluesky,tumblr,lemmy,pixabay,niche\"\nfi\n\necho \"platforms=$PLATFORMS\" >> $GITHUB_OUTPUT\necho \"schedule-type=$SCHEDULE_TYPE\" >> $GITHUB_OUTPUT\necho \"Selected platforms: $PLATFORMS\"\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "demand-driven-scan",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "strategy": {
          "fail-fast": false,
          "max-parallel": 3,
          "matrix": "${{ fromJSON(needs.plan-scans.outputs.matrix) }}"
        },
        "needs": "plan-scans",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Platform-specific setup",
            "uses": "",
            "run": "echo \"🔧 Setting up environment for ${{ matrix.platform }}...\"\necho \"📊 Target: ${{ matrix.desired }} posts\"\n\ncase \"${{ matrix.platform }}\" in\n  reddit)\n    echo \"REDDIT_CLIENT_ID=${{ secrets.REDDIT_CLIENT_ID }}\" >> $GITHUB_ENV\n    echo \"REDDIT_CLIENT_SECRET=${{ secrets.REDDIT_CLIENT_SECRET }}\" >> $GITHUB_ENV\n    ;;\n  youtube)\n    echo \"YOUTUBE_API_KEY=${{ secrets.YOUTUBE_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  giphy)\n    echo \"GIPHY_API_KEY=${{ secrets.GIPHY_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  imgur)\n    echo \"IMGUR_CLIENT_ID=${{ secrets.IMGUR_CLIENT_ID }}\" >> $GITHUB_ENV\n    ;;\n  bluesky)\n    echo \"BLUESKY_IDENTIFIER=${{ secrets.BLUESKY_IDENTIFIER }}\" >> $GITHUB_ENV\n    echo \"BLUESKY_APP_PASSWORD=${{ secrets.BLUESKY_APP_PASSWORD }}\" >> $GITHUB_ENV\n    ;;\n  pixabay)\n    echo \"PIXABAY_API_KEY=${{ secrets.PIXABAY_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  tumblr)\n    echo \"TUMBLR_API_KEY=${{ secrets.TUMBLR_API_KEY }}\" >> $GITHUB_ENV\n    ;;\nesac\n"
          },
          {
            "name": "Scan platform content",
            "uses": "",
            "run": "echo \"📡 Scanning ${{ matrix.platform }} for hotdog content...\"\necho \"🎯 Targeting ${{ matrix.desired }} posts based on queue deficit\"\n\n# Use the desired count from the planning phase\nMAX_POSTS=\"${{ matrix.desired }}\"\n\ncase \"${{ matrix.platform }}\" in\n  reddit)\n    npm run scan:reddit -- --max-posts=$MAX_POSTS || true\n    ;;\n  youtube)\n    npm run scan:youtube -- --max-posts=$MAX_POSTS || true\n    ;;\n  giphy)\n    npm run scan:giphy -- --max-posts=$MAX_POSTS || true\n    ;;\n  imgur)\n    npm run scan:imgur -- --max-posts=$MAX_POSTS || true\n    ;;\n  bluesky)\n    npm run scan:bluesky -- --max-posts=$MAX_POSTS || true\n    ;;\n  tumblr)\n    npm run scan:tumblr -- --max-posts=$MAX_POSTS || true\n    ;;\n  lemmy)\n    npm run scan:lemmy -- --max-posts=$MAX_POSTS || true\n    ;;\n  pixabay)\n    npm run scan:pixabay -- --max-posts=$MAX_POSTS || true\n    ;;\n  *)\n    echo \"❌ Unknown platform: ${{ matrix.platform }}\"\n    ;;\nesac\n\necho \"✅ Scan completed for ${{ matrix.platform }}\"\n"
          },
          {
            "name": "Upload scan logs",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.REDDIT_CLIENT_ID }}",
          "{{ secrets.REDDIT_CLIENT_SECRET }}",
          "{{ secrets.YOUTUBE_API_KEY }}",
          "{{ secrets.GIPHY_API_KEY }}",
          "{{ secrets.IMGUR_CLIENT_ID }}",
          "{{ secrets.BLUESKY_IDENTIFIER }}",
          "{{ secrets.BLUESKY_APP_PASSWORD }}",
          "{{ secrets.PIXABAY_API_KEY }}",
          "{{ secrets.TUMBLR_API_KEY }}"
        ]
      },
      {
        "jobName": "scan",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "strategy": {
          "fail-fast": false,
          "max-parallel": 3,
          "matrix": {
            "platform": "${{ fromJSON(format('[{0}]', replace(replace(needs.determine-platforms.outputs.platforms, ' ', ''), ',', '\",\"'))) }}"
          }
        },
        "needs": "determine-platforms",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Platform-specific setup",
            "uses": "",
            "run": "echo \"🔧 Setting up environment for ${{ matrix.platform }}...\"\n\ncase \"${{ matrix.platform }}\" in\n  reddit)\n    echo \"REDDIT_CLIENT_ID=${{ secrets.REDDIT_CLIENT_ID }}\" >> $GITHUB_ENV\n    echo \"REDDIT_CLIENT_SECRET=${{ secrets.REDDIT_CLIENT_SECRET }}\" >> $GITHUB_ENV\n    ;;\n  youtube)\n    echo \"YOUTUBE_API_KEY=${{ secrets.YOUTUBE_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  giphy)\n    echo \"GIPHY_API_KEY=${{ secrets.GIPHY_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  imgur)\n    echo \"IMGUR_CLIENT_ID=${{ secrets.IMGUR_CLIENT_ID }}\" >> $GITHUB_ENV\n    ;;\n  bluesky)\n    echo \"BLUESKY_IDENTIFIER=${{ secrets.BLUESKY_IDENTIFIER }}\" >> $GITHUB_ENV\n    echo \"BLUESKY_APP_PASSWORD=${{ secrets.BLUESKY_APP_PASSWORD }}\" >> $GITHUB_ENV\n    ;;\n  pixabay)\n    echo \"PIXABAY_API_KEY=${{ secrets.PIXABAY_API_KEY }}\" >> $GITHUB_ENV\n    ;;\n  niche)\n    # Niche platforms may use multiple APIs\n    echo \"LEMMY_INSTANCE_URL=${{ secrets.LEMMY_INSTANCE_URL }}\" >> $GITHUB_ENV\n    echo \"TUMBLR_API_KEY=${{ secrets.TUMBLR_API_KEY }}\" >> $GITHUB_ENV\n    ;;\nesac\n"
          },
          {
            "name": "Scan platform content",
            "uses": "",
            "run": "echo \"📡 Scanning ${{ matrix.platform }} for hotdog content...\"\n\nMAX_POSTS=\"${{ inputs.max-posts || 50 }}\"\n\ncase \"${{ matrix.platform }}\" in\n  reddit)\n    npm run scan:reddit -- --max-posts=$MAX_POSTS\n    ;;\n  youtube)\n    npm run scan:youtube -- --max-posts=$MAX_POSTS\n    ;;\n  giphy)\n    npm run scan:giphy -- --max-posts=$MAX_POSTS\n    ;;\n  imgur)\n    npm run scan:imgur -- --max-posts=$MAX_POSTS\n    ;;\n  bluesky)\n    npm run scan:bluesky -- --max-posts=$MAX_POSTS\n    ;;\n  tumblr)\n    npm run scan:tumblr -- --max-posts=$MAX_POSTS\n    ;;\n  lemmy)\n    npm run scan:lemmy -- --max-posts=$MAX_POSTS\n    ;;\n  pixabay)\n    npm run scan:pixabay -- --max-posts=$MAX_POSTS\n    ;;\n  niche)\n    # Scan multiple niche platforms with smaller limits\n    npm run scan:niche-platforms -- --max-posts=20\n    ;;\n  *)\n    echo \"❌ Unknown platform: ${{ matrix.platform }}\"\n    exit 1\n    ;;\nesac\n\necho \"✅ Scan completed for ${{ matrix.platform }}\"\n"
          },
          {
            "name": "Upload scan logs",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.REDDIT_CLIENT_ID }}",
          "{{ secrets.REDDIT_CLIENT_SECRET }}",
          "{{ secrets.YOUTUBE_API_KEY }}",
          "{{ secrets.GIPHY_API_KEY }}",
          "{{ secrets.IMGUR_CLIENT_ID }}",
          "{{ secrets.BLUESKY_IDENTIFIER }}",
          "{{ secrets.BLUESKY_APP_PASSWORD }}",
          "{{ secrets.PIXABAY_API_KEY }}",
          "{{ secrets.LEMMY_INSTANCE_URL }}",
          "{{ secrets.TUMBLR_API_KEY }}"
        ]
      },
      {
        "jobName": "summary",
        "runsOn": "ubuntu-latest",
        "needs": [
          "plan-scans",
          "demand-driven-scan",
          "determine-platforms",
          "scan"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Generate scan summary",
            "uses": "",
            "run": "echo \"📊 Generating content scan summary...\"\nnpm run scan:summary || echo \"Summary generation completed\"\n"
          },
          {
            "name": "Create GitHub step summary",
            "uses": "",
            "run": "echo \"## 📡 Content Scanner Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Trigger:** ${{ github.event_name }}\" >> $GITHUB_STEP_SUMMARY\n\n# Check if demand-driven or legacy\nif [ \"${{ needs.plan-scans.outputs.reason }}\" != \"\" ]; then\n  echo \"**Mode:** Demand-Driven\" >> $GITHUB_STEP_SUMMARY\n  echo \"**Reason:** ${{ needs.plan-scans.outputs.reason }}\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"**Mode:** Legacy/Manual\" >> $GITHUB_STEP_SUMMARY\n  echo \"**Schedule Type:** ${{ needs.determine-platforms.outputs.schedule-type }}\" >> $GITHUB_STEP_SUMMARY\n  echo \"**Platforms:** ${{ needs.determine-platforms.outputs.platforms }}\" >> $GITHUB_STEP_SUMMARY\nfi\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Platform | Status | Notes |\" >> $GITHUB_STEP_SUMMARY\necho \"|----------|--------|-------|\" >> $GITHUB_STEP_SUMMARY\n\n# Create a simplified status report\nPLATFORMS=($(echo \"${{ needs.determine-platforms.outputs.platforms }}\" | tr ',' ' '))\nfor platform in \"${PLATFORMS[@]}\"; do\n  STATUS=\"unknown\"\n  # This is simplified - you'd need to extract actual results\n  echo \"| $platform | $STATUS | Scan attempted |\" >> $GITHUB_STEP_SUMMARY\ndone\n\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"📈 **Next Steps:**\" >> $GITHUB_STEP_SUMMARY\necho \"- Content will be queued for review and scheduling\" >> $GITHUB_STEP_SUMMARY\necho \"- Check admin dashboard for new content\" >> $GITHUB_STEP_SUMMARY\n"
          },
          {
            "name": "Upload summary report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "rate-limit-check",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "needs": "scan",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Check API rate limits",
            "uses": "",
            "run": "echo \"🔍 Checking API rate limit status...\"\n\n# Check rate limits for various APIs\necho \"API Rate Limit Status:\" >> rate-limit-report.md\necho \"=====================\" >> rate-limit-report.md\necho \"\" >> rate-limit-report.md\n\n# This would ideally query actual rate limit status\necho \"- Reddit API: $(date)\" >> rate-limit-report.md\necho \"- YouTube API: $(date)\" >> rate-limit-report.md\necho \"- Giphy API: $(date)\" >> rate-limit-report.md\necho \"- Imgur API: $(date)\" >> rate-limit-report.md\necho \"\" >> rate-limit-report.md\necho \"Generated at: $(date)\" >> rate-limit-report.md\n\necho \"✅ Rate limit check completed\"\n"
          },
          {
            "name": "Upload rate limit report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/scheduler.yml",
    "name": "Content Scheduler",
    "on": {
      "schedule": [
        {
          "cron": "0 1 * * *"
        },
        {
          "cron": "0 12 * * *"
        },
        {
          "cron": "0 0 * * 0"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "operation": {
            "description": "Operation to perform",
            "type": "choice",
            "options": [
              "refill",
              "forecast",
              "reconcile",
              "twoDays"
            ],
            "default": "refill"
          },
          "days": {
            "description": "Number of days (for refill/forecast)",
            "type": "number",
            "default": 2
          }
        }
      },
      "workflow_call": {
        "inputs": {
          "operation": {
            "description": "Operation to perform",
            "type": "string",
            "default": "refill"
          },
          "days": {
            "description": "Number of days",
            "type": "number",
            "default": 2
          }
        }
      }
    },
    "concurrency": {
      "group": "scheduler-${{ github.ref }}-${{ inputs.operation || 'scheduled' }}",
      "cancel-in-progress": true
    },
    "jobs": [
      {
        "jobName": "determine-operation",
        "runsOn": "ubuntu-latest",
        "timeout": 2,
        "steps": [
          {
            "name": "Determine operation strategy",
            "uses": "",
            "run": "OPERATION=\"${{ inputs.operation || 'refill' }}\"\nDAYS=\"${{ inputs.days || 2 }}\"\n\n# Determine operation based on schedule\nif [[ \"${{ github.event_name }}\" == \"schedule\" ]]; then\n  HOUR=$(date +%H)\n  \n  if [[ $HOUR -eq 1 ]]; then\n    OPERATION=\"refill\"\n    DAYS=2\n    echo \"🌅 Morning refill - scheduling next 2 days\"\n  elif [[ $HOUR -eq 12 ]]; then\n    OPERATION=\"forecast\"\n    DAYS=3\n    echo \"🌞 Midday forecast check - analyzing next 3 days\"\n  elif [[ $HOUR -eq 0 ]]; then\n    OPERATION=\"reconcile\"\n    DAYS=7\n    echo \"🌙 Weekly reconcile - checking past 7 days\"\n  fi\nfi\n\necho \"operation=$OPERATION\" >> $GITHUB_OUTPUT\necho \"days=$DAYS\" >> $GITHUB_OUTPUT\necho \"auth-token=${{ secrets.AUTH_TOKEN }}\" >> $GITHUB_OUTPUT\necho \"Selected operation: $OPERATION for $DAYS days\"\n"
          }
        ],
        "secretRefs": [
          "{{ secrets.AUTH_TOKEN }}"
        ]
      },
      {
        "jobName": "refill",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": "determine-operation",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Refill content schedule",
            "uses": "",
            "run": "echo \"🔄 Refilling content schedule for ${{ needs.determine-operation.outputs.days }} days...\"\n\nDAYS=\"${{ needs.determine-operation.outputs.days }}\"\nAUTH_TOKEN=\"${{ needs.determine-operation.outputs.auth-token }}\"\n\n# Call the refill API endpoint\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -X POST \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"days\\\": $DAYS}\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/schedule/refill\" \\\n  --max-time 300)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\necho \"refill-status=$HTTP_STATUS\" >> $GITHUB_OUTPUT\necho \"refill-response<<EOF\" >> $GITHUB_OUTPUT\necho \"$BODY\" >> $GITHUB_OUTPUT\necho \"EOF\" >> $GITHUB_OUTPUT\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Schedule refill completed successfully\"\nelse\n  echo \"❌ Schedule refill failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\n  exit 1\nfi\n"
          },
          {
            "name": "Upload refill logs",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "forecast",
        "runsOn": "ubuntu-latest",
        "timeout": 8,
        "needs": "determine-operation",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Generate schedule forecast",
            "uses": "",
            "run": "echo \"🔮 Generating schedule forecast for ${{ needs.determine-operation.outputs.days }} days...\"\n\nDAYS=\"${{ needs.determine-operation.outputs.days }}\"\nAUTH_TOKEN=\"${{ needs.determine-operation.outputs.auth-token }}\"\n\n# Get forecast for multiple days\nfor i in $(seq 0 $((DAYS-1))); do\n  DATE=$(date -d \"+$i days\" +%Y-%m-%d)\n  echo \"📅 Generating forecast for $DATE...\"\n  \n  RESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n    \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/schedule/forecast?date=$DATE\" \\\n    --max-time 60)\n  \n  HTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\n  BODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n  \n  if [ \"$HTTP_STATUS\" -eq 200 ]; then\n    echo \"✅ Forecast for $DATE generated successfully\"\n    echo \"$BODY\" > \"forecast-$DATE.json\"\n  else\n    echo \"⚠️ Forecast for $DATE failed with status $HTTP_STATUS\"\n    echo \"Response: $BODY\"\n  fi\ndone\n\necho \"✅ Forecast generation completed\"\n"
          },
          {
            "name": "Upload forecast reports",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "reconcile",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "needs": "determine-operation",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Reconcile content and schedule",
            "uses": "",
            "run": "echo \"🔄 Reconciling content and schedule for past ${{ needs.determine-operation.outputs.days }} days...\"\n\nDAYS=\"${{ needs.determine-operation.outputs.days }}\"\nAUTH_TOKEN=\"${{ needs.determine-operation.outputs.auth-token }}\"\n\n# Call the reconcile API endpoint\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -X POST \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"days\\\": $DAYS}\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/schedule/reconcile\" \\\n  --max-time 600)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\necho \"reconcile-status=$HTTP_STATUS\" >> $GITHUB_OUTPUT\necho \"reconcile-response<<EOF\" >> $GITHUB_OUTPUT\necho \"$BODY\" >> $GITHUB_OUTPUT\necho \"EOF\" >> $GITHUB_OUTPUT\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Content reconciliation completed successfully\"\nelse\n  echo \"❌ Content reconciliation failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\n  exit 1\nfi\n"
          },
          {
            "name": "Upload reconcile logs",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "queue-health",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "needs": [
          "determine-operation",
          "refill",
          "forecast",
          "reconcile"
        ],
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Setup Supabase environment",
            "uses": "./.github/actions/setup-supabase-rest"
          },
          {
            "name": "Check queue health",
            "uses": "",
            "run": "echo \"🏥 Checking content queue health...\"\n\nAUTH_TOKEN=\"${{ needs.determine-operation.outputs.auth-token }}\"\n\n# Get queue metrics\nRESPONSE=$(curl -s -w \"HTTPSTATUS:%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  \"${{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}/api/admin/metrics\" \\\n  --max-time 30)\n\nHTTP_STATUS=$(echo $RESPONSE | tr -d '\\n' | sed -e 's/.*HTTPSTATUS://')\nBODY=$(echo $RESPONSE | sed -e 's/HTTPSTATUS:.*//')\n\nif [ \"$HTTP_STATUS\" -eq 200 ]; then\n  echo \"✅ Queue health check completed\"\n  echo \"$BODY\" > queue-health.json\nelse\n  echo \"⚠️ Queue health check failed with status $HTTP_STATUS\"\n  echo \"Response: $BODY\"\nfi\n"
          },
          {
            "name": "Upload health report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": [
          "{{ secrets.SITE_URL || 'https://hotdog-diaries.vercel.app' }}"
        ]
      },
      {
        "jobName": "summary",
        "runsOn": "ubuntu-latest",
        "needs": [
          "determine-operation",
          "refill",
          "forecast",
          "reconcile",
          "queue-health"
        ],
        "steps": [
          {
            "name": "Generate scheduler summary",
            "uses": "",
            "run": "echo \"## 📅 Content Scheduler Results\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Operation:** ${{ needs.determine-operation.outputs.operation }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Days:** ${{ needs.determine-operation.outputs.days }}\" >> $GITHUB_STEP_SUMMARY\necho \"**Trigger:** ${{ github.event_name }}\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"| Job | Status | Notes |\" >> $GITHUB_STEP_SUMMARY\necho \"|-----|--------|-------|\" >> $GITHUB_STEP_SUMMARY\n\n# Add job statuses\nif [[ \"${{ needs.refill.result }}\" != \"\" ]]; then\n  echo \"| Refill | ${{ needs.refill.result }} | Schedule refill operation |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.forecast.result }}\" != \"\" ]]; then\n  echo \"| Forecast | ${{ needs.forecast.result }} | Schedule forecast generation |\" >> $GITHUB_STEP_SUMMARY\nfi\n\nif [[ \"${{ needs.reconcile.result }}\" != \"\" ]]; then\n  echo \"| Reconcile | ${{ needs.reconcile.result }} | Content reconciliation |\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"| Queue Health | ${{ needs.queue-health.result }} | Content queue health check |\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Overall status\nOVERALL_SUCCESS=true\n\nif [[ \"${{ needs.refill.result }}\" == \"failure\" ]] || [[ \"${{ needs.forecast.result }}\" == \"failure\" ]] || [[ \"${{ needs.reconcile.result }}\" == \"failure\" ]]; then\n  OVERALL_SUCCESS=false\nfi\n\nif [[ \"$OVERALL_SUCCESS\" == \"true\" ]]; then\n  echo \"## ✅ Scheduler operations completed successfully\" >> $GITHUB_STEP_SUMMARY\nelse\n  echo \"## ❌ Some scheduler operations failed\" >> $GITHUB_STEP_SUMMARY\n  echo \"Check individual job logs for details.\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"📈 **Next Steps:**\" >> $GITHUB_STEP_SUMMARY\necho \"- Content is scheduled and ready for posting\" >> $GITHUB_STEP_SUMMARY\necho \"- Check admin dashboard for schedule overview\" >> $GITHUB_STEP_SUMMARY\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/secret-validation.yml",
    "name": "Secret Validation",
    "on": {
      "push": {
        "branches": [
          "main",
          "develop"
        ]
      },
      "pull_request": {
        "branches": [
          "main",
          "develop"
        ]
      },
      "schedule": [
        {
          "cron": "0 9 * * 1"
        }
      ]
    },
    "jobs": [
      {
        "jobName": "validate-secrets",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Checkout",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Validate secret strength",
            "uses": "",
            "run": "echo \"🔍 Running secret validation...\"\nnpm run validate-secrets -- --verbose\n"
          },
          {
            "name": "Validate in strict mode",
            "uses": "",
            "run": "echo \"🔒 Running strict validation (warnings = errors)...\"\nnpm run validate-secrets -- --strict\n"
          },
          {
            "name": "Comment on PR (if failed)",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "environment-completeness",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Checkout",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Check environment completeness",
            "uses": "",
            "run": "echo \"📋 Checking environment variable completeness...\"\n\n# Extract all process.env references from codebase\necho \"Variables referenced in codebase:\"\ngrep -r \"process\\.env\\.\" app/ lib/ components/ scripts/ middleware.* next.config.* 2>/dev/null \\\n  | grep -oE 'process\\.env\\.([A-Z_][A-Z0-9_]*)' \\\n  | sed 's/process\\.env\\.//' \\\n  | sort -u \\\n  | tee /tmp/codebase_vars.txt\n\necho \"\"\necho \"Variables in .env.example:\"\nif [ -f .env.example ]; then\n  grep -E '^[A-Z_][A-Z0-9_]*=' .env.example | cut -d= -f1 | sort | tee /tmp/env_example_vars.txt\nelse\n  echo \"⚠️ .env.example not found\"\n  touch /tmp/env_example_vars.txt\nfi\n\necho \"\"\necho \"Missing from .env.example:\"\ncomm -23 /tmp/codebase_vars.txt /tmp/env_example_vars.txt | tee /tmp/missing_vars.txt\n\n# Filter out system variables that don't need to be in .env.example\nSYSTEM_VARS=\"NODE_ENV PORT PWD PATH HOME USER VERCEL VERCEL_ENV VERCEL_URL VERCEL_REGION GITHUB_ACTIONS GITHUB_SHA GITHUB_REF CI BUILD_ID NEXT_RUNTIME\"\n\nfor var in $SYSTEM_VARS; do\n  sed -i \"/^$var$/d\" /tmp/missing_vars.txt 2>/dev/null || true\ndone\n\nif [ -s /tmp/missing_vars.txt ]; then\n  echo \"❌ Missing variables found:\"\n  cat /tmp/missing_vars.txt\n  echo \"\"\n  echo \"Please add these variables to .env.example with appropriate example values.\"\n  exit 1\nelse\n  echo \"✅ All codebase variables are documented in .env.example\"\nfi\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "token-strength-check",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Checkout",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "Install dependencies",
            "uses": "",
            "run": "npm ci"
          },
          {
            "name": "Check token rotation schedule",
            "uses": "",
            "run": "echo \"🗓️ Checking token rotation schedule...\"\n\n# Check if any tokens need rotation based on docs/secrets.md\n# This is a simplified check - in production you might want to store\n# rotation dates in a database or separate tracking system\n\nCURRENT_DATE=$(date +%Y-%m-%d)\necho \"Current date: $CURRENT_DATE\"\n\n# Check docs/secrets.md for last rotation dates\nif [ -f docs/secrets.md ]; then\n  echo \"Last rotation dates from docs/secrets.md:\"\n  grep -E \"JWT_SECRET|AUTH_TOKEN|CRON_TOKEN|ADMIN_PASSWORD\" docs/secrets.md || true\nfi\n\n# Run token validation to ensure current tokens are still strong\nnpm run validate-secrets -- --verbose\n\necho \"📊 Token strength verification completed\"\n"
          },
          {
            "name": "Create rotation issue (if needed)",
            "uses": "actions/github-script@v7"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/spec-drift.yml",
    "name": "OpenAPI Spec Drift Detection",
    "on": {
      "pull_request": {
        "paths": [
          "app/api/**/*.ts",
          "docs/openapi.yaml",
          "docs/openapi.ignore.json",
          "scripts/route-inventory.ts"
        ]
      },
      "push": {
        "branches": [
          "main"
        ],
        "paths": [
          "app/api/**/*.ts",
          "docs/openapi.yaml",
          "docs/openapi.ignore.json"
        ]
      },
      "workflow_dispatch": null,
      "schedule": [
        {
          "cron": "0 6 * * 1"
        }
      ]
    },
    "concurrency": {
      "group": "spec-drift-${{ github.ref }}",
      "cancel-in-progress": true
    },
    "jobs": [
      {
        "jobName": "validate-openapi-spec",
        "runsOn": "ubuntu-latest",
        "timeout": 5,
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Install OpenAPI validation tools",
            "uses": "",
            "run": "npm install -g @redocly/cli swagger-parser\n"
          },
          {
            "name": "Validate OpenAPI specification syntax",
            "uses": "",
            "run": "echo \"🔍 Validating OpenAPI specification syntax...\"\n\n# Check if openapi.yaml exists\nif [ ! -f \"docs/openapi.yaml\" ]; then\n  echo \"❌ OpenAPI specification not found at docs/openapi.yaml\"\n  exit 1\nfi\n\n# Validate with Redocly CLI\necho \"📋 Running Redocly validation...\"\nredocly lint docs/openapi.yaml --skip-rule=no-unused-components\n\n# Validate with swagger-parser (additional validation)\necho \"📋 Running swagger-parser validation...\"\nnpx swagger-parser validate docs/openapi.yaml\n\necho \"✅ OpenAPI specification is valid\"\n"
          },
          {
            "name": "Check specification completeness",
            "uses": "",
            "run": "echo \"🔍 Checking OpenAPI specification completeness...\"\n\n# Check for required sections\nREQUIRED_SECTIONS=(\n  \"openapi\"\n  \"info\"\n  \"servers\"\n  \"paths\"\n  \"components.schemas\"\n  \"components.securitySchemes\"\n)\n\nfor section in \"${REQUIRED_SECTIONS[@]}\"; do\n  if ! yq eval \"has(\\\"${section//./\\\".\\\"}\\\"))\" docs/openapi.yaml | grep -q \"true\"; then\n    echo \"❌ Missing required section: $section\"\n    exit 1\n  fi\n  echo \"✅ Found section: $section\"\ndone\n\n# Check for security schemes\nif ! yq eval '.components.securitySchemes | has(\"AdminToken\")' docs/openapi.yaml | grep -q \"true\"; then\n  echo \"❌ Missing AdminToken security scheme\"\n  exit 1\nfi\n\necho \"✅ OpenAPI specification is complete\"\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "detect-api-drift",
        "runsOn": "ubuntu-latest",
        "timeout": 10,
        "needs": "validate-openapi-spec",
        "steps": [
          {
            "name": "Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Setup Node.js with cache",
            "uses": "./.github/actions/setup-node"
          },
          {
            "name": "Generate current route inventory",
            "uses": "",
            "run": "echo \"🔍 Generating current API route inventory...\"\nnpx tsx scripts/route-inventory.ts\n\n# Show inventory summary\necho \"📊 Current route inventory:\"\ncat docs/api-inventory.json | jq '.totalRoutes, .adminRoutes, .publicRoutes'\n"
          },
          {
            "name": "Load ignore list",
            "uses": "",
            "run": "echo \"📋 Loading route ignore list...\"\n\nif [ -f \"docs/openapi.ignore.json\" ]; then\n  echo \"✅ Found ignore list with $(jq '.ignoredRoutes | length' docs/openapi.ignore.json) entries\"\nelse\n  echo \"⚠️ No ignore list found, creating empty one\"\n  echo '{\"ignoredRoutes\": [], \"ignorePatterns\": []}' > docs/openapi.ignore.json\nfi\n"
          },
          {
            "name": "Extract routes from OpenAPI spec",
            "uses": "",
            "run": "echo \"🔍 Extracting documented routes from OpenAPI spec...\"\n\n# Extract paths from OpenAPI spec\nyq eval '.paths | keys' docs/openapi.yaml | yq eval '.[]' - > documented-routes.txt\n\n# Prefix with /api for comparison\nsed 's|^|/api|' documented-routes.txt > documented-api-routes.txt\n\necho \"📋 Documented routes:\"\ncat documented-api-routes.txt\n"
          },
          {
            "name": "Check for drift",
            "uses": "",
            "run": "echo \"🔍 Checking for API route drift...\"\n\n# Extract actual routes from inventory\njq -r '.routes[].path' docs/api-inventory.json > actual-routes.txt\n\n# Extract ignored routes (exact matches)\njq -r '.ignoredRoutes[].path' docs/openapi.ignore.json > ignored-routes.txt\n\n# Extract ignore patterns\njq -r '.ignorePatterns[].pattern' docs/openapi.ignore.json > ignore-patterns.txt\n\n# Function to check if route matches any ignore pattern\nis_ignored() {\n  local route=\"$1\"\n  \n  # Check exact matches\n  if grep -Fxq \"$route\" ignored-routes.txt 2>/dev/null; then\n    return 0\n  fi\n  \n  # Check patterns\n  while IFS= read -r pattern; do\n    if [[ \"$route\" =~ $pattern ]]; then\n      return 0\n    fi\n  done < ignore-patterns.txt 2>/dev/null\n  \n  return 1\n}\n\n# Find missing routes (in code but not in spec and not ignored)\nMISSING_ROUTES=()\n\nwhile IFS= read -r route; do\n  # Skip empty lines\n  [ -z \"$route\" ] && continue\n  \n  # Check if route is documented or ignored\n  if ! grep -Fxq \"$route\" documented-api-routes.txt && ! is_ignored \"$route\"; then\n    MISSING_ROUTES+=(\"$route\")\n    echo \"❌ Missing from OpenAPI spec: $route\"\n  fi\ndone < actual-routes.txt\n\n# Check results\nif [ ${#MISSING_ROUTES[@]} -eq 0 ]; then\n  echo \"✅ No API drift detected - all routes are documented or ignored\"\n  echo \"drift-detected=false\" >> $GITHUB_OUTPUT\n  echo \"missing-routes=\" >> $GITHUB_OUTPUT\nelse\n  echo \"⚠️ API drift detected! ${#MISSING_ROUTES[@]} undocumented routes found\"\n  \n  # Format missing routes for output\n  MISSING_JSON=$(printf '%s\\n' \"${MISSING_ROUTES[@]}\" | jq -R . | jq -s .)\n  echo \"drift-detected=true\" >> $GITHUB_OUTPUT\n  echo \"missing-routes=$MISSING_JSON\" >> $GITHUB_OUTPUT\n  \n  # Generate suggestions\n  echo \"\"\n  echo \"🔧 To fix this drift, either:\"\n  echo \"1. Add the missing routes to docs/openapi.yaml, or\"\n  echo \"2. Add them to docs/openapi.ignore.json with a reason\"\n  echo \"\"\n  echo \"Missing routes:\"\n  printf '  - %s\\n' \"${MISSING_ROUTES[@]}\"\nfi\n"
          },
          {
            "name": "Upload drift report",
            "uses": "actions/upload-artifact@v4"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "generate-drift-summary",
        "runsOn": "ubuntu-latest",
        "needs": "detect-api-drift",
        "steps": [
          {
            "name": "Generate summary",
            "uses": "",
            "run": "echo \"## 📋 OpenAPI Spec Drift Detection\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\nif [ \"${{ needs.detect-api-drift.outputs.drift-detected }}\" = \"true\" ]; then\n  echo \"### ⚠️ Drift Detected\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"The following API routes exist in code but are not documented in the OpenAPI specification:\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  \n  # Parse missing routes JSON\n  MISSING_ROUTES='${{ needs.detect-api-drift.outputs.missing-routes }}'\n  echo \"$MISSING_ROUTES\" | jq -r '.[]' | while read -r route; do\n    echo \"- \\`$route\\`\" >> $GITHUB_STEP_SUMMARY\n  done\n  \n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"### 🔧 Resolution Options\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"1. **Document the routes**: Add them to \\`docs/openapi.yaml\\` with proper schemas\" >> $GITHUB_STEP_SUMMARY\n  echo \"2. **Ignore the routes**: Add them to \\`docs/openapi.ignore.json\\` with clear reasons\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"### 📖 Documentation\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"- [OpenAPI Specification](./docs/openapi.yaml)\" >> $GITHUB_STEP_SUMMARY\n  echo \"- [Ignore List](./docs/openapi.ignore.json)\" >> $GITHUB_STEP_SUMMARY\n  echo \"- [Route Inventory Script](./scripts/route-inventory.ts)\" >> $GITHUB_STEP_SUMMARY\n  \nelse\n  echo \"### ✅ No Drift Detected\" >> $GITHUB_STEP_SUMMARY\n  echo \"\" >> $GITHUB_STEP_SUMMARY\n  echo \"All API routes are properly documented or ignored. The OpenAPI specification is up to date!\" >> $GITHUB_STEP_SUMMARY\nfi\n\necho \"\" >> $GITHUB_STEP_SUMMARY\necho \"**Workflow**: \\`spec-drift.yml\\`\" >> $GITHUB_STEP_SUMMARY\necho \"**Timestamp**: $(date -Iseconds)\" >> $GITHUB_STEP_SUMMARY\n"
          }
        ],
        "secretRefs": []
      },
      {
        "jobName": "fail-on-drift",
        "runsOn": "ubuntu-latest",
        "needs": "detect-api-drift",
        "steps": [
          {
            "name": "Fail PR on drift",
            "uses": "",
            "run": "echo \"❌ PR blocked due to API specification drift\"\necho \"\"\necho \"The following routes are not documented in the OpenAPI specification:\"\necho '${{ needs.detect-api-drift.outputs.missing-routes }}' | jq -r '.[]'\necho \"\"\necho \"Please update docs/openapi.yaml or docs/openapi.ignore.json before merging.\"\nexit 1\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/token-refresh.yml",
    "name": "Token Refresh (Reusable)",
    "on": {
      "workflow_call": {
        "outputs": {
          "auth_token": {
            "description": "Refreshed authentication token",
            "value": "${{ jobs.refresh.outputs.auth_token }}"
          }
        },
        "secrets": {
          "SITE_URL": {
            "required": true
          },
          "SERVICE_ACCOUNT_SECRET": {
            "required": false
          },
          "REFRESH_TOKEN": {
            "required": false
          },
          "AUTH_TOKEN": {
            "required": false
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "refresh",
        "runsOn": "ubuntu-latest",
        "steps": [
          {
            "name": "Checkout repository",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "Install jq",
            "uses": "",
            "run": "sudo apt-get update\nsudo apt-get install -y jq\n"
          },
          {
            "name": "Refresh Authentication Token",
            "uses": "",
            "run": "echo \"🔐 Starting token refresh process...\"\n\n# Initialize variables\nACCESS_TOKEN=\"\"\nTOKEN_REFRESHED=false\n\n# Try service account first\nif [ -n \"$SERVICE_ACCOUNT_SECRET\" ]; then\n  echo \"Attempting service account authentication...\"\n  RESPONSE=$(curl -s -X POST \"$SITE_URL/api/auth/refresh\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"serviceAccount\\\": \\\"$SERVICE_ACCOUNT_SECRET\\\"}\")\n  \n  ACCESS_TOKEN=$(echo \"$RESPONSE\" | jq -r '.accessToken // empty')\n  \n  if [ -n \"$ACCESS_TOKEN\" ]; then\n    echo \"✅ Service account token obtained\"\n    TOKEN_REFRESHED=true\n  else\n    echo \"⚠️ Service account authentication failed\"\n  fi\nfi\n\n# Try refresh token if service account failed\nif [ \"$TOKEN_REFRESHED\" = false ] && [ -n \"$REFRESH_TOKEN\" ]; then\n  echo \"Attempting refresh token authentication...\"\n  RESPONSE=$(curl -s -X POST \"$SITE_URL/api/auth/refresh\" \\\n    -H \"Content-Type: application/json\" \\\n    -d \"{\\\"refreshToken\\\": \\\"$REFRESH_TOKEN\\\"}\")\n  \n  ACCESS_TOKEN=$(echo \"$RESPONSE\" | jq -r '.accessToken // empty')\n  NEW_REFRESH_TOKEN=$(echo \"$RESPONSE\" | jq -r '.refreshToken // empty')\n  \n  if [ -n \"$ACCESS_TOKEN\" ]; then\n    echo \"✅ Refresh token authentication successful\"\n    TOKEN_REFRESHED=true\n    \n    # Store new refresh token if provided\n    if [ -n \"$NEW_REFRESH_TOKEN\" ]; then\n      echo \"📝 New refresh token received (update GitHub secret manually)\"\n    fi\n  else\n    echo \"⚠️ Refresh token authentication failed\"\n  fi\nfi\n\n# Validate existing token as last resort\nif [ \"$TOKEN_REFRESHED\" = false ] && [ -n \"$AUTH_TOKEN\" ]; then\n  echo \"Testing existing AUTH_TOKEN...\"\n  HTTP_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" \\\n    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n    \"$SITE_URL/api/admin/queue/status\")\n  \n  if [ \"$HTTP_CODE\" = \"200\" ]; then\n    echo \"✅ Existing token is still valid\"\n    ACCESS_TOKEN=\"$AUTH_TOKEN\"\n    TOKEN_REFRESHED=true\n  else\n    echo \"⚠️ Existing token is invalid (HTTP $HTTP_CODE)\"\n  fi\nfi\n\n# Output final status\nif [ \"$TOKEN_REFRESHED\" = true ]; "
          },
          {
            "name": "Verify Token",
            "uses": "",
            "run": "echo \"🔍 Verifying refreshed token...\"\nHTTP_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" \\\n  -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n  \"$SITE_URL/api/admin/queue/status\")\n\nif [ \"$HTTP_CODE\" = \"200\" ]; then\n  echo \"✅ Token verification successful\"\nelse\n  echo \"❌ Token verification failed (HTTP $HTTP_CODE)\"\n  exit 1\nfi\n"
          }
        ],
        "secretRefs": []
      }
    ]
  },
  {
    "file": ".github/workflows/weekly-smoke-test.yml",
    "name": "🔥 Weekly Smoke Test",
    "on": {
      "schedule": [
        {
          "cron": "0 8 * * 1"
        }
      ],
      "workflow_dispatch": {
        "inputs": {
          "target_environment": {
            "description": "Target environment to test",
            "required": false,
            "type": "choice",
            "options": [
              "production",
              "development"
            ],
            "default": "production"
          },
          "include_load_tests": {
            "description": "Include load testing",
            "required": false,
            "type": "boolean",
            "default": false
          }
        }
      }
    },
    "jobs": [
      {
        "jobName": "weekly-smoke-test",
        "runsOn": "ubuntu-latest",
        "timeout": 15,
        "permissions": {
          "contents": "read",
          "actions": "write",
          "issues": "write"
        },
        "steps": [
          {
            "name": "📥 Checkout code",
            "uses": "actions/checkout@v4"
          },
          {
            "name": "📋 Setup Node.js",
            "uses": "actions/setup-node@v4"
          },
          {
            "name": "📦 Install dependencies",
            "uses": "",
            "run": "npm ci\n\n# Install additional system dependencies for smoke tests\nsudo apt-get update\nsudo apt-get install -y bc jq curl\n"
          },
          {
            "name": "🔧 Configure test environment",
            "uses": "",
            "run": "# Determine target URL\nif [ \"${{ github.event.inputs.target_environment }}\" = \"development\" ]; then\n  echo \"BASE_URL_OVERRIDE=${{ env.DEVELOPMENT_URL }}\" >> $GITHUB_ENV\n  echo \"🧪 Testing development environment\"\nelse\n  echo \"BASE_URL_OVERRIDE=${{ env.PRODUCTION_URL }}\" >> $GITHUB_ENV\n  echo \"🌐 Testing production environment\"\nfi\n\n# Configure load testing\nif [ \"${{ github.event.inputs.include_load_tests }}\" = \"true\" ]; then\n  echo \"LOAD_TEST_FLAG=--load-test\" >> $GITHUB_ENV\n  echo \"🚀 Load testing enabled\"\nelse\n  echo \"LOAD_TEST_FLAG=\" >> $GITHUB_ENV\n  echo \"📊 Standard testing only\"\nfi\n"
          },
          {
            "name": "🔥 Run smoke tests",
            "uses": "",
            "run": "echo \"🔥 Starting comprehensive smoke tests...\"\necho \"Target: $BASE_URL_OVERRIDE\"\necho \"\"\n\n# Make smoke test script executable\nchmod +x scripts/smoke.sh\n\n# Create results directory\nmkdir -p test-results\n\n# Run smoke tests with JSON output for parsing\nset +e  # Don't exit on failure, we want to capture results\n\n# Run public endpoint tests (no auth required)\necho \"📊 Testing public endpoints...\"\nif scripts/smoke.sh --json $LOAD_TEST_FLAG > test-results/smoke-results.json; then\n  SMOKE_EXIT_CODE=0\n  echo \"✅ Public smoke tests passed\"\nelse\n  SMOKE_EXIT_CODE=$?\n  echo \"❌ Public smoke tests failed (exit code: $SMOKE_EXIT_CODE)\"\nfi\n\n# Also run with human-readable output for logs\necho \"\"\necho \"📋 Detailed test results:\"\nscripts/smoke.sh $LOAD_TEST_FLAG || true\n\n# Save exit code for later steps\necho \"SMOKE_EXIT_CODE=$SMOKE_EXIT_CODE\" >> $GITHUB_ENV\n\n# Parse results if JSON exists\nif [ -f \"test-results/smoke-results.json\" ]; then\n  echo \"📊 Parsing test results...\"\n  \n  TOTAL_TESTS=$(jq -r '.summary.total // 0' test-results/smoke-results.json)\n  PASSED_TESTS=$(jq -r '.summary.passed // 0' test-results/smoke-results.json)\n  FAILED_TESTS=$(jq -r '.summary.failed // 0' test-results/smoke-results.json)\n  SUCCESS_RATE=$(jq -r '.summary.success_rate // 0' test-results/smoke-results.json)\n  \n  echo \"TOTAL_TESTS=$TOTAL_TESTS\" >> $GITHUB_ENV\n  echo \"PASSED_TESTS=$PASSED_TESTS\" >> $GITHUB_ENV\n  echo \"FAILED_TESTS=$FAILED_TESTS\" >> $GITHUB_ENV\n  echo \"SUCCESS_RATE=$SUCCESS_RATE\" >> $GITHUB_ENV\n  \n  echo \"📈 Test Summary:\"\n  echo \"  Total: $TOTAL_TESTS\"\n  echo \"  Passed: $PASSED_TESTS\"\n  echo \"  Failed: $FAILED_TESTS\"\n  echo \"  Success Rate: $SUCCESS_RATE%\"\nfi\n"
          },
          {
            "name": "🏥 Quick admin health check",
            "uses": "",
            "run": "echo \"🏥 Running quick admin health check...\"\n\n# Make poke-admin script executable\nchmod +x scripts/poke-admin.sh\n\n# Run admin health check (will skip auth tests without token)\nset +e\nif scripts/poke-admin.sh > test-results/admin-health.log 2>&1; then\n  ADMIN_HEALTH_CODE=0\n  echo \"✅ Admin health check passed\"\nelse\n  ADMIN_HEALTH_CODE=$?\n  echo \"❌ Admin health check failed (exit code: $ADMIN_HEALTH_CODE)\"\nfi\n\necho \"ADMIN_HEALTH_CODE=$ADMIN_HEALTH_CODE\" >> $GITHUB_ENV\n\necho \"📋 Admin health results:\"\ncat test-results/admin-health.log\n"
          },
          {
            "name": "📊 Generate test report",
            "uses": "",
            "run": "echo \"📊 Generating comprehensive test report...\"\n\n# Create report file\nREPORT_FILE=\"test-results/weekly-smoke-report.md\"\n\ncat > \"$REPORT_FILE\" << EOF\n# 🔥 Weekly Smoke Test Report\n\n**Date:** $(date -u -Iseconds)  \n**Environment:** $BASE_URL_OVERRIDE  \n**Triggered by:** ${{ github.event_name }}  \n**Workflow Run:** [\\#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})  \n\n## 📈 Test Results Summary\n\n| Metric | Value | Status |\n|--------|-------|--------|\n| **Total Tests** | ${TOTAL_TESTS:-N/A} | - |\n| **Passed Tests** | ${PASSED_TESTS:-N/A} | $([ \"${PASSED_TESTS:-0}\" -eq \"${TOTAL_TESTS:-1}\" ] && echo \"✅\" || echo \"❌\") |\n| **Failed Tests** | ${FAILED_TESTS:-N/A} | $([ \"${FAILED_TESTS:-1}\" -eq \"0\" ] && echo \"✅\" || echo \"❌\") |\n| **Success Rate** | ${SUCCESS_RATE:-N/A}% | $([ \"${SUCCESS_RATE:-0}\" = \"100\" ] && echo \"✅\" || echo \"❌\") |\n| **Admin Health** | Exit Code ${ADMIN_HEALTH_CODE:-N/A} | $([ \"${ADMIN_HEALTH_CODE:-1}\" -eq \"0\" ] && echo \"✅\" || echo \"❌\") |\n\n## 🎯 Overall Status\n\nEOF\n\n# Determine overall status\nif [ \"${SMOKE_EXIT_CODE:-1}\" -eq \"0\" ] && [ \"${ADMIN_HEALTH_CODE:-1}\" -eq \"0\" ]; then\n  echo \"**🎉 ALL TESTS PASSED** - System is healthy\" >> \"$REPORT_FILE\"\n  echo \"OVERALL_STATUS=success\" >> $GITHUB_ENV\nelse\n  echo \"**🚨 TESTS FAILED** - Issues detected that require attention\" >> \"$REPORT_FILE\"\n  echo \"OVERALL_STATUS=failure\" >> $GITHUB_ENV\nfi\n\ncat >> \"$REPORT_FILE\" << EOF\n\n## 📋 Detailed Results\n\n### 🔥 Smoke Test Details\n\\`\\`\\`json\n$(cat test-results/smoke-results.json 2>/dev/null || echo '{\"error\": \"No smoke test results available\"}')\n\\`\\`\\`\n\n### 🏥 Admin Health Check\n\\`\\`\\`\n$(cat test-results/admin-health.log 2>/dev/null || echo \"No admin health results available\")\n\\`\\`\\`\n\n## 🔗 Quick Links\n\n- [Production Site](${{ env.PRODUCTION_URL }})\n- [Admin Dashboard](${{ env.PRODUCTION_URL }}/admin)\n- [API Documentation](${{ env.PRODUCTION_URL }}/admin/docs)\n- [System Metrics](${{ env.PRODUCTION_URL }}/api/system"
          },
          {
            "name": "📤 Upload test results",
            "uses": "actions/upload-artifact@v4"
          },
          {
            "name": "📝 Add to job summary",
            "uses": "",
            "run": "echo \"## 🔥 Weekly Smoke Test Summary\" >> $GITHUB_STEP_SUMMARY\necho \"\" >> $GITHUB_STEP_SUMMARY\n\n# Add report content to job summary\ncat test-results/weekly-smoke-report.md >> $GITHUB_STEP_SUMMARY\n"
          },
          {
            "name": "🚨 Create issue on failure",
            "uses": "actions/github-script@v7"
          },
          {
            "name": "✅ Success notification",
            "uses": "",
            "run": "echo \"🎉 Weekly smoke test completed successfully!\"\necho \"\"\necho \"📊 Results summary:\"\necho \"  - Total tests: ${TOTAL_TESTS:-N/A}\"\necho \"  - Passed: ${PASSED_TESTS:-N/A}\"\necho \"  - Failed: ${FAILED_TESTS:-N/A}\"\necho \"  - Success rate: ${SUCCESS_RATE:-N/A}%\"\necho \"  - Admin health: $([ \"${ADMIN_HEALTH_CODE:-1}\" -eq \"0\" ] && echo \"✅ Healthy\" || echo \"❌ Issues\")\"\necho \"\"\necho \"🌐 System is healthy and operating normally.\"\n"
          }
        ],
        "secretRefs": []
      }
    ]
  }
]